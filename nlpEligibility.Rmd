---
title: "NLP eligibility criteria"
author: "digital ECMT"
date: "07/12/2021"
output: html_document
---

```{r copyright notice}
 # 
 # This file is part of the cancer-trial-match distribution (https://github.com/digital-ECMT/cancer-trial-match).
 # Copyright (C) 2021 digital ECMT
 # 
 # This program is free software: you can redistribute it and/or modify  
 # it under the terms of the GNU General Public License as published by  
 # the Free Software Foundation, version 3 or later.
 #
 # This program is distributed in the hope that it will be useful, but 
 # WITHOUT ANY WARRANTY; without even the implied warranty of 
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU 
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License 
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #


```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
##NOTE: the following packages are required to run this script, but should be installed (e.g. using code snippets below) before runnning the script, NOT as part of the script itself
# options(repos = "http://cran.us.r-project.org")
# install.packages("BiocManager")
# BiocManager::install("AnnotationDbi")
# BiocManager::install("org.Hs.eg.db")
# BiocManager::install("KEGGREST")
# BiocManager::install("KEGGlincs")
# BiocManager::install("hgu133a.db")
require(KEGGlincs)        ## GPL-3
require(KEGGgraph)        ## GPL >= 2
require(org.Hs.eg.db)     ## Artistic-2.0
require(KEGGREST)         ## Artistic 2.0
require(DBI)              ## LGPL-2.1 | LGPL-3 
require(RODBC)            ## GPL-2 | GPL-3
require(RPostgres)        ## GPL-3
require(RSQLite)          ## LGPL-2.1 | LGPL-3
require(jsonlite)         ## MIT
require(dplyr)            ## MIT
require(tidyr)            ## MIT
require(formattable)      ## MIT
require(kableExtra)       ## MIT
require(stringr)          ## MIT
require(splitstackshape)  ## GPL-3
require(reshape2)         ## MIT
require(tictoc)           ## Apache License (== 2.0
require(leaflet)          ## GPL-3
require(PostcodesioR)     ## GPL-3
require(igraph)           ## GPL-2 | GPL-3
require(tidygeocoder)     ## MIT
require(caret)
require(rpart)
require(rpart.plot)
require(SentimentAnalysis)

## clean up first
rm(list=ls())

##get today's date
today <- format(Sys.Date(), format = "%d %B %Y")
```

```{r connect to SQLite DB} 
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "indexedTrialData.sqlite")

dbListTables(con)

```
  
```{r load eligibilities table}
eligibilities <- dbGetQuery(con, statement = "SELECT * FROM eligibilities")

```

```{r load NCIt}
NCIt <- dbGetQuery(con, statement = "SELECT * FROM NCIt")

```

The NCI thesaurus includes `r length(unique(NCIt$Class))` different *Classes*, such as:  
`r head(unique(NCIt$Class))`  
  
We can use these as "topics" and identify topic(s) for each criterion.  
  
In some cases, topics are negated, such as "HER2-negative tumours defined as 0, 1+ or 2+ intensity on IHC and no evidence of amplification of the HER2 gene on ISH." (NCT03395899). We will use sentiment analysis to distinguish negative vs positive criteria.  
  
Note the NCI thesaurus will need some processing, e.g.  
* Remove synonyms that are non-specific (such as "Positive" is listed as a synonym for 71 different terms, including *PD-L1 Positive, KRAS Gene Mutation, Hepatitis B Surface Antibody Positive* and others)  
* Remove synonyms that do not contain any letters, such as *2: 162834264-162824895, 072, >=75, <1* and such.  
* Add a stemmed, lowercase copy of Synonyms (e.g. convert "HER2 Overexpression" to "her2 overexpress")  

  
This is all done as part of indexTrialData.Rmd, and the preprocessed NCI thesaurus is saved as the table NCIt.  
  
  
  
```{r preprocess NCIt}
# ## delete any rows containing the pattern "Retired Concept"
# NCIt <- NCIt[grep(pattern = "Retired Concept", x=NCIt$Synonyms, invert = TRUE), ]
# NCIt <- NCIt[grep(pattern = "Retired Concept", x=NCIt$Parent_synonym, invert = TRUE), ]
# 
# ## delete any rows with Synonyms that map to >1 term within a Class
# NCIt_multiple_terms <- NCIt %>%
#   group_by(Synonyms, Class) %>%
#   summarise(
#     number_terms = length(unique(ID))
#   ) %>%
#   filter(number_terms >1) %>%
#   as.data.frame()
# ## anti join
# NCIt <- anti_join(NCIt, NCIt_multiple_terms, by=c("Synonyms", "Class"))
# rm(NCIt_multiple_terms)
# 
# ## delete any rows that don't contain any letters... 
# NCIt <- NCIt[grep(pattern = "[a-zA-Z]", x=NCIt$Synonyms), ]
# 
# ## stem the synonyms 
# NCIt$Synonyms_stem <- textstem::stem_strings(NCIt$Synonyms)
# 
# ## convert to lowercase
# NCIt_biomarkers$Synonyms_stem <- tolower(NCIt_biomarkers$Synonyms_stem)
```

```{r stem NCIt synonyms}
# ## stem the synonyms in same way as we will for eligibility criteria
# NCIt$Synonyms_stem <- textstem::stem_strings(NCIt$Synonyms)
# 
# ## convert to lowercase
# NCIt_biomarkers$Synonyms_stem <- tolower(NCIt_biomarkers$Synonyms_stem)



```









```{r index on Cell or Molecular Dysfunction}
tic("index all studies")

example_studies <- c("NCT04607668", "NCT03875820")

NCIt_cellMolecularDysfunction <- unique(dplyr::filter(NCIt, Class=="Cell or Molecular Dysfunction"))

custom_tokens <- unique(NCIt_cellMolecularDysfunction$Synonyms_stem)

example_criteria <- eligibilities

# example_criteria <- unique(filter(example_criteria, nct_id %in% example_studies))

example_criteria <- dplyr::select(example_criteria, criterion_index,nct_id, criteria, criterion_type, criteria_stem)

## create a stemmed copy
# example_criteria$criteria_stem <- textstem::stem_strings(example_criteria$criteria)

## convert to lowercase
# example_criteria$criteria_stem <- tolower(example_criteria$criteria_stem)

## tokenise
## tokenise the condition names
example_criteria$tokens <- as.list(corpus::text_tokens(x=example_criteria$criteria_stem,                                                filter= corpus::text_filter(combine = custom_tokens, map_case=FALSE, connector="_", drop_punct=TRUE )))

## unnest
example_criteria <- as.data.frame(unnest(data = example_criteria, tokens)) 

## replace underscores with spaces
example_criteria$tokens <- gsub(pattern = "_", replacement = " ", x=example_criteria$tokens)



## inner join
example_criteria_topics <- unique(merge(x=example_criteria, by.x = "tokens", all.x = FALSE, y = unique(dplyr::select(NCIt_cellMolecularDysfunction, Synonyms_stem, ID,PreferredTerm, Class)), by.y = "Synonyms_stem"))

toc()

```
  
**Note:** there are many false hits, e.g. "*abnormal*" is included as a synonym for *TP53 Gene Mutation* (C118396), which appears many times among eligibility criteria that are unrelated to this topic.  
  
We should penalise words that are common in the entire corpus (all eligibility criteria).  
  
  
  
  
  
taken from: https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63  
  
  

TF-IDF  
One problem with scoring word frequency is that the most frequent words in the document start to have the highest scores. These frequent words may not contain as much “informational gain” to the model compared with some rarer and domain-specific words. One approach to fix that problem is to penalize words that are frequent across all the documents. This approach is called TF-IDF.
TF-IDF, short for term frequency-inverse document frequency is a statistical measure used to evaluate the importance of a word to a document in a collection or corpus.  
  
The TF-IDF scoring value increases proportionally to the number of times a word appears in the document, but it is offset by the number of documents in the corpus that contain the word.  
  
```{r TF IDF calculation}
## NOW MOVED TO INDEXTRIALDATA.RMD CODE.... 
# eligibilities <- eligibilities %>% group_by(nct_id) %>% mutate(criterion_index = paste0(nct_id, "_", row_number())) %>% as.data.frame()

## see https://bookdown.org/yann_ryan/r-for-newspaper-data/calculating-tf-idf-scores-with-tidytext.html

## get a count of the frequency of each word (token) among the entire corpus of eligibility criteria
tic("tally tokens")
tally_tokens_by_nct_id <- example_criteria %>%
  group_by(nct_id, tokens) %>%
  tally() %>%
  arrange(desc(n)) %>%
  as.data.frame()
toc()

## just tally across the whole corpus
# tic("tally tokens")
# tally_tokens <- example_criteria %>% 
#   group_by(tokens) %>%
#   tally() %>% 
#   arrange(desc(n)) %>%
#   as.data.frame()
# toc()



## use bind_tf_idf() to calculate the measurement for each word in the dataframe
tally_tokens_by_nct_id <- tally_tokens_by_nct_id %>% tidytext::bind_tf_idf(tokens, nct_id, n)
# tally_tokens <- tally_tokens %>% tidytext::bind_tf_idf(tokens, n)

## merge with example_criteria_topics
example_criteria_topics <- merge(x=example_criteria_topics, by.x = c("nct_id", "tokens"), all.x = TRUE, y = unique(dplyr::select(tally_tokens_by_nct_id, nct_id, tokens, tf_idf)), by.y = c("nct_id", "tokens"))

```


















`r knitr::knit_exit()`    
  
  
  
  
  
  
  
  
  
  
  

```{r specify some example criteria}

criterion1 <- "Confirmed human epidermal growth factor 2 (HER2)-overexpressing status assessed by central laboratory and defined as immunohistochemistry (IHC) 3+ or IHC 2+/ in situ hybridization (ISH) +."

criterion2 <- "Histologically or cytologically proven advanced non-small-cell lung cancer (NSCLC) with a documented KRAS mutation, refractory to conventional treatment, or for which no conventional therapy exists or is declined by the patient (20 patients)."

criterion3 <- "Proficient mismatch repair/microsatellite stable (pMMR/MSS), histologically or cytologically-confirmed adenocarcinoma of the colon or rectum. Patients with any BRAF or KRAS mutation status are eligible."

exampleCriteria <- data.frame(criteria = c(criterion1, criterion2, criterion3))

```

```{r preprocess the example criteria}
## convert to stems
# corpus::text_tokens(exampleCriteria$criteria, stemmer = "en")

# corpus::text_tokens(exampleCriteria$criteria, filter=corpus::text_filter(stemmer = "english", drop_number = TRUE, drop_punct = TRUE, combine = "KRAS mutation"))

## lemmatize instead of stemming... 
# textstem::lemmatize_strings(criterion1)

exampleCriteria$criteria_lemma <- textstem::lemmatize_strings(exampleCriteria$criteria)

## note however, that this does not work
textstem::lemmatize_strings("HER2 Overexpression")

## but this does
textstem::stem_strings("HER2 Overexpression")

exampleCriteria$criteria_stems <- textstem::stem_strings(exampleCriteria$criteria)

# lemma_dictionary2 <- textstem::make_lemma_dictionary(x=criterion1, engine = 'hunspell')

```



```{r preprocess NCIt 2}
## we will use NCIt$Class values as "topics", and NCIt$Synonyms values as "detail"
## in order to index on biomarkers, we will use the following Classes: 
# "Laboratory or Test Result", "Cell or Molecular Dysfunction", "Gene or Genome"
# we will omit "Gene or Genome" as this massively increases the number of terms
# we will get gene synonyms from humanGenes table

NCIt_biomarkers <- unique(dplyr::filter(NCIt, Class %in% c("Laboratory or Test Result", "Cell or Molecular Dysfunction")))

## drop unnecessary colmns
NCIt_biomarkers <- unique(dplyr::select(NCIt_biomarkers, ID, Synonyms, PreferredTerm, Class))

## stem the synonyms in same way as eligibility criteria
NCIt_biomarkers$Synonyms_stem <- textstem::stem_strings(NCIt_biomarkers$Synonyms)

## convert to lowercase
NCIt_biomarkers$Synonyms_stem <- tolower(NCIt_biomarkers$Synonyms_stem)

```


```{r preprocess eligibility criteria}


## stem the criteria in same way as NCIt synonyms
eligibilities$criteria_stem <- textstem::stem_strings(eligibilities$criteria)

## drop unnecessary columns
eligibilities <- unique(dplyr::select(eligibilities, nct_id, id, criterion_type, criteria, criteria_stem))

## tokenise, passing NCIt synonym stems as custom tokens
## we will provide condition synonyms as custom tokens, then tokenise, unnest and perform the join
custom_tokens <- unique(NCIt_biomarkers$Synonyms_stem)

## tokenise the condition names
eligibilities$tokens <- as.list(corpus::text_tokens(x=eligibilities$criteria_stem,                                                filter= corpus::text_filter(combine = custom_tokens, map_case=FALSE, connector="_", drop_punct=TRUE )))

## unnest
eligibilities <- as.data.frame(unnest(data = eligibilities, tokens)) 

## replace underscores with spaces
eligibilities$tokens <- gsub(pattern = "_", replacement = " ", x=eligibilities$tokens)

```



```{r merge eligibility criteria with NCIt biomarkers}
eligibilities <- merge(x=eligibilities, by.x = "tokens", all.x=TRUE, y=NCIt_biomarkers, by.y="Synonyms_stem")




```








```{r sentiment analysis practice}


sentence1 <- "Proficient mismatch repair/microsatellite stable (pMMR/MSS), histologically or cytologically-confirmed adenocarcinoma of the colon or rectum. Patients with any BRAF or KRAS mutation status are eligible"


sentiment <- analyzeSentiment(sentence1)
convertToBinaryResponse(sentiment)$SentimentQDAP


sentence2 <- "For participants who have non-breast or -ovarian cancers that are breast cancer susceptibility gene 1/2 (BRCA1/2) mutated (BRCAm), or who have cancers that are BRCA1/2 non-mutated and homologous recombination repair nonmutated: Has a centrally-confirmed known or suspected deleterious mutation in breast cancer susceptibility gene (BRCA) 1 or BRCA2 and does not harbor a germline BRCA1 or BRCA2 mutation."

sentiment <- analyzeSentiment(sentence2)
convertToBinaryResponse(sentiment)$SentimentQDAP

```


