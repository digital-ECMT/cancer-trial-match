---
title: "Index clinicaltrials.gov data"
author: "digital ECMT"
date: "19/11/2021"
output: html_document
---


```{r copyright notice}
 # 
 # This file is part of the cancer-trial-match distribution (https://github.com/digital-ECMT/cancer-trial-match).
 # Copyright (C) 2021 digital ECMT
 # 
 # This program is free software: you can redistribute it and/or modify  
 # it under the terms of the GNU General Public License as published by  
 # the Free Software Foundation, version 3 or later.
 #
 # This program is distributed in the hope that it will be useful, but 
 # WITHOUT ANY WARRANTY; without even the implied warranty of 
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU 
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License 
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #


```




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
##NOTE: the following packages are required to run this script, but should be installed (e.g. using code snippets below) before runnning the script, NOT as part of the script itself
# options(repos = "http://cran.us.r-project.org")
# install.packages("BiocManager")
# BiocManager::install("AnnotationDbi")
# BiocManager::install("org.Hs.eg.db")
# BiocManager::install("KEGGREST")
# BiocManager::install("KEGGlincs")
# BiocManager::install("hgu133a.db")
require(KEGGlincs)        ## GPL-3
require(KEGGgraph)        ## GPL >= 2
require(org.Hs.eg.db)     ## Artistic-2.0
require(KEGGREST)         ## Artistic 2.0
require(DBI)              ## LGPL-2.1 | LGPL-3 
require(RODBC)            ## GPL-2 | GPL-3
require(RPostgres)        ## GPL-3
require(RSQLite)          ## LGPL-2.1 | LGPL-3
require(jsonlite)         ## MIT
require(dplyr)            ## MIT
require(tidyr)            ## MIT
require(formattable)      ## MIT
require(kableExtra)       ## MIT
require(stringr)          ## MIT
require(splitstackshape)  ## GPL-3
require(reshape2)         ## MIT
require(tictoc)           ## Apache License (== 2.0
require(leaflet)          ## GPL-3
require(PostcodesioR)     ## GPL-3
require(igraph)           ## GPL-2 | GPL-3
require(tidygeocoder)     ## MIT
require(caret)
require(rpart)
require(rpart.plot)
require(textstem)
require(quanteda)         ## GPL-3


## clean up first
rm(list=ls())

##get today's date
today <- format(Sys.Date(), format = "%d %B %Y")
```


**Date of data refresh: `r today`**  
  
  
```{r connect to SQLite DB} 
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "indexedTrialData.sqlite")

dbListTables(con)

```
  
### **Download and save a table of human genes and synonyms**  
  
```{r download and process a list of all human genes and their synonyms}

## start timer
tic("download a list of all human genes and their synonyms")


humanGenes <- read.table(file = "humanGenes.tsv", header = TRUE, quote = "", sep = "\t", fill = TRUE, stringsAsFactors = FALSE)


## exclude any entries that are not for Homo Sapiens
humanGenes <- unique(dplyr::filter(humanGenes, Org_name == "Homo sapiens"))

humanGenes <- unique(dplyr::select(humanGenes, GeneID, Symbol, Aliases)) ## drop everything except GeneID, Symbol and Aliases columns


humanGenes$Aliases <- strsplit(x=humanGenes$Aliases, split = ",")## split the aliases on comma 
humanGenes <- unnest(data = humanGenes, cols = Aliases, keep_empty = TRUE) ## unnest to multiply rows, keep any rows with no aliases
humanGenes <- as.data.frame(humanGenes) ## convert to data frame

humanGenes$Aliases <- str_squish(string = humanGenes$Aliases) ## trim excess whitespace from Aliases values

## Symbol values are not represented among Aliases
# create a data frame with unique Symbol values
symbols <- unique(dplyr::select(humanGenes,GeneID,"Symbol"= "Symbol", "Aliases"="Symbol"))


# bind this onto bottom of humanGenes data frame
humanGenes <- rbind(humanGenes,symbols)
# remove duplicated values, if any
humanGenes <- unique(humanGenes)
# sort on Symbol values
humanGenes <- humanGenes[order(humanGenes$Symbol), ] 

# drop any rows where Aliases is NA
humanGenes <- humanGenes[!is.na(humanGenes$Aliases), ]

## drop any rows where Aliases value is only a single character
humanGenes <- dplyr::filter(humanGenes, nchar(Aliases)>1)

## drop any rows where Aliases is a number
humanGenes <- humanGenes[is.na(as.numeric(humanGenes$Aliases)), ]

## drop any rows where Aliases is a common false hit (e.g. Roman numerals)
humanGenes <- humanGenes[!humanGenes$Aliases %in% c("I", "II", "III", "IV", "V", "VI", "VII", "VIII", "NA", "B12", "EL", "G6PD", "CAT", "CT", "MRI", "OTC", "polymerase", "G1", "PI", "COPD", "A1", "ARM", "ALS", "AA", "B5", "C1", "C2", "C3", "C5", "C6", "D3", "D4", "A-2", "A3", "1D", "1A", "L1"), ]

## NOW humanGenes TABLE CONTAINS ALL HUMAN GENES AND THEIR SYNONYMS

## stop timer
toc()

## delete symbols object to save memory
rm(symbols)
```
  
List of human genes and their synonyms is saved in the humanGenes table:  
  
`r formattable(head(humanGenes))`  
  
  
```{r save table of human genes to DB}
## preview
# formattable(head(humanGenes))

## create as a table in database
dbWriteTable(conn = con,name = "humanGenes", value = humanGenes, overwrite=TRUE)

## check it has saved
dbListTables(con)

```
    
### **Download and save NCI thesaurus**  
  
```{r download and create NCIthesaurus table}

## specify URL for NCI thesaurus - this should always be the most recent? 
NCItURL <- "https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/Thesaurus.FLAT.zip"

destFlatFilename <- "NCIt_FLAT.zip"
download.file(url=NCItURL,destfile = destFlatFilename)
unzip(zipfile = paste0(getwd(),"/",destFlatFilename))

NCIt <- read.table("Thesaurus.txt",header = FALSE, sep = "\t", comment.char = "", fill = TRUE, stringsAsFactors = FALSE, quote = "")
names(NCIt) <- c("ID","URL","ParentID","Synonyms","Description","PreferredTerm","Type","Class")


## save a copy for use later if needed
NCIt_raw <- NCIt

## an entity may have more than one class, so need to multiply rows
## split and unnest the Class column of NCIt
NCIt$Class <- strsplit(NCIt$Class, split = "\\|")
NCIt <- unnest(data = NCIt, Class)

## do the same for Parent column
## split ParentID column on pipe symbol
NCIt$ParentID <- strsplit(NCIt$ParentID, split = "\\|")
## unnest the ID column to multiply rows
NCIt <- unnest(data=NCIt,ParentID)

## drop unnecessary rows
NCIt <- unique(dplyr::select(NCIt, ID, ParentID, Synonyms, PreferredTerm, Class))

## join parent column back
## first, get the synonyms and IDs for parents
NCItParents <- NCIt[which(NCIt$ID %in% NCIt$ParentID), ]

## each parent term may have more than one synonym
## for simplicity, we will retain only the first synonym for each parent term
NCItParents$Synonyms <- gsub("\\|.*","",NCItParents$Synonyms)

NCItParents <- unique(dplyr::select(NCItParents, "ParentID"="ID", "Parent_synonym"="Synonyms"))

## merge parents on entity ID = parent ID
NCIt <- merge(x=NCIt,y=NCItParents,by.x="ParentID",by.y="ParentID",all.x=TRUE)

## split and unnest the Synonyms column
NCIt$Synonyms <- strsplit(NCIt$Synonyms, split = "\\|")
NCIt <- unnest(data = NCIt, Synonyms)

NCIt <- as.data.frame(NCIt)

## add a column to indicate date downloaded
NCIt$downloaded <- Sys.Date()

## drop redundant rows, if any
NCIt <- unique(NCIt)
```

  
```{r preprocess NCIt}
## delete any rows containing the pattern "Retired Concept"
NCIt <- NCIt[grep(pattern = "Retired Concept", x=NCIt$Synonyms, invert = TRUE), ]
NCIt <- NCIt[grep(pattern = "Retired Concept", x=NCIt$Parent_synonym, invert = TRUE), ]

## delete any rows with Synonyms that map to >1 term within a Class
NCIt_multiple_terms <- NCIt %>%
  group_by(Synonyms, Class) %>%
  summarise(
    number_terms = length(unique(ID))
  ) %>%
  filter(number_terms >1) %>%
  as.data.frame()
## anti join
NCIt <- anti_join(NCIt, NCIt_multiple_terms, by=c("Synonyms", "Class"))
rm(NCIt_multiple_terms)

## delete any rows that don't contain any letters... 
NCIt <- NCIt[grep(pattern = "[a-zA-Z]", x=NCIt$Synonyms), ]

## stem the synonyms 
NCIt$Synonyms_stem <- textstem::stem_strings(NCIt$Synonyms)

## convert to lowercase
NCIt$Synonyms_stem <- tolower(NCIt$Synonyms_stem)
```
  
  
Preprocessed NCI thesaurus is saved in the NCIt table:  
  
`r formattable(head(NCIt))`  
  
    

```{r write NCIt to database}
## create as a table in database
dbWriteTable(conn = con,name = "NCIt", value = NCIt, overwrite=TRUE)

```
  
  
  
A subset of the preprocessed NCI thesaurus (Class=="Pharmacologic Substance" is saved in memory in the NCIt_Pharmacologics table (not saved to DB).  

```{r subset NCIt for Pharmacologic Substance}


NCIt_Pharmacologics <- unique(dplyr::filter(NCIt, Class=="Pharmacologic Substance"))

## delete NCIt and NCItParents objects to save memory
# rm(NCIt)
rm(NCItParents)

```
  

### **Map NCIt drugs to targets via KEGG**  
  
```{r use KEGG BRITE}
## download Target-based Classification of Drugs (JSON format) from: https://www.genome.jp/kegg-bin/download_htext?htext=br08310&format=json&filedir=
## save as "kegg_brite.json"
# kegg_brite <- fromJSON("kegg_brite.json")

## CAN'T USE THIS, AS SOME OF THE TARGETS LISTED REFER TO GROUPS OF PROTEINS, NOT INDIVIDUAL PROTEINS.. 

```
  
```{r use pathways in cancer}

## the KEGG pathways in cancer entry (hsa05200) is associated with 329 different drugs...
hsa05200_list <- keggGet("hsa05200")
# the drug names are stored in even numbered elements
# the KEGG drug IDs are stored in odd numbered elements
hsa05200_list_drugs <- hsa05200_list[1][[1]]$DRUG

kegg_drugs <- data.frame(
  drug_name = hsa05200_list_drugs[seq(2, length(hsa05200_list_drugs), 2)], ## get even numbered elements 
  kegg_drug_id = hsa05200_list_drugs[seq(1, length(hsa05200_list_drugs), 2)] ## get odd numbered elements
)

## process drug names
kegg_drugs$drug_name <- gsub(pattern = " \\(.*", replacement = "", x=kegg_drugs$drug_name)

## join to NCIt ID
kegg_drugs$drug_name_lower <- tolower(kegg_drugs$drug_name)
NCIt_Pharmacologics$Synonyms_lower <- tolower(NCIt_Pharmacologics$Synonyms)

kegg_drugs <- unique(merge(x=dplyr::select(NCIt_Pharmacologics, "NCIt_drug_id"="ID", Synonyms_lower ), 
      by.x = "Synonyms_lower", 
      y=kegg_drugs, by.y="drug_name_lower", all.y=TRUE))

# can use drug IDs to get targets, e.g. 
# keggGet("D12282")[[1]]$TARGET$TARGET
## however, cannot use this directly, as some drugs map to multiple targets, e.g. 
# keggGet("D11138")[[1]]$TARGET$TARGET

## add a column that will hold ID for target gene(s)
kegg_drugs$target_id <- NA
for(i in 1:nrow(kegg_drugs)) {
  drug_id = as.character(kegg_drugs$kegg_drug_id[i])
  geneid <- NA
  tryCatch({geneid <- keggGet(drug_id)[[1]]$TARGET$TARGET},
             error=function(cond) {return(NA)})
  #print(geneid)
  if(length(geneid)>0) kegg_drugs$target_id[i] <- geneid
}
## parse to retain only the id numbers for target genes
kegg_drugs$target_id <- gsub(pattern = ".*HSA:", replacement = "", x=kegg_drugs$target_id)

kegg_drugs$target_id <- gsub(pattern = "\\].*", replacement = "", x=kegg_drugs$target_id)

# split on space into individual ids, where applicable
kegg_drugs$target_id <- strsplit(kegg_drugs$target_id, split = " ")
kegg_drugs <- unnest(data = kegg_drugs, target_id)
kegg_drugs <- as.data.frame(kegg_drugs)
kegg_drugs$target_id <- str_squish(kegg_drugs$target_id)
kegg_drugs$target_id <- paste0("hsa:", kegg_drugs$target_id)
## need to parse the hsa codes, convert to lowercase and then call e.g. 
# keggGet("hsa:4914")[[1]]$SYMBOL

## add a column that will hold symbol for target gene(s)
kegg_drugs$target_symbol <- NA
for(i in 1:nrow(kegg_drugs)) {
  target_id = as.character(kegg_drugs$target_id[i])
  target_symbol <- NA
  tryCatch({target_symbol <- keggGet(target_id)[[1]]$SYMBOL},
             error=function(cond) {return(NA)})
  #print(target_symbol)
  if(length(target_symbol)>0) kegg_drugs$target_symbol[i] <- target_symbol
}
## parse to retain only the first value (Entrez symbol)
kegg_drugs$target_symbol <- gsub(pattern = ",.*", replacement = "", x=kegg_drugs$target_symbol)

## select and reorder columns
kegg_drugs <- unique(dplyr::select(kegg_drugs, NCIt_drug_id, drug_name, target_symbol))

 
```

  
  
A list of cancer drugs, their molecular targets, and mapping to NCIt entities is saved in the kegg_drugs table:  
  
`r formattable(head(kegg_drugs))`  
  
   
  
```{r write kegg drugs to database}

## create as a table in database
dbWriteTable(conn = con,name = "kegg_drugs", value = kegg_drugs, overwrite=TRUE)

dbListTables(con)

```



```{r get cancer drugs from db}

## a database of licensed cancer drugs is maintained at https://www.anticancerfund.org/en/cancerdrugs-db 
## machine-readable version can be downloaded from... 
# https://acfdata.coworks.be/cancerdrugsdb.txt

# cancer_drugs <- read.delim(file="https://acfdata.coworks.be/cancerdrugsdb.txt", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "", stringsAsFactors = FALSE)
## as of 01/11/2021, there are 282 drugs in this database


## however, drugs such as Inavolisib don't appear in this list, but do have entries in KEGG... 
```
  

```{r download NCIt in OWL format}
## we will download the inferred version of the thesaurus, described at https://evs.nci.nih.gov/evs-download/thesaurus-downloads 

# NCIt_url_OWL <- "https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/ThesaurusInf_21.10d.OWL.zip"
# destOWLfilename <- "NCIt_OWL.zip"
# download.file(url=NCIt_url_OWL,destfile = destOWLfilename)
# unzip(zipfile = paste0(getwd(),"/",destOWLfilename))

## the unzipped file is called "ThesaurusInferred.owl"
```

```{r use R ontocat to navigate ontology}

## install.packages("BiocManager")
## BiocManager::install("ontoCAT")
## "not available for R 3.6.2" (deprecated and no longer supported?)

```
  
```{r load using OntologyX}
## download NCIt in OBO format from EMBL?
## see https://www.ebi.ac.uk/ols/ontologies/ncit
## download manually 
# require(ontologyIndex)
# ontology <- get_ontology("ncit_obo.owl")


```

```{r read NCIt in OWL format}
## issues creating miniconda environment due to apostrophe in name of Users folder
## Error 127 occurred creating conda environment C:/Users/O’ReganPaul/AppData/Local/r-miniconda/envs/r-reticulate

## import owlready2





```

```{r define function to map drug names to KEGG drug IDs}

# test using "1-methyl-D-tryptophan", aka "Indoximod"

# getDrugID <- function(drugName){
#   if(is.na(drugName)) return(NA)
#   ## get drug ID
#   drugid <- tryCatch({names(keggFind(database = "drug", query = drugName))},
#              error=function(cond) {return(NA)})
#   if(is.null(drugid)) return(NA)
#   if(is.na(drugid)) return(NA)
#   drugid <- as.list(drugid)
#   return(drugid)
# }

```

```{r map NCIt drug names to KEGG drug IDs}
## NOT RUN, AS TAKES >20 HOURS TO COMPLETE
## ONCE COMPLETE, NEED TO ALSO MAP FROM DRUG ID TO TARGET GENE ID, AND THEN FROM TARGET GENE ID TO TARGET GENE SYMBOL... 


# NCIt_Pharmacologics$kegg_drug_id <- NA
# 
# tic("index NCIt pharmacologics with kegg drug id")
# for(i in 1:length(unique(NCIt_Pharmacologics$ID))) {
#   print(paste0("i:", i))
#   id <- unique(NCIt_Pharmacologics$ID)[i]
#   print(paste0("ID:", id))
#   synonyms <- unique(NCIt_Pharmacologics$Synonyms[NCIt_Pharmacologics$ID == id])
#   print(paste(synonyms, collapse = ", "))
#   kegg_drugid <- NA
#   ## loop through synonyms and call KEGG API
#   for(j in 1:length(synonyms)) {
#     kegg_drugid <- getDrugID(synonyms[j])
#     if(!is.na(kegg_drugid)) break
#   }
#   print(paste0("kegg drug id:", kegg_drugid))
#   NCIt_Pharmacologics$kegg_drug_id[NCIt_Pharmacologics$ID == id] <- kegg_drugid
# }
# toc()


```
  
### **Download lat, long values for UK postcodes**  
  
```{r download ordnance survey data}
## download from https://www.freemaptools.com/download/full-uk-postcodes/ukpostcodes.zip
## Copyright and Reproduction
## As per : https://www.ons.gov.uk/methodology/geography/licences

##You may re-use this information (not including logos or Northern Ireland data) free of charge in any format or medium, under the terms of the relevant data owners' licence. In addition, the following attribution statements must be acknowledged or displayed whenever the owners data is used:

## Contains Ordnance Survey data © Crown copyright and database right 2021

## Contains Royal Mail data © Royal Mail copyright and database right 2021

## Source: Office for National Statistics licensed under the Open Government Licence v.3.0

## specify URL for download 
postcodesURL <- "https://www.freemaptools.com/download/full-uk-postcodes/ukpostcodes.zip"

destPostcodesFilename <- "uk_postcodes.zip"
download.file(url=postcodesURL, destfile = destPostcodesFilename)
unzip(zipfile = paste0(getwd(),"/",destPostcodesFilename))

uk_postcodes <- read.csv("ukpostcodes.csv", header = TRUE, stringsAsFactors = FALSE)


## create as a table in database
dbWriteTable(conn = con,name = "uk_postcodes", value = uk_postcodes, overwrite=TRUE)

```

  
A list of latitude, longitude values for UK postcodes is saved in the uk_postcodes table:  
  
`r formattable(head(uk_postcodes))`  
  
   
### **Define controlled terms and synonyms for cancer types**  
  
```{r create table of cancer types}
## conditionSynonyms specifies which cancer types are of interest, and which condition names (as used by clinicaltrials.gov) will be considered as matches for each

## synonyms define on basis of those in clinicaltrials.gov
conditionSynonyms <- read.csv(file = "conditionSynonyms5.csv", stringsAsFactors = FALSE)

## trim leading/trailing whitespace, if any
conditionSynonyms$condition_synonyms <- str_squish(string = conditionSynonyms$condition_synonyms)

## remove redundancy, if any
conditionSynonyms <- unique(conditionSynonyms)

## create as a table in database
dbWriteTable(conn = con,name = "conditionSynonyms", value = conditionSynonyms, overwrite=TRUE)

## check it has saved
dbListTables(con)

```
  

  
A list of cancer types of interest and their mappings to condition names (as used by clinicaltrials.gov) is saved in the conditionSynonyms table:  
  
`r formattable(head(conditionSynonyms))`  
    
### **Connect to clinicaltrials.gov**  
  
```{r connect to clinicaltrialsgov}  
## specify user name and password for AACT account
## see https://aact.ctti-clinicaltrials.org/ for how to create an account

## load configuration data from JSON file
## configuration <- rjson::fromJSON(file = "trialMatchConfiguration.json")

## jsonlite is MIT
configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
aact.username <- configuration$aact.username
aact.password <- configuration$aact.password


## connect via RPostgres (GPL-3 licence)
drv = RPostgres::Postgres()
conn2 <- dbConnect(drv, dbname="aact",host="aact-db.ctti-clinicaltrials.org", port=5432, user=aact.username, password=aact.password )
```
 
### **Get study info for all interventional cancer studies (globally, ever)**  
  
```{r get study data}

## get data for all cancer studies that have reported results
cancerStudiesQ <- "SELECT s.nct_id, s.brief_title, s.phase, s.acronym, s.number_of_arms, s.number_of_groups,  s.overall_status, s.last_update_posted_date, c.name AS condition
FROM studies s
INNER JOIN conditions c ON c.nct_id = s.nct_id
INNER JOIN calculated_values cv ON cv.nct_id = s.nct_id
WHERE s.study_type LIKE ('Interventional')
AND (c.downcase_name LIKE '%cancer%'
OR c.downcase_name LIKE '%neoplasm%'
OR c.downcase_name LIKE '%carcinoma%'
OR c.downcase_name LIKE '%tumo%')"

## get data from clinicaltrials.gov
cancerStudies <- dbGetQuery(conn2,cancerStudiesQ)

## add a column to indicate refresh date
cancerStudies$refresh_date <- today

```
  
As of `r today`, there are a total of `r length(unique(cancerStudies$nct_id))` cancer studies listed in clinicaltrials.gov and included in this analysis.  
  
  
`r formattable(head(cancerStudies))`  
    

#### **Map verbatim condition names to controlled set of cancer types**  
  
```{r tokenise and join to condition synonyms}
## we can't just join to condition synonyms as condition may include extra words
## such as "Stage IV Lung Cancer AJCC v8" and "Metastatic Lung Non-Small Cell Carcinoma"

## we will provide condition synonyms as custom tokens, then tokenise, unnest and perform the join
custom_tokens <- unique(conditionSynonyms$condition_synonyms)

## tokenise the condition names
cancerStudies$word <- as.list(corpus::text_tokens(x=cancerStudies$condition,                                                filter= corpus::text_filter(combine = custom_tokens, map_case=TRUE, connector="_", drop_punct=TRUE )))


## unnest
cancerStudies <- as.data.frame(unnest(data = cancerStudies, word)) 
## this function does insist on replacing whitespace with a character (here, underscore), so need to swap that back to whitespace
cancerStudies$word <- gsub(pattern = "_", replacement = " ", x=cancerStudies$word)


## join on word = conditionSynonyms$condition_synonyms
cancerStudies <- unique(merge(x=cancerStudies, by.x = "word", y=conditionSynonyms, by.y="condition_synonyms"))

## NOTE: ANY STUDY-CONDITION COMBINATIONS NOT REPRESENTED IN THE CONTROLLED TERMS WILL BE LOST AT THIS STAGE

## drop the word column
cancerStudies <- unique(dplyr::select(cancerStudies, -c(word)))


```
  
After mapping to controlled terms for cancer types, `r length(unique(cancerStudies$nct_id))` studies remain...  
  
  
`r formattable(head(cancerStudies))`  
    
  
### **Get study interventions**  
  
```{r get study interventions}
## format study IDs for SQL query
studyIDsForSQL <- paste0("\'",paste(unique(cancerStudies$nct_id), collapse = "\',\'"), "\'")

getInterventionsQ <- paste0("select i.nct_id, i.id AS intervention_id, i.name AS intervention_name 
from interventions i
where i.nct_id in (",
"", studyIDsForSQL,
")")

## get interventions from clinicaltrials.gov
interventions <- dbGetQuery(conn2,getInterventionsQ)

```

Interventions are stored as follows in clinicaltrials.gov (each intervention_id value is unique, i.e. same intervention in different studies is given different intervention_id values):  
  
`r formattable(head(interventions))`  
  
    
```{r create corpus from intervention names}
tic("create interventions corpus")
interventions_corpus <-  quanteda::corpus(x=unique(dplyr::select(interventions, nct_id, intervention_id, intervention_name)),
                                          text_field = "intervention_name", 
                                          docid_field = "intervention_id",
                                          unique_docnames = FALSE)
toc()

```

```{r tokenise interventions corpus}
tic("tokenise interventions corpus")
interventions_tokens <- tokens(interventions_corpus, remove_punct=TRUE, padding = FALSE, split_hyphens = FALSE)
toc()
```

```{r get context words surrounding intervention names}
## we can specify any window size, since we just want to pick out drug synonyms from surrounding text
tic("get kwic for interventions")
kwic_interventions <- as.data.frame(kwic(interventions_tokens, pattern =  unique(NCIt_Pharmacologics$Synonyms), window = 1, valuetype = "fixed", case_insensitive = TRUE))
toc()
#formattable(head(as.data.frame(kw_genes), 30))

## we just want the intervention ID and the matching pattern
kwic_interventions <- unique(dplyr::select(kwic_interventions, "intervention_id"="docname", "intervention_synonym"=pattern))

```
  
```{r join intervention_id to intervention name}

kwic_interventions <- unique(merge(x=interventions, by.x="intervention_id", all.x=TRUE, y=kwic_interventions, by.y = "intervention_id", incomparables = NA))

```

```{r join NCIt IDs to kwic interventions}
kwic_interventions <- unique(merge(x=kwic_interventions, by.x="intervention_synonym", all.x=TRUE, y=NCIt_Pharmacologics, by.y = "Synonyms", incomparables = NA))

```

```{r drop redundant rows in kwic interventions}
kwic_interventions <- unique(dplyr::select(kwic_interventions, nct_id, intervention_id, intervention_name, "NCIt_id"="ID", PreferredTerm, "Mechanism"="Parent_synonym"))

```

```{r join kegg targets to kwic interventions}

## seems to join NA's in each column?!...
## see https://community.rstudio.com/t/why-does-na-match-na-when-joining-two-dataframes/28785/2

kwic_interventions <- unique(merge(x=kwic_interventions, by.x="NCIt_id", all.x=TRUE, y=unique(dplyr::select(kegg_drugs, NCIt_drug_id, target_symbol)), by.y = "NCIt_drug_id", incomparables = NA))

## select and reorder columns
kwic_interventions <- unique(dplyr::select(kwic_interventions, nct_id, intervention_id, intervention_name, NCIt_id, PreferredTerm,target_symbol, Mechanism))

interventions <- kwic_interventions
```

```{r process intervention names}
# ## duplicate intervention name
# interventions$intervention_name_processed <- interventions$intervention_name
# ## convert to lowercase 
# interventions$intervention_name_processed <- tolower(interventions$intervention_name_processed)
# 
# ## split on words related to combinations of therapy
# combinations_pattern = "\\bwith\\b|\\band\\b|\\/|\\+|\\bplus\\b|\\,|\\bcombination\\b"
# interventions$intervention_name_processed <- strsplit(interventions$intervention_name_processed, split = combinations_pattern)
# interventions <- as.data.frame(unnest(data = interventions, intervention_name_processed))
# 
# ## split on brackets (e.g. values like "roniciclib (bay1000394)" and "e39 peptide (100mcg)")
# brackets_pattern <- "\\(|\\)"
# interventions$intervention_name_processed <- strsplit(interventions$intervention_name_processed, split = brackets_pattern)
# interventions <- as.data.frame(unnest(data = interventions, intervention_name_processed))
# 
# ## split on any substrings related to dose
# ## matches any digit, optionally followed by space, followed by "mg"
# dose_pattern <- "[0-9]+ ?mg"
# interventions$intervention_name_processed <- strsplit(interventions$intervention_name_processed, split = dose_pattern)
# interventions <- as.data.frame(unnest(data = interventions, intervention_name_processed))
# 
# ## trim excess whitespace
# interventions$intervention_name_processed <- str_squish(interventions$intervention_name_processed)
# 
# ## replace terms related to placebo with "placebo"
# interventions$intervention_name_processed[grep(pattern = "placebo|dummy", x=interventions$intervention_name_processed, ignore.case = TRUE)] <- "placebo"
# 
# # design_group_interventions$intervention_name[grep(pattern = "placebo|dummy", x=design_group_interventions$intervention_name, ignore.case = TRUE)] <- "Placebo"
```
  
#### **Map study interventions to NCIt pharmacologics**  
  
```{r join interventions to NCIt pharmacologics}
# ## create a temporary copy of NCIt pharmacologics
# NCIt_Pharmacologics_temp <- unique(dplyr::select(NCIt_Pharmacologics, "NCIt_ID"="ID", Synonyms, PreferredTerm, "Mechanism"="Parent_synonym"))
# ## convert synonyms to lower case for joining
# NCIt_Pharmacologics_temp$Synonyms <- tolower(NCIt_Pharmacologics_temp$Synonyms)
# 
# NCIt_Pharmacologics_temp <- unique(dplyr::select(NCIt_Pharmacologics, "NCIt_ID"="ID", Synonyms, PreferredTerm, "Mechanism"="Parent_synonym"))
# 
# interventions <- merge(x=interventions, by.x = "intervention_name_processed", all.x=TRUE, 
#                        y=NCIt_Pharmacologics_temp, by.y = "Synonyms")
# 
# ## delete temporary copy
# rm(NCIt_Pharmacologics_temp)
# 
# ## select and reorder columns
# ## remove duplicates
# interventions <- unique(dplyr::select(interventions, nct_id, intervention_id, intervention_name, NCIt_ID, PreferredTerm, Mechanism))
# 

```



```{r omit cancerstudies with unmapped interventions}
# cancerStudies <- unique(dplyr::filter(cancerStudies, nct_id %in% interventions$nct_id))



```

  
#### **write indexed cancer studies to database**  
  
Cancer study information is saved to the cancerStudies table:  
  
  
`r formattable(head(cancerStudies))`  
    
  
```{r write cancerStudies to database}
## create as a table in database
dbWriteTable(conn = con,name = "cancerStudies", value = cancerStudies, overwrite=TRUE)

## check it has saved
dbListTables(con)


```


#### **Write indexed interventions to database**  
  
Study interventions (including mapping to NCIt entities and KEGG target genes where applicable) are saved to the interventions table:  
  
`r formattable(head(interventions))`


```{r write interventions to database}
## create as a table in database
dbWriteTable(conn = con,name = "interventions", value = interventions, overwrite=TRUE)

## check it has saved
dbListTables(con)

```

#### **Map UK cancer study sites to postcodes**  
  
```{r download facilities}

UKfacilitiesQ <- paste0("select f.nct_id, f.status AS facility_status, f.name AS facility_name, f.city, f.zip 
from facilities f
where f.nct_id in (",
"", studyIDsForSQL,
") AND lower(f.country) = 'united kingdom'")

## get criteria from clinicaltrials.gov
uk_facilities <- dbGetQuery(conn2,UKfacilitiesQ)



```

```{r map postcodes to lat and long}
## convert postcodes to lowercase for join
uk_postcodes$postcode_lower <- tolower(uk_postcodes$postcode)
uk_facilities$zip_lower <- tolower(uk_facilities$zip)

## merge
uk_facilities <- merge(x=uk_facilities, by.x = "zip_lower", all.x = TRUE, y=uk_postcodes, by.y="postcode_lower")

## select and reorder columns
uk_facilities <- unique(dplyr::select(uk_facilities, nct_id, facility_name, status, city, latitude, longitude))

## delete uk_postcodes object from memory
rm(uk_postcodes)
```

```{r map cities to lat and long}

## get a list of cities that are still missing lat, long values 
missing_cities <- data.frame(verbatim = as.character(unique(uk_facilities$city[is.na(uk_facilities$latitude)])))

## need to process 
missing_cities$processed <- as.character(missing_cities$verbatim)
missing_cities$processed <- strsplit(x=missing_cities$processed, split = ",")
missing_cities <- as.data.frame(unnest(data = missing_cities, processed))
missing_cities$processed <- str_squish(missing_cities$processed)
missing_cities$processed <- paste0(missing_cities$processed, ", ", configuration$country)


## use tidygeocoder (MIT licence)
## need append country from config file after city name...
geocoder_addresses <- as.data.frame(tidygeocoder::geo(address = unique(missing_cities$processed), method = 'osm'))

## join to missing cities
missing_cities <- merge(x=missing_cities, by.x="processed", y=geocoder_addresses, by.y="address")

## join to uk_facilities
uk_facilities <- merge(x=uk_facilities, by.x="city", all.x=TRUE, y=dplyr::select(missing_cities, verbatim, "geo_lat"="lat", "geo_long"="long"), by.y = "verbatim")


## replace the missing latitude and longitude values with the geocoder values
uk_facilities$latitude[is.na(uk_facilities$latitude)] <- uk_facilities$geo_lat[is.na(uk_facilities$latitude)]

uk_facilities$longitude[is.na(uk_facilities$longitude)] <- uk_facilities$geo_long[is.na(uk_facilities$longitude)]

## select and reorder columns
uk_facilities <- unique(dplyr::select(uk_facilities, nct_id, facility_name, status, city, latitude, longitude))
```
  
A table of study sites, their statuses and lat, long values for their location has been saved to the uk_facilities table:  
  
`r formattable(head(uk_facilities))`  
  
  
  
```{r write uk facilities to database}
## create as a table in database
dbWriteTable(conn = con,name = "uk_facilities", value = uk_facilities, overwrite=TRUE)

## check it has saved
dbListTables(con)

```

#### **Get eligibility criteria**  
  
```{r get eligibility criteria from ct}
getEligibilities <- paste0("select * 
from eligibilities 
where nct_id in (",
"", studyIDsForSQL,
")")

## get criteria from clinicaltrials.gov
eligibilities <- dbGetQuery(conn2,getEligibilities)

```

```{r split into individual eligibility criteria}

## split into individual criteria on single line breaks
eligibilities$criteria <- strsplit(eligibilities$criteria, split = "\n")
## unnest so each criterion gets its own row
eligibilities <- as.data.frame(unnest(data = eligibilities, cols = criteria))
## drop any empty elements
eligibilities <- eligibilities[eligibilities$criteria != "", ] ## drop empty elements

```

```{r add an index column to eligibilities}
## we will add an index column that uniquely identifies each criterion
eligibilities <- eligibilities %>% group_by(nct_id) %>% mutate(criterion_index = paste0(nct_id, "_", row_number())) %>% as.data.frame()


```

```{r classify as inclusion exclusion criteria}

## add a column to indicate criterion type
eligibilities$criterion_type <- NA

## set first value as "INCLUSION"
eligibilities$criterion_type[1] <- "INCLUSION"

## tag first criterion that equals "inclusion criteria:" (case-insensitive, with or without colon)
eligibilities$criterion_type[grep(pattern = "inclusion criteria:?$", x=eligibilities$criteria, ignore.case = TRUE)] <- "INCLUSION"

## tag first criterion that equals "exclusion criteria:" (case-insensitive, with or without colon)
eligibilities$criterion_type[grep(pattern = "exclusion criteria:?$", x=eligibilities$criteria, ignore.case = TRUE)] <- "EXCLUSION"

## fill "down" using the tdiyr::fill() function
eligibilities <- tidyr::fill(data=eligibilities, criterion_type, .direction="down")

```

```{r impute missing values for gender}
## for gender, replace "All" with "Male|Female"
eligibilities$gender[eligibilities$gender=="All"] <- "Male|Female"
## do the same for missing values
eligibilities$gender[is.na(eligibilities$gender)] <- "Male|Female"

```

```{r impute missing values for minimum age}

## for minimum ages are all either "xxx months", "1 year", "xxx years" or "N/A"
## convert all values to years...
min_age_month_indices <- grep(pattern = "month", x=eligibilities$minimum_age, ignore.case = TRUE)
## trim off first space and everything after
eligibilities$minimum_age[min_age_month_indices] <- gsub(pattern = " .*", replacement = "", x=eligibilities$minimum_age[min_age_month_indices])
## convert to numeric
# eligibilities$minimum_age[min_age_month_indices] <- as.numeric(eligibilities$minimum_age[min_age_month_indices])
## divide by 12 to get min age in years
eligibilities$minimum_age[min_age_month_indices] <- round(as.numeric(eligibilities$minimum_age[min_age_month_indices])/12, digits = 1)

## just trim off " years" from min ages in years
min_age_year_indices <- grep(pattern = "year", x=eligibilities$minimum_age, ignore.case = TRUE)
eligibilities$minimum_age[min_age_year_indices] <- gsub(pattern = " .*", replacement = "", x=eligibilities$minimum_age[min_age_year_indices])

## impute missing values with zero
eligibilities$minimum_age[is.na(eligibilities$minimum_age)] <- 0
eligibilities$minimum_age[eligibilities$minimum_age == "N/A"] <- 0

## convert to numeric
eligibilities$minimum_age <- as.numeric(eligibilities$minimum_age)

```

```{r impute missing values for maximum age}


## for maximum age, all values are in years, or NA or "N/A"
# to test... 
## unique(grep(pattern = "year", x=eligibilities$maximum_age, ignore.case = TRUE, value = TRUE, invert = TRUE))

## trim off first space and everything after
eligibilities$maximum_age <- gsub(pattern = " .*", replacement = "", x=eligibilities$maximum_age)

## impute missing values with 120
eligibilities$maximum_age[is.na(eligibilities$maximum_age)] <- 120
eligibilities$maximum_age[eligibilities$maximum_age == "N/A"] <- 120

## convert to numeric
eligibilities$maximum_age <- as.numeric(eligibilities$maximum_age)

```

##### **Write eligibility criteria to database**  
  
  
```{r write eligibilities to database}
## create as a table in database
dbWriteTable(conn = con,name = "eligibilities", value = eligibilities, overwrite=TRUE)

## check it has saved
dbListTables(con)


## delete indices
rm(min_age_year_indices)
rm(min_age_month_indices)

```
  
Individual eligibility criteria for all studies has been written to the eligibilities table:  
  
`r formattable(head(eligibilities))`  
  
  
### **Get design group information**  
  
#### **Get design groups (study arms)**  
  
```{r get design groups from ct}
getDesignGroupsQ <- paste0("select dg.nct_id, dg.id as dg_id, dg.title as dg_title, dg.description as dg_description, dg.group_type as dg_group_type, dgi.intervention_id
from design_groups dg
left join design_group_interventions dgi on dg.id = dgi.design_group_id 
where dg.nct_id in (",
"", studyIDsForSQL,
")")

## get criteria from clinicaltrials.gov
design_groups <- dbGetQuery(conn2,getDesignGroupsQ)

## NOTE, SOME STUDIES HAVE NO DESIGN GROUPS SPECIFIED, BUT MAY HAVE RESULT GROUPS SPECIFIED

```

```{r concatenate titles and descriptions for design groups}

design_groups$dg_title_description <- paste(design_groups$dg_title, design_groups$dg_description, sep = ": ")

## replace mu (micro) symbols with u as this causes mapping function to barf
design_groups$dg_title_description <- gsub(pattern = "\U00B5|\U03BC", replacement = "u", x=design_groups$dg_title_description)

```


### **Get result groups**  
  
#### **Get result groups**  
  
```{r get result groups}
getResultGroupsQ <- paste0("select rg.nct_id, rg.id as rg_id, ctgov_group_code, result_type, rg.title as rg_title, rg.description as rg_description
from result_groups rg 
where rg.nct_id in (",
"", studyIDsForSQL,
")")

## get criteria from clinicaltrials.gov
result_groups <- dbGetQuery(conn2,getResultGroupsQ)

```
    
```{r concatenate titles and descriptions for result groups}

result_groups$rg_title_description <- paste(result_groups$rg_title, result_groups$rg_description, sep = ": ")

## replace mu (micro) symbols with u as this causes mapping function to barf
result_groups$rg_title_description <- gsub(pattern = "\U00B5|\U03BC", replacement = "u", x=result_groups$rg_title_description)

```
  
  
### **Map result groups to design groups**  
  
Interventions are linked to design groups (study arms).   
  
Results are reported for result groups, but these are not explicitly mapped to design groups. In order to know how outcomes relate to treatment, we need to map from result groups to design groups.  
  
This is not always obvious...  
  
* Where a study has only a single design group, we will map all result groups for that study to that design group.  
* If a result group title exactly matches a design group title, we will associate interventions based on the design group interventions.  
* For remaining studies, we will predict which design group each result group belongs to based on comparison of the titles and descriptions for design and result groups.    

```{r create empty dataframe that will hold predicted mappings}

predictions <- data.frame(nct_id = character(0),
                          rg_id = character(0), 
                          predicted_design_group = character(0)
                          )


```

```{r create a variable that will hold unmapped result groups}

unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=predictions$rg_id)


```

#### **Map result groups for single arm studies**  

```{r studies with 1 design group}

single_dg_studies <- design_groups %>%
  group_by(nct_id) %>%
  summarise(
    number_dgs = length(unique(dg_id)), 
    predicted_design_group = paste(unique(dg_id), collapse = "; ")
  ) %>% 
  filter(number_dgs == 1) %>%
  as.data.frame()


## join to result groups on nct_id... 
## this means all result groups for that study will be mapped to the single design group
single_dg_studies <- merge(x=single_dg_studies, by.x="nct_id", y=result_groups, by.y = "nct_id")

## just select the columns (and order) needed to bind to predictions
single_dg_studies <- unique(dplyr::select(single_dg_studies,names(predictions)))

## rowbind onto predictions table
predictions <- unique(rbind(predictions, single_dg_studies))

## update list of unmapped result groups ids
unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=predictions$rg_id)

```

#### **Map result groups based on exact match between group titles**  
  
```{r studies with matching design and result group titles}

matched_group_titles <- unique(dplyr::select(design_groups, nct_id, "predicted_design_group" = "dg_id", dg_title))

## convert title to lowercase
matched_group_titles$dg_title <- tolower(matched_group_titles$dg_title)

## map result group title to lowercase
result_groups$rg_title_lower <- tolower(result_groups$rg_title)

## merge
matched_group_titles <- unique(merge(x=matched_group_titles, by.x = c("nct_id", "dg_title"), y=dplyr::select(result_groups, nct_id, rg_id, rg_title_lower), by.y = c("nct_id", "rg_title_lower")))

## make names match predictions
matched_group_titles <- unique(dplyr::select(matched_group_titles, names(predictions)))

## rowbind onto predictions
predictions <- unique(rbind(predictions, matched_group_titles))

## update list of unmapped result groups ids
unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=predictions$rg_id)
```
  
#### **Assign interventions based on similarity between design, result group descriptions**   
  
```{r filter result groups and retain only outcomes and events}
## NOTE SOME RESULT GROUPS ARE "TOTAL" i.e. total values for all groups
## these will not be specified as design groups
## if we try to map these onto a design group, the mapping is likely to barf
## WE WILL EXCLUDE THESE GROUPS AT THIS POINT by filtering result groups and retaining only those where result_type = "Outcome" or "Reported Event"... 

result_groups <- unique(dplyr::filter(result_groups, result_type %in% c("Outcome", "Reported Event")))

## update list of unmapped result groups ids
unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=predictions$rg_id)
```

```{r define stopwords}
stopwords <- as.data.frame(tidytext::get_stopwords())
```

For each unmapped design group, we will create a document-term matrix from design group title and description, then use this to generate a model to predict design group ids for document-term matrices based on result group titles and descriptions.  
  
We will specify design group titles and interventions as custom tokens when tokenising.  

```{r define function to create document term matrix}

## define a function that will... 
# accept custom tokens to be included in tokenisation
# create document-term matrix

create_dtm <- function(dataframe, text_column, id_column, custom_tokens) {
  ## get the text column to be used
  text_column_num <- which(names(dataframe)==text_column)
  text <- dataframe[ , text_column_num]
  ## remove anything that is not a number or letter...
  text <- str_squish(str_replace_all(string = text, "[^a-zA-Z0-9]", replacement = " "))
  ## overwrite the text column  
  dataframe[ , text_column_num] <- text

  
  ## 1. TOKENISE THE TEXT COLUMN
  ## need to tokenise using corpus function, as this allows drug synonyms, inc multi word synonyms, to be specified upfront as tokens so they don't get split
  dataframe$word <- as.list(corpus::text_tokens(x=dataframe[ , text_column_num], filter= corpus::text_filter(combine = custom_tokens, map_case=TRUE, connector="_", drop_punct=TRUE )))
  ## unnest
  dataframe <- as.data.frame(unnest(data = dataframe, word)) 
  ## this function does insist on replacing whitespace with a character (here, underscore), so need to swap that back to whitespace
  # dataframe$word <- gsub(pattern = "_", replacement = " ", x=dataframe$word)
  ## remove stopwords
  # dataframe <- anti_join(x=dataframe, y=stopwords)
  
  ## 2. CREATE DOCUMENT-TERM MATRIX
  ## count each word in each description
  dataframe <- dataframe %>% 
    group_by_at(id_column) %>%
    count(word, sort=FALSE) %>%
    ungroup() %>%
    as.data.frame()
  ## use reshape2::dcast so get a dataframe as a result
  dataframe <- reshape2::dcast(data=dataframe, formula = as.formula(paste(id_column, "~ word")), value.var = "n")
  ## convert NA to zero
  dataframe <- dataframe %>% mutate_all(~replace(., is.na(.), 0))
  ## convert id to factor
  dataframe[ , which(names(dataframe)==id_column)] <- as.factor(dataframe[ , which(names(dataframe)==id_column)])
  
  ## 3. RETURN DOCUMENT-TERM MATRIX
  return(dataframe)
}

```

```{r loop through remaining unmapped result groups}

## we will perform mapping per-study, not per result group... 

## get a list of studies with unmapped result groups
unmapped_study_ids <- unique(result_groups$nct_id[result_groups$rg_id %in% unmapped_result_group_ids])

tic("loop through unmapped result groups and predict")
for(i in 1:length(unmapped_study_ids)) {
  #print(paste0(i, "/", length(unmapped_study_ids)))
  study_id <- unmapped_study_ids[i]
  
  #study_id <- unique(unmapped_design_groups$nct_id)[i]
  #print(study_id)
  
  temp_unmapped_dgs <- unique(dplyr::filter(design_groups, nct_id == study_id))
  ## if no design groups, skip to next study
  if(nrow(temp_unmapped_dgs)==0) next
  
  ## drop unnecessary columns
  temp_unmapped_dgs <- unique(dplyr::select(temp_unmapped_dgs, nct_id, dg_id,dg_title, dg_title_description))
  
  ## get study interventions (verbatim) to use as custom tokens
  study_interventions_verbatim <- unique(interventions$intervention_name[interventions$nct_id==study_id])
  #print(study_interventions_verbatim)
  
  ## get synonyms for study interventions to use as custom tokens
  study_interventions_NCItID <- unique(na.omit(interventions$NCIt_ID[interventions$nct_id==study_id]))
  #print(study_interventions_NCItID)
  
  study_interventions_synonyms <- unique( NCIt_Pharmacologics$Synonyms[NCIt_Pharmacologics$ID %in% study_interventions_NCItID])
  #print(study_interventions_synonyms)
  
  ## get design group titles to use as custom tokens
  design_group_titles <- temp_unmapped_dgs$dg_title 
  #print(design_group_titles)
  
  tokens <- unique(c(study_interventions_synonyms, design_group_titles,study_interventions_verbatim))
  
  ## create document term matrix
  unmapped_dgs_dtm <- create_dtm(dataframe = temp_unmapped_dgs, text_column = "dg_title_description", id_column = "dg_id", custom_tokens = tokens)
  #print(unmapped_dgs_dtm)
  
  temp_unmapped_rgs <- unique(dplyr::filter(result_groups, nct_id == study_id))
  ## drop unnecessary columns
  temp_unmapped_rgs <- unique(dplyr::select(temp_unmapped_rgs, nct_id, rg_id,rg_title, rg_title_description))
  
  ## create DTM for result group descriptions
  unmapped_rgs_dtm <- create_dtm(dataframe = temp_unmapped_rgs, text_column = "rg_title_description", id_column = "rg_id", custom_tokens = tokens)
  #print(unmapped_rgs_dtm)
  ## make names valid, otherwise rpart will barf...
  names(unmapped_dgs_dtm) <- gsub(" ", "_", names(unmapped_dgs_dtm))
  names(unmapped_rgs_dtm) <- gsub(" ", "_", names(unmapped_rgs_dtm))
  
  ## get those column names that are common to both dtms
  common_terms <- intersect(names(unmapped_dgs_dtm), names(unmapped_rgs_dtm))
  
  ## drop any common_terms that are numbers
  common_terms <- common_terms[is.na(as.numeric(common_terms))]
  
  ## drop any common terms that are stopwords
  common_terms <- common_terms[!(common_terms %in% stopwords$word)]
  
  ## if no common terms, skip to next study
  if(length(common_terms)==0) next
  
  ## drop non-overlapping columns from DGs_dtm
  unmapped_dgs_dtm <- dplyr::select(unmapped_dgs_dtm, dg_id, all_of(common_terms))
  #print(unmapped_dgs_dtm)
  
  tryCatch({
            ## create decision tree model
            modFit <- rpart::rpart(formula = dg_id ~., method = "class", data = unmapped_dgs_dtm, control =rpart.control(minsplit = 1,minbucket=1, cp=0))
            ## (optional) print tree
            #rpart.plot(modFit)
            ## predict design group for each result group
            study_predictions <- data.frame(nct_id = as.character(study_id),
                          rg_id = as.character(unmapped_rgs_dtm$rg_id), 
                          predicted_design_group = as.character(predict(object = modFit, unmapped_rgs_dtm, type = "class"))
                          )
            #print(study_predictions)
            
            }, error=function(cond) {
              return(study_predictions <- data.frame(nct_id = study_id,
                                                     result_group_id = unmapped_rgs_dtm$rg_id,
                                                     predicted_design_group = NA
                          ))})
  
  ## row bind study predictions onto predictions table
  predictions <- unique(rbind(predictions, study_predictions))
  
  
}
toc()


## update list of unmapped result groups ids
unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=predictions$rg_id)


```

```{r join descriptions to sanity check}
predictions$nct_id <- as.character(predictions$nct_id)
predictions$rg_id <- as.character(predictions$rg_id)
predictions$predicted_design_group <- as.character(predictions$predicted_design_group)

## join result group titles and descriptons
predictions <- merge(x=predictions, by.x=c("nct_id", "rg_id"), y=dplyr::select(result_groups, nct_id, rg_id, rg_title_description), by.y=c("nct_id", "rg_id"))

## join design group titles and descriptions
predictions <- merge(x=predictions, by.x=c("nct_id", "predicted_design_group"), y=dplyr::select(design_groups, nct_id, dg_id, dg_title_description), by.y=c("nct_id", "dg_id"))




```
  
`r length(unmapped_result_group_ids)` of `r length(unique(result_groups$rg_id))` result groups have not been mapped to a predicted design group.  
  
```{r write predictions to database}
## create as a table in database
dbWriteTable(conn = con,name = "predictions", value = predictions, overwrite=TRUE)

## check it has saved
dbListTables(con)

## delete unmapped study ids
rm(unmapped_study_ids)

```

### **Get outcome data**  
  
  
```{r get outcome measurements table}

getOutcome_measurements <- paste0("select *
from outcome_measurements 
where nct_id in (",
"", studyIDsForSQL,
")")
# 
## get data from clinicaltrials.gov
outcome_measurements <- dbGetQuery(conn2, getOutcome_measurements)
 


```
  
#### **Overall survival**  
  
* First, filter the outcome measurements table and retain rows where the outcome measurement title contains the pattern "*\\bOS\\b|\\boverall survival\\b*"  
  * ("\\b" enforces whole-word match)  
* Second, filter and retain rows where units contain the pattern "*days|weeks|months|years*"  
* Third, convert units to months (rounded to 1 decimal place):  
  * Where units = days, divide parameter values and confidence limits by 28  
  * Where units = weeks, divide parameter values and confidence limits by 4  
  * Where units = years, multiply parameter values and confidence limits by 12  
  
* **Note we have not filtered according to *parameter type*, and so values may be median (most common), mean, min, max or any other summary statistic.**  
  
  
```{r filter and return only OS data}

## first filter on on presence of OS pattern
OS_pattern <- "\\bOS\\b|\\boverall survival\\b"
overall_survival <- outcome_measurements[grep(pattern = OS_pattern, x=outcome_measurements$title, ignore.case = TRUE), ]

## second, filter on units
# overall_survival <- overall_survival[grep(pattern = "days|weeks|months|years", x=overall_survival$units, ignore.case = TRUE), ]
overall_survival$units <- tolower(overall_survival$units)
overall_survival <- unique(dplyr::filter(overall_survival, units %in% c("days", "weeks", "months", "years")))

## remove the param_value column
overall_survival <- dplyr::select(overall_survival, -c(param_value))

## convert days to months
## ASSUME 28 DAYS IN A MONTH
# convert point estimates
overall_survival$param_value_num[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$param_value_num[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)]/28, digits = 1)
# convert LL
overall_survival$dispersion_lower_limit[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_lower_limit[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)]/28, digits = 1)
# convert UL
overall_survival$dispersion_upper_limit[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_upper_limit[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)]/28, digits = 1)
# reset units 
overall_survival$units[grep(pattern = "days", x=overall_survival$units, ignore.case = TRUE)] <- "months"



## convert weeks to months
## ASSUME 4 WEEKS IN A MONTH
# convert point estimates
overall_survival$param_value_num[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$param_value_num[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)]/4, digits = 1)
# convert LL
overall_survival$dispersion_lower_limit[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_lower_limit[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)]/4, digits = 1)
# convert UL
overall_survival$dispersion_upper_limit[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_upper_limit[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)]/4, digits = 1)
# reset units 
overall_survival$units[grep(pattern = "weeks", x=overall_survival$units, ignore.case = TRUE)] <- "months"



## convert years to months
## ASSUME 12 MONTHS IN A YEAR
# convert point estimates
overall_survival$param_value_num[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$param_value_num[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)]*12, digits = 1)
# convert LL
overall_survival$dispersion_lower_limit[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_lower_limit[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)]*12, digits = 1)
# convert UL
overall_survival$dispersion_upper_limit[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)] <- round(overall_survival$dispersion_upper_limit[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)]*12, digits = 1)
# reset units 
overall_survival$units[grep(pattern = "years", x=overall_survival$units, ignore.case = TRUE)] <- "months"


## add a column to indicate these are all OS data
overall_survival$outcome_controlled <- "Overall survival"
```
  
Overall survival measurements have been written to the overall_survival table:  
  
`r formattable(head(overall_survival))`   
  
  
```{r write OS table to DB}
## create as a table in database
dbWriteTable(conn = con,name = "overall_survival", value = overall_survival, overwrite=TRUE)

## check it has saved
dbListTables(con)

```

  
This filtering leaves us with the following outcomes:  
* **`r unique(overall_survival$title)`**  
  
#### **Get progression-free survival data**  
     
* Filter and retain outcome measurements where outcome title includes the pattern "*PFS|progression-free survival|progression free survival*".  
* Filter and retain rows where units include the pattern "*days|weeks|months|years*"  
* Convert units to months (as for OS, above)  
  
  

  
```{r filter and return only PFS data}

## first filter on on presence of OS pattern
PFS_pattern <- "PFS|progression-free survival|progression free survival"
PFS <- outcome_measurements[grep(pattern = PFS_pattern, x=outcome_measurements$title, ignore.case = TRUE), ]

## second, filter on units
# PFS <- PFS[grep(pattern = "days|weeks|months|years", x=PFS$units, ignore.case = TRUE), ]
PFS$units <- tolower(PFS$units)
PFS <- unique(dplyr::filter(PFS, units %in% c("days", "weeks", "months", "years")))


## remove the param_value column
PFS <- dplyr::select(PFS, -c(param_value))

## convert days to months
## ASSUME 28 DAYS IN A MONTH
# convert point estimates
PFS$param_value_num[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)] <- round(PFS$param_value_num[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)]/28, digits = 1)
# convert LL
PFS$dispersion_lower_limit[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_lower_limit[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)]/28, digits = 1)
# convert UL
PFS$dispersion_upper_limit[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_upper_limit[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)]/28, digits = 1)
# reset units 
PFS$units[grep(pattern = "days", x=PFS$units, ignore.case = TRUE)] <- "months"



## convert weeks to months
## ASSUME 4 WEEKS IN A MONTH
# convert point estimates
PFS$param_value_num[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)] <- round(PFS$param_value_num[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)]/4, digits = 1)
# convert LL
PFS$dispersion_lower_limit[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_lower_limit[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)]/4, digits = 1)
# convert UL
PFS$dispersion_upper_limit[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_upper_limit[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)]/4, digits = 1)
# reset units 
PFS$units[grep(pattern = "weeks", x=PFS$units, ignore.case = TRUE)] <- "months"



## convert years to months
## ASSUME 12 MONTHS IN A YEAR
# convert point estimates
PFS$param_value_num[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)] <- round(PFS$param_value_num[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)]*12, digits = 1)
# convert LL
PFS$dispersion_lower_limit[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_lower_limit[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)]*12, digits = 1)
# convert UL
PFS$dispersion_upper_limit[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)] <- round(PFS$dispersion_upper_limit[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)]*12, digits = 1)
# reset units 
PFS$units[grep(pattern = "years", x=PFS$units, ignore.case = TRUE)] <- "months"

## add a column to indicate these are all PFS data
PFS$outcome_controlled <- "Progression free survival"
```
  

      
    
  
This filtering leaves us with the following outcomes:  
* **`r unique(PFS$title)`**  
    
Progression-free survival measurements have been written to the PFS table:  
  
`r formattable(head(PFS))`   


```{r write PFS table to DB}
## create as a table in database
dbWriteTable(conn = con,name = "PFS", value = PFS, overwrite=TRUE)

## check it has saved
dbListTables(con)

```


### **Get adverse event data**  
  
#### **Individual adverse event counts**  
  
  
  
Individual adverse event data are stored in the *reported_events* table.  
  

```{r get reported event counts}

getAEcounts <- paste0("select *
from reported_events 
where nct_id in (",
"", studyIDsForSQL,
")")
# 
## get criteria from clinicaltrials.gov
AE_counts <- dbGetQuery(conn2, getAEcounts)


## order on subjects_affected descending
AE_counts <- AE_counts[order(AE_counts$subjects_affected, decreasing = TRUE), ]

# kbl(head(AE_counts), format = "html",escape = FALSE) %>%
#   kable_styling(fixed_thead = T, bootstrap_options = c("striped", "hover", "condensed")) %>%
#   scroll_box(width = "125%", height = "200px")
```
  
  
Details include number of subjects affected and number of subjects at risk.  
  
We can derive *percent_affected* based on subjects_affected / subjects_at_risk...  

  
```{r derive AE rates}
AE_counts$percent_affected <- round(((AE_counts$subjects_affected * 100)/ AE_counts$subjects_at_risk), digits = 1)


kbl(head(AE_counts), format = "html",escape = FALSE) %>%
  kable_styling(fixed_thead = T, bootstrap_options = c("striped", "hover", "condensed")) %>%
  scroll_box(width = "125%", height = "200px")


```
  

```{r write AE counts table to DB}
## create as a table in database
dbWriteTable(conn = con,name = "AE_counts", value = AE_counts, overwrite=TRUE)

## check it has saved
dbListTables(con)

```


#### **Combined adverse event counts (e.g. total, any adverse event)**  
  
         
  
Total event counts are also stored in the *reported_event_totals* table.  
  
These data include summary counts such as *Total, serious adverse events*, *Total, other adverse events* etc.  
  


```{r get event totals}

getAEtotals <- paste0("select *
from reported_event_totals 
where nct_id in (",
"", studyIDsForSQL,
")")
# 
## get criteria from clinicaltrials.gov
AE_totals <- dbGetQuery(conn2, getAEtotals)

```
  
Number of subjects at risk and affected are also included, so we can derive *percent_affected*.  
  
```{r derive percent affected}

## derive percent affected
AE_totals$percent_affected <- round((AE_totals$subjects_affected * 100)/ AE_totals$subjects_at_risk, digits = 1)

kbl(head(AE_totals), format = "html",escape = FALSE) %>%
  kable_styling(fixed_thead = T, bootstrap_options = c("striped", "hover", "condensed")) %>%
  scroll_box(width = "125%", height = "200px")
```



```{r write AE totals table to DB}
## create as a table in database
dbWriteTable(conn = con,name = "AE_totals", value = AE_totals, overwrite=TRUE)

## check it has saved
dbListTables(con)

```








### **Index trial populations**  
  
See also https://tutorials.quanteda.io/basic-operations/corpus/corpus/ for workflow from quanteda...  
  
We will index each of: eligibility criteria, design groups (titles and descriptions) and result groups (titles and descriptions)...  
  
The process is as follows:  
   
* First, create a tidy table containing the relevant text, plus identifiers that will allow us to rejoin the results...  
  * For criteria, we will use the verbatim criteria as text  
  * For design and result groups, we will use concatenation of title and description  
  
  
```{r create tidy table of criteria plus dgs plus rgs}

text_for_indexing <- data.frame(nct_id = character(0), 
                                id=character(0), 
                                id_type = character(0), 
                                text = character(0))

    
eligibilities_for_indexing <- eligibilities %>% 
         # mutate(id_type="criterion_index") %>%
         dplyr::select(nct_id, "id"="criterion_index","id_type"="criterion_type","text"="criteria") %>%
         unique()

design_groups_for_indexing <- design_groups %>% 
         mutate(id_type="design_group") %>%
         dplyr::select(nct_id, "id"="dg_id",id_type,"text"="dg_title_description") %>%
         unique()

result_groups_for_indexing <- result_groups %>% 
         mutate(id_type="result_group") %>%
         dplyr::select(nct_id, "id"="rg_id",id_type,"text"="rg_title_description") %>%
         unique()

text_for_indexing <- rbind(eligibilities_for_indexing, design_groups_for_indexing, result_groups_for_indexing)

## clean up
rm(eligibilities_for_indexing)
rm(design_groups_for_indexing)
rm(result_groups_for_indexing)
```
  
* Second, create a corpus from the tidy table...  
  

```{r create corpus}
# tic("create eligibilities corpus")
# eligibilities_corpus <-  quanteda::corpus(x=unique(dplyr::select(eligibilities, nct_id, criterion_index, criteria, criterion_type)),
#                                           text_field = "criteria", 
#                                           docid_field = "criterion_index",
#                                           unique_docnames = FALSE)
# toc()


```
  
```{r create populations corpus}
 

tic("create populations_corpus")
populations_corpus <-  quanteda::corpus(x=text_for_indexing,
                                          text_field = "text", 
                                          docid_field = "id",
                                          unique_docnames = FALSE)
toc()

```
  
* Third, tokenise the corpus...  
  

```{r tokenise the corpus}
# tic("tokenise eligibilities corpus")
# eligibilities_tokens <- tokens(eligibilities_corpus, remove_punct=TRUE, padding = FALSE, split_hyphens = TRUE)
# toc()
```

```{r tokenise populations_corpus}

tic("tokenise populations_corpus")
populations_tokens <- tokens(populations_corpus, remove_punct=TRUE, padding = FALSE, split_hyphens = TRUE)
toc()

```
  
* Fourth, remove stopwords...  
  

```{r remove stopwords}
# tic("remove stopwords")
# eligibilities_tokens <- tokens_select(x=eligibilities_tokens, pattern = stopwords("en"), selection = "remove", padding = FALSE)
# toc()
```

```{r remove stopwords from populations_tokens}
tic("remove stopwords from populations_tokens")
populations_tokens <- tokens_select(x=populations_tokens, pattern = stopwords("en"), selection = "remove", padding = FALSE)
toc()

```

#### **Index on genetic features**  
  
We will get a "bag of words" (excluding stopwords) surrounding human gene names (inc synonyms) within a defined window on either side (default=5).  


```{r get context words surrounding gene names}

# tic("get kwic for genes")
# kwic_genes <- as.data.frame(kwic(eligibilities_tokens, pattern =  unique(humanGenes$Aliases), window = 5, case_insensitive = FALSE))
# toc()
# #formattable(head(as.data.frame(kw_genes), 30))
# 
# ## concatenate pre, gene name and post tokens
# kwic_genes <- dplyr::mutate(kwic_genes, context = paste(pre,keyword, post, sep = " "))
# 
# ## select and rename columns
# kwic_genes <- dplyr::select(kwic_genes, "criterion_index"="docname", context, "gene_synonym"=pattern)

```

```{r get context words surrounding gene names in populations_tokens}

tic("get context words surrounding gene names in populations_tokens")
kwic_genes_populations <- as.data.frame(kwic(populations_tokens, pattern =  unique(humanGenes$Aliases), window = 5, case_insensitive = FALSE))
toc()

# tic("get context words surrounding gene names in populations_tokens")
# kwic_genes_populations <- kwic(populations_tokens, pattern =  unique(humanGenes$Aliases), window = 5, case_insensitive = FALSE)
# toc()
#formattable(head(as.data.frame(kw_genes), 30))

## concatenate pre, gene name and post tokens
kwic_genes_populations <- dplyr::mutate(kwic_genes_populations, context = paste(pre,keyword, post, sep = " "))

## select and rename columns
kwic_genes_populations <- dplyr::select(kwic_genes_populations, "id"="docname", context, "gene_synonym"=pattern)

```
  
We will join the Entrez symbols from humanGenes table...  
  
  
```{r join Entrez Symbols}
# 
# kwic_genes <- merge(x=kwic_genes, by.x="gene_synonym", y=dplyr::select(humanGenes, Symbol, Aliases), by.y = "Aliases")

```

```{r join Entrez Symbols to kwic_genes_populations}

kwic_genes_populations <- merge(x=kwic_genes_populations, by.x="gene_synonym", y=dplyr::select(humanGenes, Symbol, Aliases), by.y = "Aliases")

```
  
We will rejoin the metadata from text_for_indexing - **NB this relies on each type of identifier being unique (e.g. no matches between result group IDs and design group IDs)** - this appears to hold...  
  
  
```{r join verbatim criteria and nct_id}
kwic_genes_populations <- merge(x=text_for_indexing, by.x="id", y=kwic_genes_populations, by.y="id", incomparables=NA)

## rename and reorder columns
kwic_genes_populations <- unique(dplyr::select(kwic_genes_populations, nct_id, id, id_type,text, context, "match"="gene_synonym", "controlled_match"="Symbol"))

```
  
We will index the populations for genetic features by filtering and retaining only those texts that include a given pattern within the bag of words surrounding the gene name...  
  

```{r define function to index on pattern}
indexOnPattern <- function(dataframe, pattern, featureLabel) {
  ## get indices with matching pattern
  indices <- grep(pattern = pattern, x=dataframe$context, ignore.case = TRUE)
  ## subset dataframe
  dataframe <- dataframe[indices, ]
  ## add a column with featurelabel
  dataframe$feature <- featureLabel
  return(dataframe)
}

```
  
We will define patterns for each different alteration type...  
  
  
##### **Index on mutations**  
  
```{r define mutant pattern}
## define mutant pattern
mutant_pattern <- "mutat|mutant|defect|deficien|altera|altere|loss of function|loss-of-function|loss function"
```

For mutations, we will use the pattern `r mutant_pattern`.  
  

```{r index populations on mutations}

mutation_populations <- indexOnPattern(dataframe = kwic_genes_populations, pattern = mutant_pattern, featureLabel = "mutation")

## select and reorder columns for consistency with trialMatchDataRefresh
mutation_populations <- unique(dplyr::select(mutation_populations, match, nct_id, id, id_type, text, feature, controlled_match ))

```
  
  
Sample results:  
  
`r formattable(head(mutation_populations)) `  
  
  
##### **Index on rearrangements**  
  
```{r define rearrangemnts pattern}
rearrangement_pattern <- " fusion|rearrangement|truncation|truncated|deletion|deleted|lost|duplication|duplicated|transloc"
```

For rearrangements, we will use the pattern `r rearrangement_pattern`.  


```{r index on rearrangements}

# rearrangement_pattern <- " fusion|rearrangement|truncation|truncated|deletion|deleted|lost|duplication|duplicated|transloc"
# 
# rearrangement_eligibilities <- indexOnPattern(dataframe = kwic_genes, pattern = rearrangement_pattern, featureLabel = "rearrangement")
# 
# ## select and reorder columns for consistency with trialMatchDataRefresh
# rearrangement_eligibilities <- unique(dplyr::select(rearrangement_eligibilities, names(mutation_eligibilities) ))

```
  

```{r index populations on rearrangements}

rearrangement_populations <- indexOnPattern(dataframe = kwic_genes_populations, pattern = rearrangement_pattern, featureLabel = "rearrangement")

## select and reorder columns for consistency with trialMatchDataRefresh
rearrangement_populations <- unique(dplyr::select(rearrangement_populations, match, nct_id, id, id_type, text, feature, controlled_match ))

```

  
  
Sample results:  
  
`r formattable(head(rearrangement_populations)) `  
  
  
##### **Index on amplifications**  
  
```{r define amplification pattern}
amplification_pattern <- " amplifi|overexpress"

```

For amplifications, we will use the pattern `r amplification_pattern`.  


```{r index on amplifications}
# 
# 
# amplification_eligibilities <- indexOnPattern(dataframe = kwic_genes, pattern = amplification_pattern, featureLabel = "amplification")
# 
# ## select and reorder columns for consistency with trialMatchDataRefresh
# amplification_eligibilities <- unique(dplyr::select(amplification_eligibilities, names(mutation_eligibilities) ))

```


```{r index populations on amplifications}

amplification_populations <- indexOnPattern(dataframe = kwic_genes_populations, pattern = amplification_pattern, featureLabel = "amplification")

## select and reorder columns for consistency with trialMatchDataRefresh
amplification_populations <- unique(dplyr::select(amplification_populations, match, nct_id, id, id_type, text, feature, controlled_match ))

```

  
  
Sample results:  
  
`r formattable(head(amplification_populations)) `  
  
  
##### **Index on loss**  
  
```{r define loss pattern}
loss_pattern <- " loss"

```

For losses, we will use the pattern `r loss_pattern`.  
  


```{r index populations on losses}

loss_populations <- indexOnPattern(dataframe = kwic_genes_populations, pattern = loss_pattern, featureLabel = "loss")
```

  
In order to avoid spurious hits against "loss of function" (which should be indexed as a mutation), we will filter again and exclude those rows where the context contains "loss of function" (or variants thereof)...  
  

```{r exclude loss of function pattern}
loss_populations <- loss_populations[grep(pattern = "loss of function|loss-of-function|loss function", x=loss_populations$context, ignore.case = TRUE, invert = TRUE), ]



## select and reorder columns for consistency with trialMatchDataRefresh
loss_populations <- unique(dplyr::select(loss_populations, match, nct_id, id, id_type, text, feature, controlled_match ))

```

  
  
Sample results:  
  
`r formattable(head(loss_populations)) `  
  

#### **Index on prior therapies**  
  
We will get keywords surrounding synonyms related to therapy (as defined by NCIt for Class "Therapeutic or Preventive Procedure")...    
Since some of these entries are multi-word expressions, we need to use the phrase() function...  

  
  
```{r get context surrounding therapy keywords} 

tic("get context words surrounding therapies/procedures in populations_tokens")
kwic_prior_tx_populations <- as.data.frame(kwic(populations_tokens, 
                                                pattern =  phrase(unique(NCIt$Synonyms[NCIt$Class=="Therapeutic or Preventive Procedure"])),
                                                window = 5, 
                                                case_insensitive = TRUE))
toc()



## concatenate pre, pattern and ignore post tokens
kwic_prior_tx_populations <- dplyr::mutate(kwic_prior_tx_populations, context = paste(pre,keyword, sep = " "))

## select and rename columns
# kwic_genes_populations <- dplyr::select(kwic_genes_populations, "id"="docname", context, "gene_synonym"=pattern)




```

  
```{r define pattern for prior tx}
# prior_tx_pattern <- "previous therapy|prior therapy|previous treatment|prior treatment"
# 
# prior_tx_pattern <- c("previous", "prior", "previous therapy", "prior therapy", "previous treatment", "prior treatment")

```
  

```{r index populations on prior therapies}



# tokens_compound(toks, pattern = phrase("prior * therapy"))

# phrase(unique(NCIt$Synonyms[NCIt$Class=="Therapeutic or Preventive Procedure"]))

```



```{r index populations on prior therapies 2}


# therapy_eligibilities <- eligibilities[grep(pattern = prior_tx_pattern, x=eligibilities$criteria, ignore.case = TRUE), ]
# 
# therapy_eligibilities$feature <- "PRIOR_THERAPY"
# 
# ## drop redundant rows, if any
# therapy_eligibilities <- unique(therapy_eligibilities)
# 
# ## since prior therapies tend to be a mixture of 2-word synonyms, 3-word synonyms etc, plus parent terms, best approach for now is to not try and match against a therapy
# 
# 
# 
# # add columns for row binding only
# therapy_eligibilities$match <- NA
# therapy_eligibilities$controlled_match <- NA
# therapy_eligibilities <- unique(dplyr::select(therapy_eligibilities, names(mutation_eligibilities) ))
# 
# 
# ## instead, in the UI, just show inclusion and exclusion criteria (separately) related to prior therapies
```
  



```{r disconnect from  database}

# disconnect from clinicaltrials.gov
dbDisconnect(conn2)

# Disconnect from SQLite database
dbDisconnect(con)

```
  

    

`r knitr::knit_exit()`    





```{r index on copy number loss}
## NOTE USE WORD RANGE OF 2 FOR LOSS, OTHERWISE GET TOO MANY FALSE HITS (including "loss of function" etc, which is indexed as a mutation)
tic("get kwic for genes 2")
kwic_genes_2 <- as.data.frame(kwic(eligibilities_tokens, pattern =  unique(humanGenes$Aliases), window = 2, case_insensitive = FALSE))
toc()
#formattable(head(as.data.frame(kw_genes), 30))

## concatenate pre, gene name and post tokens
kwic_genes_2 <- dplyr::mutate(kwic_genes_2, context = paste(pre,keyword, post, sep = " "))

## select and rename columns
kwic_genes_2 <- dplyr::select(kwic_genes_2, "criterion_index"="docname", context, "gene_synonym"=pattern)

loss_pattern <- " loss"

loss_eligibilities <- indexOnPattern(dataframe = kwic_genes, pattern = loss_pattern, featureLabel = "loss")

## select and reorder columns for consistency with trialMatchDataRefresh
loss_eligibilities <- unique(dplyr::select(loss_eligibilities, names(mutation_eligibilities) ))

```

```{r index on prior therapies}

prior_tx_pattern <- "previous therapy|prior therapy|previous treatment|prior treatment"

therapy_eligibilities <- eligibilities[grep(pattern = prior_tx_pattern, x=eligibilities$criteria, ignore.case = TRUE), ]

therapy_eligibilities$feature <- "PRIOR_THERAPY"

## drop redundant rows, if any
therapy_eligibilities <- unique(therapy_eligibilities)

## since prior therapies tend to be a mixture of 2-word synonyms, 3-word synonyms etc, plus parent terms, best approach for now is to not try and match against a therapy



# add columns for row binding only
therapy_eligibilities$match <- NA
therapy_eligibilities$controlled_match <- NA
therapy_eligibilities <- unique(dplyr::select(therapy_eligibilities, names(mutation_eligibilities) ))


## instead, in the UI, just show inclusion and exclusion criteria (separately) related to prior therapies
```

```{r sentiment analysis practice}


# sentence2 <- "Part A3: Participants with presence of loss of function mutation in the gene for ARIDIA, ATRX and /or DAXX and ATM"
# 
# sentiment <- SentimentAnalysis::analyzeSentiment(sentence2)
# convertToBinaryResponse(sentiment)$SentimentQDAP


# sentimentr::sentiment("Part A3: Participants with presence of loss of function mutation in the gene for ARIDIA, ATRX and /or DAXX and ATM")$sentiment
# 
# sentimentr::sentiment("Known BAP1 loss per immunohistochemistry (IHC) or NGS")$sentiment
# 
# sentimentr::sentiment("No genomic alteration of APC, MUTYH, SMAD4, BMPR1A, PTEN or STK11 in case of adenomatous polyposis or hamartoma presentation")$sentiment
# 
# sentimentr::sentiment("")$sentiment
# 
# sentimentr::sentiment("")$sentiment


```

```{r split criteria into sentences}
## split eligibilities into individual sentences 
# eligibilities$sentences <- strsplit(eligibilities$criteria, split = "\\. ")
# eligibilities <- as.data.frame(unnest(data = eligibilities, sentences))
# 
# ## create a stemmed copy
# eligibilities$sentences_stem <- textstem::stem_strings(eligibilities$sentences)
# 
# ## convert to lowercase
# eligibilities$sentences_stem <- tolower(eligibilities$sentences_stem)
# 
# ## add a sentence index
# eligibilities <- eligibilities %>% group_by(criterion_index) %>% mutate(criterion_sentence_index = paste0(criterion_index, "_", row_number())) %>% as.data.frame()
```

```{r stem eligibility criteria}
## create a stemmed copy
# eligibilities$criteria_stem <- textstem::stem_strings(eligibilities$criteria)

## convert to lowercase
# eligibilities$criteria_stem <- tolower(eligibilities$criteria_stem)



```
  
```{r apply dictionary}
## Convert tokens into equivalence classes defined by values of a dictionary object.
## this works, but is relatively slow... 
# dict4 <- dictionary(list(gene = humanGenes$Aliases, alteration = "KRAS mutation"))
# toks4 <- tokens("Patients with any BRAF or KRAS mutation status are eligible.")
# tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE)

## also this... 
# labResultSynonyms <- unique(NCIt$Synonyms[NCIt$Class == "Laboratory or Test Result"])
# dict4 <- dictionary(list(gene = humanGenes$Aliases, lab_result = labResultSynonyms))
# toks4 <- tokens("Proficient mismatch repair/microsatellite stable (pMMR/MSS), histologically or cytologically-confirmed adenocarcinoma of the colon or rectum. Patients with any BRAF or KRAS mutation status are eligible.")
# tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE)
# as.character(tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE))


## and this
# cellMolDysfSynonyms <- unique(NCIt$Synonyms[NCIt$Class == "Cell or Molecular Dysfunction"])
# dict4 <- dictionary(list(gene = humanGenes$Aliases, lab_result = labResultSynonyms, cellMol_dysfunction = cellMolDysfSynonyms))
# toks4 <- tokens("Proficient mismatch repair/microsatellite stable (pMMR/MSS), histologically or cytologically-confirmed adenocarcinoma of the colon or rectum. Patients with any BRAF or KRAS mutation status are eligible.")
# tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE)
# as.character(tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE))

## and this
# neoProcessSynonyms <- unique(NCIt$Synonyms[NCIt$Class == "Neoplastic Process"])
# dict4 <- dictionary(list(gene = humanGenes$Aliases, 
#                          lab_result = labResultSynonyms, 
#                          cellMol_dysfunction = cellMolDysfSynonyms, 
#                          neoplastic_process = neoProcessSynonyms))




# toks4 <- tokens("Proficient mismatch repair/microsatellite stable (pMMR/MSS), histologically or cytologically-confirmed adenocarcinoma of the colon or rectum. Patients with any BRAF or KRAS mutation status are eligible.")
# #tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE)
# as.character(tokens_lookup(toks4, dict4, nested_scope = "key", exclusive = FALSE))



## piped version
# "BRCA Positive Serous Ovarian: Patients with serous ovarian cancer who have a harmful mutation in the breast cancer genes BRCA1 or BRCA2. (Serous tumors are the most common subtype of ovarian cancer)." %>%
#     tokens( padding = TRUE, remove_punct=TRUE) %>%
#     tokens_select( pattern = stopwords("en"), selection = "remove") %>%
#     tokens_lookup( dict4, nested_scope = "key", exclusive = FALSE,valuetype = "fixed") %>%
#     as.character() %>%
#     paste(collapse = "', '")


## apply to whole set of criteria
# tic("index all criteria")
# 
# eligibilities_tokens_dict <- eligibilities_corpus %>%
#   tokens( padding = TRUE, remove_punct=TRUE) %>%
#     tokens_select( pattern = stopwords("en"), selection = "remove") %>%
#     tokens_lookup( dict4, nested_scope = "key", exclusive = FALSE,valuetype = "fixed")
# 
# toc()

```

```{r keywords in context}
## basic kwic, simple pattern...
# kw_mutations <- kwic(eligibilities_tokens, pattern =  c("mutat*", "mutan*"), window = 5)
# formattable(head(as.data.frame(kw_mutations), 30))
# 
# 
# 
# ## can use multi-word tokens as patterns
# msi_synonyms <- NCIt$Synonyms[NCIt$ID=="C131459"]
# msi_synonyms <- msi_synonyms[msi_synonyms != "Stable"]
# msi_synonyms
# kw_msi <- kwic(eligibilities_tokens, pattern =  phrase(msi_synonyms), window = 5, case_insensitive = TRUE)
# formattable(head(as.data.frame(kw_msi), 30))
```

```{r define function to get pattern and context}
#' Get context words (words within a symmetric window around the target word/phrase)
#' sorrounding a user defined target.

## reuse code from https://rdrr.io/github/prodriguezsosa/conText/src/R/get_context.R with modification to get useable values for docname

## pattern may be a single string, or a vector of strings...

## specify some sensible defaults...
# get_context_mod <- function(dataframe, textcolumn, docid_field, pattern, window = 6, valuetype = "regex",what="word", ignore_case = TRUE) {
#   #dataframe <- dataframe
#   #pattern <- pattern
#   #window <- window
#   #valuetype <- valuetype
#   #what <- what
#   
#   ## get a vector of TRUE/FALSE values indicating whether pattern present in dataframe
#   pattern_present <- stringr::str_detect(dataframe[ ,which(names(dataframe)==textcolumn)], paste(stringr::regex(pattern, ignore_case = ignore_case), collapse = '|'))
#   
#   ## subset dataframe
#   dataframe_subset <- dataframe[pattern_present, ]
#   
#   ## turn into a corpus object
#   dataframe_subset_corpus <-  quanteda::corpus(x=dataframe_subset,
#                       text_field = textcolumn, 
#                       docid_field = docid_field,
#                       #docid_field = "criterion_sentence_index", 
#                       unique_docnames = FALSE)
#   
#   #out <- dataframe_subset_corpus
#   
#   ## get context of pattern
#   kwic_i <- as.data.frame(quanteda::kwic(quanteda::tokens(dataframe_subset_corpus, what = what), pattern = quanteda::phrase(pattern), window = window, valuetype = valuetype, case_insensitive = TRUE))
#   
#   out <- kwic_i
#   out <- as.data.frame(kwic_i) %>%
#       dplyr::select(docname, keyword, pre, post) %>% # keep pre and post (see kwic documentation for info on values)
#       dplyr::mutate(context = paste(pre,keyword, post, sep = " ")) %>% # combine pre and post into one variable named context
#       dplyr::select(-c('pre', 'post')) %>% # drop pre & post
#       dplyr::rename(target = keyword) # align variable names (we use target instead of keyword)
#   
#   return(out)
# }
# 


```

##### **Write indexed eligibility criteria to database**  

```{r write indexed eligibilities to database}


indexed_eligibilities <- unique(rbind(mutation_eligibilities, rearrangement_eligibilities, loss_eligibilities, amplification_eligibilities, therapy_eligibilities))

## create as a table in database
dbWriteTable(conn = con,name = "indexedEligibility", value = indexed_eligibilities, overwrite=TRUE)

## check it has saved
dbListTables(con)
```

```{r write data to csv for word embeddings}

## select all verbatim criteria
raw_criteria <- unique(dplyr::select(eligibilities, criteria))

## select and rename columns from indexed eligibilities
annotated_criteria <- unique(dplyr::select(indexed_eligibilities, match, "criterion"="criteria", feature, "entrez_gene"="controlled_match"))
## drop rows related to prior tx
annotated_criteria <- unique(dplyr::filter(annotated_criteria, feature != "PRIOR_THERAPY"))
## drop rows with obvious false hits
annotated_criteria <- annotated_criteria[!annotated_criteria$match %in% c("B12", "EL", "G6PD", "CAT", "MRI", "CT", "polymerase", "A1", "AA", "ARMS", "IMPACT", "STEPS", "OTC", "CAV", "NB", "PSA", "PK"), ]

## write to file
write.csv(x=raw_criteria, file = "raw_criteria.csv", row.names = FALSE)
write.csv(x=annotated_criteria, file = "annotated_criteria.csv", row.names = FALSE)

```
  
#### **Index design groups**  

In some cases, patients are allocated to arms according to features (e.g. genetic alterations) - this information is relevant to clinician's evaluation of potential studies.  
  
Therefore, we will index design groups (titles and descriptions) in same way as for eligibility criteria...   
  
```{r create corpus for design groups}
tic("create design groups corpus")
dg_corpus <-  quanteda::corpus(x=unique(dplyr::select(design_groups, nct_id, dg_id, dg_title_description)),
                                          text_field = "dg_title_description", 
                                          docid_field = "dg_id",
                                          unique_docnames = FALSE)
toc()


```

```{r change units of dg corpus to sentences}
dg_corpus <- corpus_reshape(dg_corpus, to = "sentences")

```

```{r tokenise the dg corpus}
tic("tokenise dg corpus")
dg_tokens <- tokens(dg_corpus, remove_punct=TRUE, padding = FALSE, split_hyphens = TRUE)
toc()
```

```{r remove stopwords from dg tokens}
# tic("remove stopwords")
# dg_tokens <- tokens_select(x=dg_tokens, pattern = stopwords("en"), selection = "remove", padding = FALSE)
# toc()
```

```{r get context words surrounding gene names in dg}

tic("get kwic for genes, dgs")
kwic_genes_dg <- as.data.frame(kwic(dg_tokens, pattern =  unique(humanGenes$Aliases), window = 6, case_insensitive = FALSE))
toc()
#formattable(head(as.data.frame(kw_genes), 30))

## concatenate pre, gene name and post tokens
kwic_genes_dg <- dplyr::mutate(kwic_genes_dg, context = paste(pre,keyword, post, sep = " "))

## select and rename columns
kwic_genes_dg <- dplyr::select(kwic_genes_dg, "dg_id"="docname", context, "gene_synonym"=pattern)

## trim off the sentence ID added to dg_id (if using sentence-level corpus)
kwic_genes_dg$dg_id <- gsub(pattern = "\\..*" , replacement = "", x=kwic_genes_dg$dg_id)

```

```{r join Entrez Symbols to kwic_genes_dg}

kwic_genes_dg <- merge(x=kwic_genes_dg, by.x="gene_synonym", y=dplyr::select(humanGenes, Symbol, Aliases), by.y = "Aliases")

```

```{r join dg title and nct_id}
kwic_genes_dg <- merge(x=dplyr::select(design_groups, nct_id, dg_id, dg_title, dg_description), by.x="dg_id", y=kwic_genes_dg, by.y="dg_id")

## rename and reorder columns
kwic_genes_dg <- unique(dplyr::select(kwic_genes_dg, nct_id, dg_id, dg_title,dg_description, context, "match"="gene_synonym", "controlled_match"="Symbol"))

```
  
```{r index dg on mutations}

mutation_dg <- indexOnPattern(dataframe = kwic_genes_dg, pattern = mutant_pattern, featureLabel = "mutation")

## select and reorder columns for consistency with trialMatchDataRefresh
mutation_dg <- unique(dplyr::select(mutation_dg, match, nct_id, dg_title, context, feature, controlled_match ))
```

```{r index dg on rearrangements}

rearrangement_dg <- indexOnPattern(dataframe = kwic_genes_dg, pattern = rearrangement_pattern, featureLabel = "rearrangement")

## select and reorder columns for consistency 
rearrangement_dg <- unique(dplyr::select(rearrangement_dg, match, nct_id, dg_title, context, feature, controlled_match ))

```

```{r index dg on amplifications}


amplification_dg <- indexOnPattern(dataframe = kwic_genes_dg, pattern = amplification_pattern, featureLabel = "amplification")

## select and reorder columns for consistency 
amplification_dg <- unique(dplyr::select(amplification_dg, names(rearrangement_dg) ))

```
  
```{r write indexed design groups to database}

indexed_dg <- unique(rbind(mutation_dg, rearrangement_dg, amplification_dg))

## create as a table in database
dbWriteTable(conn = con,name = "indexedDesignGroups", value = indexed_dg, overwrite=TRUE)

## check it has saved
dbListTables(con)
```  
  
  
  
#### **Index result groups**  

In some cases, results are analysed according to features (e.g. genetic alterations) - this information is relevant to clinician's evaluation of potential studies.  
  
Therefore, we will index result groups (titles and descriptions) in same way as for eligibility criteria...   
  

```{r create corpus for result groups}
tic("create design groups corpus")
rg_corpus <-  quanteda::corpus(x=unique(dplyr::select(result_groups, nct_id, rg_id, rg_title_description)),
                                          text_field = "rg_title_description", 
                                          docid_field = "rg_id",
                                          unique_docnames = FALSE)
toc()


```

```{r change units of rg corpus to sentences}
rg_corpus <- corpus_reshape(rg_corpus, to = "sentences")

```

```{r tokenise the rg corpus}
tic("tokenise rg corpus")
rg_tokens <- tokens(rg_corpus, remove_punct=TRUE, padding = FALSE, split_hyphens = TRUE)
toc()
```

```{r remove stopwords from rg tokens}
# tic("remove stopwords")
# rg_tokens <- tokens_select(x=rg_tokens, pattern = stopwords("en"), selection = "remove", padding = FALSE)
# toc()
```

```{r get context words surrounding gene names in rg}

tic("get kwic for genes, rgs")
kwic_genes_rg <- as.data.frame(kwic(rg_tokens, pattern =  unique(humanGenes$Aliases), window = 6, case_insensitive = FALSE))
toc()

## concatenate pre, gene name and post tokens
kwic_genes_rg <- dplyr::mutate(kwic_genes_rg, context = paste(pre,keyword, post, sep = " "))

## select and rename columns
kwic_genes_rg <- dplyr::select(kwic_genes_rg, "rg_id"="docname", context, "gene_synonym"=pattern)

## trim off the sentence ID added to dg_id (if using sentence-level corpus)
kwic_genes_rg$rg_id <- gsub(pattern = "\\..*" , replacement = "", x=kwic_genes_rg$rg_id)

```

```{r join Entrez Symbols to kwic_genes_rg}

kwic_genes_rg <- merge(x=kwic_genes_rg, by.x="gene_synonym", y=dplyr::select(humanGenes, Symbol, Aliases), by.y = "Aliases")

```

```{r join rg title and nct_id}
kwic_genes_rg <- merge(x=dplyr::select(result_groups, nct_id, rg_id, rg_title, rg_description), by.x="rg_id", y=kwic_genes_rg, by.y="rg_id")

## rename and reorder columns
kwic_genes_rg <- unique(dplyr::select(kwic_genes_rg, nct_id, rg_id, rg_title,rg_description, context, "match"="gene_synonym", "controlled_match"="Symbol"))

```
  
```{r index rg on mutations}

mutation_rg <- indexOnPattern(dataframe = kwic_genes_rg, pattern = mutant_pattern, featureLabel = "mutation")

## select and reorder columns for consistency with trialMatchDataRefresh
mutation_rg <- unique(dplyr::select(mutation_rg, match, nct_id, rg_title, context, feature, controlled_match ))
```

```{r index rg on rearrangements}

rearrangement_rg <- indexOnPattern(dataframe = kwic_genes_rg, pattern = rearrangement_pattern, featureLabel = "rearrangement")

## select and reorder columns for consistency 
rearrangement_rg <- unique(dplyr::select(rearrangement_rg, names(mutation_rg) ))

```

```{r index rg on amplifications}


amplification_rg <- indexOnPattern(dataframe = kwic_genes_rg, pattern = amplification_pattern, featureLabel = "amplification")

## select and reorder columns for consistency 
amplification_rg <- unique(dplyr::select(amplification_rg, names(mutation_rg) ))

```
  
```{r write indexed result groups to database}

indexed_rg <- unique(rbind(mutation_rg, rearrangement_rg, amplification_rg))

## create as a table in database
dbWriteTable(conn = con,name = "indexedResultGroups", value = indexed_rg, overwrite=TRUE)

## check it has saved
dbListTables(con)
```  
    
  


































```{r get design group interventions from clinicaltrials.gov}

getDesignGroupInterventions <- paste0("select dg.nct_id, dg.id as dg_id, dg.group_type, dg.title as dg_title, dg.description as dg_description, i.name as intervention_name 
from design_groups dg
inner join design_group_interventions dgi on dgi.design_group_id = dg.id
inner join interventions i on i.id = dgi.intervention_id
where dg.nct_id in (",
"", studyIDsForSQL,
")")
# 
## get criteria from clinicaltrials.gov
design_group_interventions <- dbGetQuery(conn2, getDesignGroupInterventions)

design_group_interventions_aggregated <- design_group_interventions %>%
    group_by(nct_id, dg_id) %>%
    summarise_all(function(x) {paste(unique(x), collapse = "; ")}) %>%
    as.data.frame()


kbl(design_group_interventions_aggregated, format = "html",escape = FALSE) %>%
  kable_styling(fixed_thead = T, bootstrap_options = c("striped", "hover", "condensed")) %>%
  scroll_box(width = "100%", height = "200px")
```  
   


  
#### **Get cancer studies with results**  
  

#### **Map interventions to molecular targets**  
  

```{r get molecular targets for cancerStudies interventions}
## first, get all interventions (note that there will be some redundancy due to case)
drugs.targets <- unique(dplyr::select(cancerStudiesResults,nct_id,interventions))

## keep interventions column as verbatim so can join later
## make a duplicate column
drugs.targets$interventions.processed <- drugs.targets$interventions


## split and unnest on " + "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " \\+ ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unneston the word " plus "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " plus ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unneston the word " and "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " and ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unnest on  " & "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " \\& ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unnest on  " or "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " or ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unnest on  " (+) "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " \\(\\+\\) ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

# also split and unnest on  " with "
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " with ")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)

## also split on brackets
drugs.targets$interventions.processed <- strsplit(drugs.targets$interventions.processed, split = " \\(")
drugs.targets <- unnest(data = drugs.targets, interventions.processed)
# remove closing bracket
drugs.targets$interventions.processed <- gsub(pattern = "\\)", replacement = "", x=drugs.targets$interventions.processed)


## trim off anything related to dose
# pattern is (a number, with or without a decimal point) with/without a space, followed by "mg", anything after "mg is removed
drugs.targets$interventions.processed <- gsub(pattern = " \\d+\\.?\\d+ ?mg.*", replacement = "", x=drugs.targets$interventions.processed, ignore.case = T)

## convert to lowercase
drugs.targets$interventions.processed <- tolower(drugs.targets$interventions.processed)

drugs.targets <- as.data.frame(drugs.targets)



## join to NCIthesaurus 
## drop rows without a match 
drugs.targets <- merge(x=drugs.targets, 
      by.x = "interventions.processed", 
      all.x = FALSE,
      y= unique(dplyr::select(NCIthesaurus, "NCI_ID"="ID", SynonymsLower, PreferredTerm, ParentTerm)), 
      by.y = "SynonymsLower")



# convert empty cells to NA
drugs.targets$PreferredTerm[drugs.targets$PreferredTerm==""] <- NA

## drop the interventions processed column
drugs.targets <- unique(dplyr::select(drugs.targets, -c(interventions.processed)))

## drop any rows that don't have a preferred term
#drugs.targets <- unique(drugs.targets[!is.na(drugs.targets$PreferredTerm), ])


## reduce number of rows
drugs.targets <-unique(dplyr::select(drugs.targets, interventions, PreferredTerm,NCI_ID))

## map preferred terms to drug IDs in KEGG
# drugs.targets.preferred <- unique(dplyr::select(drugs.targets, PreferredTerm))
```


```{r get drug ids based on intervention name}
## add an empty column to hold drug ID
drugs.targets$drugID <- NA

tic("get drug IDs based on intervention name")
for(i in 1:nrow(drugs.targets)) {
  print(i)
  drugName <- drugs.targets$interventions[i]
  preferred <- drugs.targets$PreferredTerm[i]
  print(drugName)
  drugID <- getDrugID(drugName)
  if(is.na(drugID)) {
    drugID <- getDrugID(preferred)
  }
  
  drugs.targets$drugID[i] <- drugID
  print(drugs.targets$drugID[i])
}  
toc()

## unnest
drugs.targets <- as.data.frame(unnest(data = drugs.targets, drugID, keep_empty = TRUE))


```

```{r define function to get drug target IDs from KEGG}

getDrugTargetID <- function(drugID){
  if(is.na(drugID)) return(NA)
  geneid <- tryCatch({keggGet(drugID)[[1]]$TARGET$TARGET},
             error=function(cond) {return(NA)})
  if(is.null(geneid)) return(NA)
  if(is.na(geneid)) return(NA)
  ## parse the drugTargetID values - trim off extra characters and unnest where multiple targets per drug
  #trim everything up to "HSA:"
  geneid <- gsub(pattern = ".*\\HSA:", replacement = "", x=geneid) 
  # trim everything after square bracket
  geneid <- gsub(pattern = "\\].*", replacement = "", x=geneid) 
  # split on space into individual ids, where applicable
  geneid <- strsplit(geneid, split = " ")
  # unlist
  geneid <- unlist(geneid)
  # paste on a "hsa:"
  geneid <- paste0("hsa:",geneid)
  geneid <- as.list(geneid)
  return(geneid)
}



```



```{r map each drug ID to a target gene ID}
# drugs.targets$target_id <- NA

# drugs.targets$PreferredTerm[drugs.targets$drugID=="dr:D10231"]

temp_table <- data.frame(drugID= unique(na.omit(drugs.targets$drugID)), 
                         target_id = NA)


for(i in 1:nrow(temp_table)) {
  print(i)
  drugid <- as.character(temp_table$drugID[i])
  print(drugid)
  target_id <- getDrugTargetID(drugid)
  print(target_id)
  temp_table$target_id[i] <- list(target_id)
}


## unnest
temp_table <- as.data.frame(unnest(data = temp_table, target_id, keep_empty = FALSE))
temp_table$target_id <- as.character(temp_table$target_id)
## drop any null rows
temp_table <- temp_table[temp_table$target_id != "NULL", ]
```





```{r define function to get drug target symbols from KEGG via API}}
# keggGet("hsa:3620")[[1]]$SYMBOL[1]


getDrugTargetSymbol <- function(targetID){
  if(is.na(targetID)) return(NA)
  geneSymbol <- tryCatch({
    keggGet(targetID)[[1]]$SYMBOL[1]
    }, error=function(cond) {return(NA)})
  if(is.null(geneSymbol)) return(NA)
  if(is.na(geneSymbol)) return(NA)
  ## parse value
  ## multiple symbols separated by comma, we want the first one...
  geneSymbol <- gsub(pattern = ",.*", replacement = "", x=geneSymbol)
  
  return(geneSymbol)
}
```



```{r get drug symbols using function}
temp_table$target_symbol <- NA

tic("get drug target symbols")
for(i in 1:nrow(temp_table)) {
  print(i)
  targetID <- temp_table$target_id[i]
  print(targetID)
  temp_table$target_symbol[i] <- getDrugTargetSymbol(targetID)
  print(temp_table$target_symbol[i])
}
toc()


# temp_table[temp_table$target_symbol != "NA", ]
temp_table <- temp_table[complete.cases(temp_table), ]


# 
# ## reorder columns
# drugs.targets <- unique(dplyr::select(drugs.targets,"interventions.verbatim"= "interventions", interventions.processed, Description, ParentTerm, drugTargetSymbol))
```
  


```{r join target name to interventions}
drugs.targets <- unique(merge(x=drugs.targets, by.x="drugID", all.x=TRUE, y=temp_table, by.y = "drugID"))



```

```{r join mechanisms from NCIt}
drugs.targets <- unique(merge(x=drugs.targets, by.x="NCI_ID", all.x=TRUE, y=unique(dplyr::select(NCIthesaurus, ID, Class, ParentTerm)), by.y = "ID"))



## write to database

```

```{r join drugs targets back to nct_id}

cancerStudiesResults_interventions <- unique(merge(x=unique(dplyr::select(cancerStudiesResults, nct_id, interventions)), by.x = "interventions", y=drugs.targets, by.y="interventions"))



cancerStudiesResults
```

  
  
  
  
  
```{r assign interventions based on mentions}
for(i in 1: length(unique(unmapped_result_groups$nct_id))) {
  study_id <- unique(unmapped_result_groups$nct_id)[i]
  print(study_id)
  study_interventions <- unique(interventions$intervention_name[interventions$nct_id==study_id])
  print(study_interventions)
  temp_unmapped_rgs <- unique(dplyr::filter(unmapped_result_groups, nct_id == study_id))
  
}





```


















#### **Assign interventions based on similarity between design, result group descriptions**   



```{r issues with creating DTMs}
## e.g. study NCT00063570 has: 
# design group titles = "A" and "B"
# design group descriptions = NA and NA
# design group interventions = same for both groups
# design group intervention descriptions = different between groups
# e.g. "500 mg/m2, intravenous (IV), every 14 days, until disease progression" for group A, and 
# "500 mg/m2, intravenous (IV), every 21 days, until disease progression" for group B

## result group titles are e.g. 
# "Bi-Weekly Schedule" and "21-Day Schedule"
# result group descriptions e.g. 
# "Pemetrexed: 500 mg/m2, intravenous (IV), every 14 days, until disease progression. Gemcitabine: 1500 mg/m2, intravenous (IV), every 14 days, until disease progression." and 
# "Pemetrexed: 500 mg/m2, intravenous (IV), every 21 days, until disease progression. Gemcitabine: 1000 mg/m2, intravenous (IV) on Days 1 and 8 of a 21-day cycle, until disease progression."




## need to code some resilience in: 
# if purity of categories is <100%, return NA
# if no common terms between design and result group descriptions, return NA


## for groups still unmapped, may need to retrieve and use intervention descriptions... 


```


    
























```{r predict mapping based on group titles and descriptions}

# 
# study_id <- "NCT00063570"
# study_id <- "NCT00002540"
# study_id <- "NCT00002597"
# study_id <- "NCT00503984"
# temp_unmapped_dgs <- unique(dplyr::filter(unmapped_design_groups, nct_id == study_id))
# temp_unmapped_rgs <- unique(dplyr::filter(unmapped_result_groups, nct_id == study_id))
# study_interventions <- unique(interventions$intervention_name[interventions$nct_id==study_id])
# 
# ## create document-term matrix for design group descriptions
# unmapped_dgs_dtm <- create_dtm(dataframe = temp_unmapped_dgs, text_column = "dg_title_description", id_column = "dg_id", custom_tokens = study_interventions)
# 
#   ## create DTM for result group descriptions
# unmapped_rgs_dtm <- create_dtm(dataframe = temp_unmapped_rgs, text_column = "rg_title_description", id_column = "rg_id", custom_tokens = study_interventions)
# 
# ## make names valid, otherwise rpart will barf...
# names(unmapped_dgs_dtm) <- gsub(" ", "_", names(unmapped_dgs_dtm))
# names(unmapped_rgs_dtm) <- gsub(" ", "_", names(unmapped_rgs_dtm))
# 
# names(unmapped_dgs_dtm) <- make.names(names(unmapped_dgs_dtm))
# names(unmapped_rgs_dtm) <- make.names(names(unmapped_rgs_dtm))
# 
# common_terms <- intersect(names(unmapped_dgs_dtm), names(unmapped_rgs_dtm))
# 
# if(length(common_terms)==0) next
# ## drop non-overlapping columns from DGs_dtm
# unmapped_dgs_dtm <- dplyr::select(unmapped_dgs_dtm, dg_id, all_of(common_terms))
# 
# tryCatch({
#             ## create decision tree model
#             modFit <- rpart::rpart(formula = dg_id ~., method = "class", data = unmapped_dgs_dtm, control =rpart.control(minsplit = 1,minbucket=1, cp=0))
# 
# 
#             ## (optional) print tree
#             rpart.plot(modFit)
#             ## predict design group for each result group
#             study_predictions <- data.frame(nct_id = as.character(study_id),
#                           rg_id = as.character(unmapped_rgs_dtm$rg_id),
#                           predicted_design_group = as.character(predict(object = modFit, unmapped_rgs_dtm, type = "class"))
#                           )
# 
#             }, error=function(cond) {
#               return(study_predictions <- data.frame(nct_id = study_id,
#                                                      result_group_id = unmapped_rgs_dtm$rg_id,
#                                                      predicted_design_group = NA
#                           ))})
# 
# 
# 

```













 
  
  
```{r loop through unmapped result groups and predict design group}

for(i in 1: length(unique(unmapped_result_groups$nct_id))) {
  study_id <- unique(unmapped_result_groups$nct_id)[i]
  print(study_id)
  temp_unmapped_dgs <- unique(dplyr::filter(unmapped_design_groups, nct_id == study_id))
  print(nrow(temp_unmapped_dgs))
  ## drop unnecessary columns, as multiple interventions give multiple rows which throws document term matrix out
  temp_unmapped_dgs <- unique(dplyr::select(temp_unmapped_dgs, -intervention_id)) 
  
  temp_unmapped_rgs <- unique(dplyr::filter(unmapped_result_groups, nct_id == study_id))
  print(nrow(temp_unmapped_rgs))
  study_interventions <- unique(interventions$intervention_name[interventions$nct_id==study_id])
  print(study_interventions)
  
  ## create document-term matrix for design group descriptions
  unmapped_dgs_dtm <- create_dtm(dataframe = temp_unmapped_dgs, text_column = "dg_title_description", id_column = "dg_id", custom_tokens = study_interventions)
  
  ## create DTM for result group descriptions
  unmapped_rgs_dtm <- create_dtm(dataframe = temp_unmapped_rgs, text_column = "rg_title_description", id_column = "rg_id", custom_tokens = study_interventions)
  
  
  
  ## make names valid, otherwise rpart will barf...
  names(unmapped_dgs_dtm) <- gsub(" ", "_", names(unmapped_dgs_dtm))
  names(unmapped_rgs_dtm) <- gsub(" ", "_", names(unmapped_rgs_dtm))
  
  #names(unmapped_dgs_dtm) <- make.names(names(unmapped_dgs_dtm))
  #names(unmapped_rgs_dtm) <- make.names(names(unmapped_rgs_dtm))

  ## try make.names
  ## or something like str_squish(str_replace_all(string = "fish = not + this ^ Fire % hi &", "[^[:alnum:]]", replacement = " "))
  
  ## need to create model using terms that are common to both DTMs, otherwise can end up trying to predict on variables we don't have... 
  common_terms <- intersect(names(unmapped_dgs_dtm), names(unmapped_rgs_dtm))
  
  ## drop any common_terms that are numbers
  common_terms <- common_terms[is.na(as.numeric(common_terms))]
  
  if(length(common_terms)==0) next
  
  # else {
  ## drop non-overlapping columns from DGs_dtm
  unmapped_dgs_dtm <- dplyr::select(unmapped_dgs_dtm, dg_id, all_of(common_terms))
  print(common_terms)
  
  tryCatch({
            ## create decision tree model
            modFit <- rpart::rpart(formula = dg_id ~., method = "class", data = unmapped_dgs_dtm, control =rpart.control(minsplit = 1,minbucket=1, cp=0))
            ## (optional) print tree
            rpart.plot(modFit)
            ## predict design group for each result group
            study_predictions <- data.frame(nct_id = as.character(study_id),
                          rg_id = as.character(unmapped_rgs_dtm$rg_id), 
                          predicted_design_group = as.character(predict(object = modFit, unmapped_rgs_dtm, type = "class"))
                          )
            
            }, error=function(cond) {
              return(study_predictions <- data.frame(nct_id = study_id,
                                                     result_group_id = unmapped_rgs_dtm$rg_id,
                                                     predicted_design_group = NA
                          ))})
  ## now we have predicted design group for each unmapped result group for this study
  ## what we want is study id, rg_id, predicted intervention id
  ## so we need to get intervention ids for each predicted design group
  study_predictions$predicted_design_group <- as.character(study_predictions$predicted_design_group)
  study_predictions <- merge(x=study_predictions, by.x=c("nct_id", "predicted_design_group"), all.x=TRUE, y=unique(dplyr::select(design_groups, nct_id, dg_id, intervention_id)), by.y=c("nct_id", "dg_id"))
  
  ## make names match those for result_group_interventions
  study_predictions <- unique(dplyr::select(study_predictions, names(result_group_interventions)))
  # }
  ## rowbind onto result_group_interventions
  result_group_interventions <- unique(rbind(result_group_interventions, study_predictions))
  
}


## update vector of unmapped result groups
## The elements of setdiff(x,y) are those elements in x but not in y
unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=result_group_interventions$rg_id)
length(unmapped_result_group_ids)




### NEED TO MAKE THIS WORK WITH STUDY NCT00014222
## BARFS WIT ERROR: 
# Error: Obsolete data mask.
# x Too late to resolve `5µg` after the end of `dplyr::mutate()`.
# i Did you save an object that uses `5µg` lazily in a column in the `dplyr::mutate()` expression ?

## BARFS AT CREATION OF DESIGN GROUP DTM (due presence of microgram symbol?)
## try replacing mu symbols with u?
## use gsub e.g. 
# gsub(pattern = "\U00B5", replacement = "u", x=" Filgrastim 5µg/kg/d ")
```

```{r assign interventions for single arm studies}
# for(i in 1:length(unique(rgs$nct_id))) {
#   nct_id <- unique(rgs$nct_id)[i]
#   print(nct_id)
#   number_arms <- unique(rgs$number_of_arms[rgs$nct_id==nct_id])
#   print(number_arms)
#   study_interventions <- unique(interventions$intervention_name[interventions$nct_id == nct_id])
#   print(study_interventions)
#   study_intervention_ids <- unique(interventions$intervention_id[interventions$nct_id == nct_id])
#   print(study_intervention_ids)
#   if(!is.na(number_arms) & number_arms==1) {
#     rgs$rg_interventions[rgs$nct_id==nct_id] <- list(study_interventions)
#     rgs$rg_intervention_ids[rgs$nct_id==nct_id] <- list(study_intervention_ids)
#   }
# }

## if result group titles match design group titles, match on that basis

  ## finally, if still no match, predict match based on document term matrices of titles and descriptions
```

```{r get interventions for each design group}
# design_group_interventions <- unique(dplyr::select(design_groups, nct_id, dg_id, dg_title, dg_description, "dg_intervention_id"="intervention_id"))
# 
# design_group_interventions$dg_title_description <- paste(design_group_interventions$dg_title, design_group_interventions$dg_description, sep = ": ")
# 
# testrun <- merge(x=design_group_interventions, by.x=c("nct_id", "dg_title"), all.x=FALSE,y=rgs, by.y = c("nct_id", "rg_title"), all.y=TRUE)


```


#### **Define function to replace drug names with preferred terms (where available)**  
  
The function will accept a synonym, then:  
* convert it to lower case  
* get the preferred term(s) from NCIt_drugs_preferred table  
* convert preferred term to lower case  
* return the preferred term  



```{r define function to replace drug synonyms with preferred terms}

## define a function that will be called if str_replace_all() finds a match between a string (lowercase description) and a pattern (lowercase synonyms)...
synonym2preferred <- function(synonym) {
  synonym <- tolower(synonym)
  preferred <- NCIt_Pharmacologics$PreferredTerm[NCIt_Pharmacologics$Synonyms_lower==synonym] ## get the preferred term for that synonym
  preferred <- paste(unique(preferred), collapse = ", ") ## in case more than one match
  preferred <- tolower(preferred)
  return(preferred) ## return the preferred term
}

```
  
We will use the stringr::str_replace_all() function to:  
* look for a synonym that appears in NCI thesaurus (based on a pattern of all synonyms collapsed, pipe-separated)  
* when found, call the function defined above to replace it with the preferred term  
  
```{r replace synonyms in result group title descriptions}
# for(i in 1:length(unique(rgs$nct_id))) {
#   nct_id <- unique(rgs$nct_id)[i]
#   study_intervention_NCIt_IDs <- c(unique(interventions$NCIt_ID[interventions$nct_id == nct_id]))
#   print(study_intervention_ids)
#   study_intervention_synonyms <- unique(NCIt_Pharmacologics$Synonyms[NCIt_Pharmacologics$ID %in% study_intervention_NCIt_IDs])
#   if(length(study_intervention_synonyms)==0) next
#   study_intervention_synonyms <- str_c("\\b", study_intervention_synonyms, "\\b", collapse="|")
#   ## collapse the synonyms to create a pattern used to identify
#   
#   print(study_intervention_synonyms)
# }



```

```{r define the pattern used to identify valid synonyms}

## define a pattern that CONTAINS ONLY SYNONYMS FOR THE INTERVENTIONS USED IN THESE STUDIES
## (OTHERWISE R WILL ABORT...)
## omit rows that aren't listed as an intervention in a design group
# NCIt_drugs_preferred <- dplyr::filter(NCIt_drugs_preferred, Synonyms %in% design_group_interventions$intervention_name)


## we will use a pattern that is all the relevant synonyms, collapsed into a single string separated by pipe symbols...
# synonyms_lower_collapsed <- str_c("\\b", unique(NCIt_drugs_preferred$Synonyms_lower), "\\b", collapse="|")

```


```{r write tables to database}
## write tables to database
dbWriteTable(conn = con,name = "drugs.targets", value = drugs.targets, overwrite=TRUE)




dbWriteTable(conn = con,name = "cancerStudiesResults_interventions", value = cancerStudiesResults_interventions, overwrite=TRUE)



dbListTables(con)


```

  
```{r NOT USED filter and retain only result groups for outcomes and events}
## NOTE SOME RESULT GROUPS ARE "TOTAL" i.e. total values for all groups
## these will not be specified as design groups
## if we try to map these onto a design group, the mapping is likely to barf
## WE WILL EXCLUDE THESE GROUPS AT THIS POINT by filtering result groups and retaining only those where result_type = "Outcome" or "Reported Event"... 

# result_groups <- unique(dplyr::filter(result_groups, result_type %in% c("Outcome", "Reported Event")))

```

```{r NOT USED create empty table that will hold predicted mappings}

# result_group_interventions <- data.frame(nct_id = character(0), 
#                                          rg_id = character(0), 
#                                          intervention_id = character(0))
# 
# ## create a vector that will hold list of unmapped result groups
# ## The elements of setdiff(x,y) are those elements in x but not in y
# unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=result_group_interventions$rg_id)
# number_unmapped_rgs <- length(unique(unmapped_result_group_ids))
# proportion_rgs_unmapped <- number_unmapped_rgs/length(unique(result_groups$rg_id))
# unmapped_result_groups <- unique(dplyr::filter(result_groups, rg_id %in% unmapped_result_group_ids))

```

```{r NOT USED concatenate titles and descriptions for unmapped result groups}

# unmapped_result_groups$rg_title_description <- paste(unmapped_result_groups$rg_title, unmapped_result_groups$rg_description, sep = ": ")

## replace mu (micro) symbols with u as this causes mapping function to barf
# unmapped_result_groups$rg_title_description <- gsub(pattern = "\U00B5|\U03BC", replacement = "u", x=unmapped_result_groups$rg_title_description)

```

```{r NOT USED get single arm studies}
# single_arm_study_IDs <- unique(cancerStudies$nct_id[cancerStudies$number_of_arms==1])
# 
# single_arm_result_groups <- unique(dplyr::filter(result_groups, nct_id %in% single_arm_study_IDs))
# single_arm_result_groups <- unique(dplyr::select(single_arm_result_groups, nct_id, rg_id))
# ## join to interventions on nct_id alone, means all interventions will be mapped to all result groups for those studies
# single_arm_result_groups <- unique(merge(x = single_arm_result_groups, by.x = "nct_id", y=dplyr::select(interventions, nct_id, intervention_id), by.y = "nct_id"))
  

## row bind onto empty result group interventions table
# result_group_interventions <- rbind(result_group_interventions, single_arm_result_groups)
# 
# 
# ## update vector of unmapped result groups
# unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=result_group_interventions$rg_id)
# number_unmapped_rgs <- length(unique(unmapped_result_group_ids))
# proportion_rgs_unmapped <- number_unmapped_rgs/length(unique(result_groups$rg_id))
# unmapped_result_groups <- unique(dplyr::filter(unmapped_result_groups, rg_id %in% unmapped_result_group_ids))


```

```{r NOT USED match design and result group titles}

## convert titles to lower
# unmapped_result_groups$rg_title_lower <- tolower(unmapped_result_groups$rg_title)
# design_groups$dg_title_lower <- tolower(design_groups$dg_title)
# 
# mapped_result_groups <- merge(x=unique(dplyr::select(unmapped_result_groups, nct_id, rg_id, rg_title_lower)), by.x = c("nct_id", "rg_title_lower"), all.x = FALSE, y= unique(dplyr::select(design_groups, nct_id, dg_title_lower, intervention_id)), by.y = c("nct_id", "dg_title_lower"), all.y = FALSE)
# 
# ## drop the title
# mapped_result_groups <- unique(dplyr::select(mapped_result_groups, nct_id, rg_id, intervention_id))


# ## row bind onto result group interventions table
# result_group_interventions <- unique(rbind(result_group_interventions, mapped_result_groups))
# 
# 
# ## update vector of unmapped result groups
# unmapped_result_group_ids <- setdiff(x=result_groups$rg_id, y=result_group_interventions$rg_id)
# number_unmapped_rgs <- length(unique(unmapped_result_group_ids))
# proportion_rgs_unmapped <- number_unmapped_rgs/length(unique(result_groups$rg_id))
# unmapped_result_groups <- unique(dplyr::filter(unmapped_result_groups, rg_id %in% unmapped_result_group_ids))


```

```{r NOT USED exclude studies that are not in unmapped design groups}
## some studies (e.g. NCT00058539) do not specify number of arms, nor do they have any design groups to map to 
## at least one of these (NCT00065182) has more than one group, and treatments differ between groups

## for now, we will exclude these from unmapped_result_groups
# unmapped_result_groups <- unique(dplyr::filter(unmapped_result_groups, nct_id %in% design_groups$nct_id))

```

```{r NOT USED define stopwords}
# stopwords <- as.data.frame(tidytext::get_stopwords())
```

```{r NOT USED get design groups for unmapped result groups}

# unmapped_design_groups <- unique(dplyr::filter(design_groups, nct_id %in% unmapped_result_groups$nct_id))
# 
# ## concatenate title and description
# unmapped_design_groups$dg_title_description <- paste(unmapped_design_groups$dg_title, unmapped_design_groups$dg_description, sep = ": ")
# 
# ## drop interventions column, as this leads to unnecessary duplication of rows for groups with >1 intervention
# unmapped_design_groups <- unique(dplyr::select(unmapped_design_groups, nct_id, dg_id, dg_title_description))
# 
# ## replace greek symbols with letters as this causes mapping function to barf
# unmapped_design_groups$dg_title_description <- gsub(pattern = "\U00B5|\U03BC", replacement = "u", x=unmapped_design_groups$dg_title_description)

```

```{r NOT USED define function to create document term matrix}

## define a function that will... 
# accept custom tokens to be included in tokenisation
# create document-term matrix

# create_dtm <- function(dataframe, text_column, id_column, custom_tokens) {
#   ## get the text column to be used
#   text_column_num <- which(names(dataframe)==text_column)
#   text <- dataframe[ , text_column_num]
#   ## remove anything that is not a number or letter...
#   text <- str_squish(str_replace_all(string = text, "[^a-zA-Z0-9]", replacement = " "))
#   ## overwrite the text column  
#   dataframe[ , text_column_num] <- text
# 
#   
#   ## 1. TOKENISE THE TEXT COLUMN
#   ## need to tokenise using corpus function, as this allows drug synonyms, inc multi word synonyms, to be specified upfront as tokens so they don't get split
#   dataframe$word <- as.list(corpus::text_tokens(x=dataframe[ , text_column_num], filter= corpus::text_filter(combine = custom_tokens, map_case=TRUE, connector="_", drop_punct=TRUE )))
#   ## unnest
#   dataframe <- as.data.frame(unnest(data = dataframe, word)) 
#   ## this function does insist on replacing whitespace with a character (here, underscore), so need to swap that back to whitespace
#   # dataframe$word <- gsub(pattern = "_", replacement = " ", x=dataframe$word)
#   ## remove stopwords
#   # dataframe <- anti_join(x=dataframe, y=stopwords)
#   
#   ## 2. CREATE DOCUMENT-TERM MATRIX
#   ## count each word in each description
#   dataframe <- dataframe %>% 
#     group_by_at(id_column) %>%
#     count(word, sort=FALSE) %>%
#     ungroup() %>%
#     as.data.frame()
#   ## use reshape2::dcast so get a dataframe as a result
#   dataframe <- reshape2::dcast(data=dataframe, formula = as.formula(paste(id_column, "~ word")), value.var = "n")
#   ## convert NA to zero
#   dataframe <- dataframe %>% mutate_all(~replace(., is.na(.), 0))
#   ## convert id to factor
#   dataframe[ , which(names(dataframe)==id_column)] <- as.factor(dataframe[ , which(names(dataframe)==id_column)])
#   
#   ## 3. RETURN DOCUMENT-TERM MATRIX
#   return(dataframe)
# }

```

```{r NOT USED create an empty dataframe that will hold predicted mappings dg to rg}

# predictions <- data.frame(nct_id = character(0),
#                           rg_id = character(0), 
#                           predicted_design_group = character(0)
#                           )


```

```{r NOT USED loop through unmapped result groups}
# for(i in 1:length(unique(unmapped_design_groups$nct_id))) {
#   #print(paste0(i, "/", length(unique(unmapped_result_groups$rg_id))))
#   
#   study_id <- unique(unmapped_design_groups$nct_id)[i]
#   #print(study_id)
#   
#   temp_unmapped_dgs <- unique(dplyr::filter(unmapped_design_groups, nct_id == study_id))
#   ## get study interventions (verbatim) to use as custom tokens
#   study_interventions_verbatim <- unique(interventions$intervention_name[interventions$nct_id==study_id])
#   
#   ## get synonyms for study interventions to use as custom tokens
#   study_interventions_NCItID <- unique(interventions$NCIt_ID[interventions$nct_id==study_id])
#   study_interventions_synonyms <- unique( NCIt_Pharmacologics$Synonyms[NCIt_Pharmacologics$ID %in% study_interventions_NCItID])
#   #print(study_interventions_synonyms)
#   
#   ## get design group titles to use as custom tokens
#   design_group_titles <- unique(design_groups$dg_title[design_groups$nct_id==study_id])
#   #print(design_group_titles)
#   
#   tokens <- unique(c(study_interventions_synonyms, design_group_titles,study_interventions_verbatim))
#   
#   ## create document term matrix
#   unmapped_dgs_dtm <- create_dtm(dataframe = temp_unmapped_dgs, text_column = "dg_title_description", id_column = "dg_id", custom_tokens = tokens)
#   #print(unmapped_dgs_dtm)
#   
#   
#   
#   
#   
#   
#   temp_unmapped_rgs <- unique(dplyr::filter(unmapped_result_groups, nct_id == study_id))
#   
#   
#   ## create DTM for result group descriptions
#   unmapped_rgs_dtm <- create_dtm(dataframe = temp_unmapped_rgs, text_column = "rg_title_description", id_column = "rg_id", custom_tokens = tokens)
#   #print(unmapped_rgs_dtm)
#   ## make names valid, otherwise rpart will barf...
#   names(unmapped_dgs_dtm) <- gsub(" ", "_", names(unmapped_dgs_dtm))
#   names(unmapped_rgs_dtm) <- gsub(" ", "_", names(unmapped_rgs_dtm))
#   
#   ## get those column names that are common to both dtms
#   common_terms <- intersect(names(unmapped_dgs_dtm), names(unmapped_rgs_dtm))
#   
#   ## drop any common_terms that are numbers
#   common_terms <- common_terms[is.na(as.numeric(common_terms))]
#   
#   ## drop any common terms that are stopwords
#   common_terms <- common_terms[!(common_terms %in% stopwords$word)]
#   ## if no common terms, skip to next study
#   if(length(common_terms)==0) next
#   
#   ## drop non-overlapping columns from DGs_dtm
#   unmapped_dgs_dtm <- dplyr::select(unmapped_dgs_dtm, dg_id, all_of(common_terms))
#   #print(unmapped_dgs_dtm)
#   
#   tryCatch({
#             ## create decision tree model
#             modFit <- rpart::rpart(formula = dg_id ~., method = "class", data = unmapped_dgs_dtm, control =rpart.control(minsplit = 1,minbucket=1, cp=0))
#             ## (optional) print tree
#             #rpart.plot(modFit)
#             ## predict design group for each result group
#             study_predictions <- data.frame(nct_id = as.character(study_id),
#                           rg_id = as.character(unmapped_rgs_dtm$rg_id), 
#                           predicted_design_group = as.character(predict(object = modFit, unmapped_rgs_dtm, type = "class"))
#                           )
#             #print(study_predictions)
#             
#             }, error=function(cond) {
#               return(study_predictions <- data.frame(nct_id = study_id,
#                                                      result_group_id = unmapped_rgs_dtm$rg_id,
#                                                      predicted_design_group = NA
#                           ))})
#   
#   ## row bind study predictions onto predictions table
#   predictions <- unique(rbind(predictions, study_predictions))
#   
#   
# }




```

```{r NOT USED join descriptions to sanity check}
# predictions$nct_id <- as.character(predictions$nct_id)
# predictions$rg_id <- as.character(predictions$rg_id)
# predictions$predicted_design_group <- as.character(predictions$predicted_design_group)
# 
# ## join result group titles and descriptons
# predictions <- merge(x=predictions, by.x=c("nct_id", "rg_id"), y=dplyr::select(unmapped_result_groups, nct_id, rg_id, rg_title_description), by.y=c("nct_id", "rg_id"))
# 
# ## join design group titles and descriptions
# predictions <- merge(x=predictions, by.x=c("nct_id", "predicted_design_group"), y=dplyr::select(unmapped_design_groups, nct_id, dg_id, dg_title_description), by.y=c("nct_id", "dg_id"))
# 
# 
# ## save predictions as a table in database


```

```{r NOT USED write predictions to database}
## create as a table in database
# dbWriteTable(conn = con,name = "predictions", value = predictions, overwrite=TRUE)
# 
# ## check it has saved
# dbListTables(con)

```



 
   
   