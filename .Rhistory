modFit <- train(wage ~ age + jobclass + education,
method = "lm",
data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod, pch=19, cex=0.5,col="#00000010")
qplot(finMod$fitted.values, finMod$residuals, colour=race, data=training)
plot(finMod$residuals, pch=19)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisaease)
data(AlzheimerDisease)
data("concrete")
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training <- mixtures[inTrain, ]
testing <- mixtures[-inTrain, ]
qplot(training$CompressiveStrength)
plot(training$CompressiveStrength)
names(training)
plot(training$CompressiveStrength, colour="Cement")
qplot(training$CompressiveStrength, colour="Cement")
qplot(training$CompressiveStrength,seq_along(training$CompressiveStrength) colour="Cement")
qplot(training$CompressiveStrength,seq_along(training$CompressiveStrength), colour="Cement")
plot(training$CompressiveStrength, colour="Cement")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="Cement")
names(training)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="BlastFurnaceSlag")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="FlyAsh")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=Cement)
unique(training$Cement)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="Cement")
?cut2
libary(Hmisc)
library(Hmisc)
?cut2
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Cement))
head(training)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$BlastFurnaceSlag))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$FlyAsh))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Water))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Age))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$FlyAsh))
qplot(training$Superplasticizer)
log(training$Superplasticizer)
set.seed(3433)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
names(training)
grep(pattern = "IL", x=names(training))
head(training[ ,grep(pattern = "IL", x=names(training))])
head(training[ ,grep(pattern = "^IL", x=names(training))])
subTraining <- training[ ,grep(pattern = "^IL", x=names(training))]
prComp <- prcomp(subTraining)
head(prComp)
summary(prComp)
preObj <- preProcess(training[ ,grep(pattern = "^IL", x=names(training))])
summary(preObj)
class(preObj)
preObj$rotation
set.seed(3433)
data(AlzheimerDisease)
names(training)
rm(list=ls())
rm(list=ls())
data("iris")
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
modFit <- train(Species ~ ., data=training, method="rf", prox=TRUE)
modFit <- train(Species ~ ., data=training, method="rf", prox=TRUE)
modFit
getTree(modFit$finalModel, k=2)
library(randomForest)
getTree(modFit$finalModel, k=2)
irisP <- classCenter(training[ ,c(3,4)], training$Species, modFit$finalModel$proximity)
class(irisP)
irisP <- as.data.frame(irisP)
head(irisP)
irisP
irisP$Species <- rownames(irisP)
irisP
p <- qplot(Petal.Width, Petal.Length, col=Species, data=training)
p+ geom_point(aes(x=Petal.Width, y=Petal.Length, col=Species), size=5, shape=4, data=irisP)
pred <- predict(modFit, testing)
testing$predRight <- pred==testing$Species
table(pred, testing$Species)
qplot(Petal.Width, Petal.Length, colour=predRight,data=testing, main="newdata Predictions")
rm(list=ls())
library(caret)
data("iris")
head(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[ -inTrain, ]
head(training)
sample(x=training, size=5, replace = TRUE)
?sample
X[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]  ## sample 5 rows from training dataset, all variables
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
split0 <- training[sample(nrow(training),size=5,replace=TRUE),]  ## sample 5 rows from training dataset, all variables
split1 <- training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
split2 <- training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
install.packages("ineq")
library(ineq)
modFit <- train(Species ~ ., method="rpart", data=split0)
head(split0)
split0 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]  ## sample 5 rows from training dataset, all variables
modFit <- train(Species ~ ., method="rpart", data=split0)
library(rattle)
fancyRpartPlot(modFit$finalModel)
split(split0, Petal.Length < 2.6)
split(split0, split0$Petal.Length < 2.6)
split(split0, split0$Petal.Length < 2.6)[[1]]
split1.1 <- split(split0, split0$Petal.Length < 2.6)[[1]]
head(split1.1)
split1.2 <- split(split0, split0$Petal.Length < 2.6)[[2]]
head(split1.2)
split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
modFit <- train(Species ~ ., method="rpart", data=split1.1)
fancyRpartPlot(modFit$finalModel)
split2.1 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[1]]
head(split2.1)
split2.2 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[2]]
head(split2.2)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]  ## sample rows from training dataset, all variables
split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
head(split1.1)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
split1.2 <- training[sample(nrow(training),size=nrow(split1.2),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.2)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE))
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
> split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
> split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
head(split1.1)
head(split1.2)
?getTree
library(randomForest)
?getTree
modFit <- train(Species ~ ., data = training, method="rf", prox=TRUE)
getTree(modFit$finalModel, k=1)
class(getTree(modFit$finalModel, k=1))
fancyRpartPlot(getTree(modFit$finalModel, k=1))
cforest(Species ~ ., data=training, controls=cforest_control(mtry=2, mincriterion=0))
rm(list=ls())
data("iris")
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
head(training)
> modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
library(rattle)
fancyRpartPlot(modFit$finalModel) ## nicer looking plot
split1.1 <- split(training, Petal.Length<2.5)[[1]]
split1.1 <- split(training, training$Petal.Length<2.5)[[1]]
split1.2 <- split(training, training$Petal.Length<2.5)[[2]]
head(split1.1,10)
head(split1.2,10)
head(training,10)
table(iris$Species)
table(training$Species)
table(split1.1$Species)
table(split1.2$Species)
split2.1 <- split(split1.1, split1.1$Petal.Width<1.6)[[1]]
split2.2 <- split(split1.1, split1.1$Petal.Width<1.6)[[2]]
head(split2.1)
table(split2.1$Species)
head(split2.2)
table(split2.2$Species)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
table(split1.1$Species)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
table(split1.2$Species)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
evidence <- read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
dim(evidence)
names(evidence)
"H773_V774insAH" %in% evidence$variant
filter(evidence, gene=="EGFR")
library(dplyr)
filter(evidence, gene=="EGFR")
unique(filter(evidence, gene=="EGFR"))
unique(filter(evidence, gene=="EGFR"))$variant
sort(unique(filter(evidence, gene=="EGFR"))$variant)
sort(unique(filter(evidence, gene=="MYC"))$variant)
sort(unique(filter(evidence, gene=="MYC")))
unique(filter(evidence, gene=="MYC"))
sort(unique(filter(evidence, gene=="FGFR3"))$variant)
unique(filter(evidence, gene=="FGFR3"))
unique(filter(evidence, gene=="KRAS"))
unique(filter(evidence, gene=="KRAS"))$variant
sort(unique(filter(evidence, gene=="FGFR3")$variant))
sort(unique(filter(evidence, gene=="KRAS")$variant))
unique(filter(evidence, gene=="KRAS" & variant =="Q61R"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61.*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61"))
rm(list=ls())
getwd()
rm(list=ls())
# Chunk 1: setup
require(flexdashboard)
require(dplyr)
require(tidyr)
require(kableExtra)
require(shinyWidgets)
require(leaflet)
require(htmltools)
require(rjson)
require(RSQLite)
#require(DT)
## load configuration data from JSON file
configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
# [1] "interventions"      "locations"          "postcode"
#  [4] "nct_id"             "brief_title"        "overall_status"
#  [7] "condition"          "site_name"          "site_status"
# [10] "investigators"      "contacts"           "Refresh.date"
# [13] "matching.condition" "TARGET.condition"   "Link"
# [16] "postcode.lat"       "postcode.long"      "lat"
# [19] "long"               "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
# conditionSynonyms <- read.csv(file="conditionSynonyms4.csv", header = TRUE, stringsAsFactors = FALSE)
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
getwd()
setwd("GitHub/cancer-trial-match")
# Chunk 1: setup
require(flexdashboard)
require(dplyr)
require(tidyr)
require(kableExtra)
require(shinyWidgets)
require(leaflet)
require(htmltools)
require(rjson)
require(RSQLite)
#require(DT)
## load configuration data from JSON file
configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
# [1] "interventions"      "locations"          "postcode"
#  [4] "nct_id"             "brief_title"        "overall_status"
#  [7] "condition"          "site_name"          "site_status"
# [10] "investigators"      "contacts"           "Refresh.date"
# [13] "matching.condition" "TARGET.condition"   "Link"
# [16] "postcode.lat"       "postcode.long"      "lat"
# [19] "long"               "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
# conditionSynonyms <- read.csv(file="conditionSynonyms4.csv", header = TRUE, stringsAsFactors = FALSE)
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
gene_variant_type.list <- sort(unique(scoredMatches$gene_variant_type))
head(gene_variant_type.list)
selectedAlterations <- "EGFR mutation"
table <- scoredMatches
table <- dplyr::filter(table, gene_variant_type %in% selectedAlterations)
table
tableScored <- scoredMatches
tableScored <- dplyr::filter(tableScored, gene_variant_type %in% selectedAlterations)
tableStudies <- cancerStudies
tableStudies <- merge(x=tableStudies, by.x=c("nct_id"), all.x=TRUE,
y=tableScored, by.y=c("nct_id"))
head(tableStudies)
tableStudies$combined_score[is.na(tableStudies$combined_score)] <- 0
head(tableStudies)
tableStudies <- tableStudies[order(tableStudies$combined_score, decreasing = TRUE), ]
head(tableStudies)
tableStudies[is.na(tableStudies)] <- "-"
head(tableStudies)
?arrange
head(tableStudies)
tableStudies %>%
arrange(desc(nct_id))
tableStudies %>%
arrange(desc(nct_id)) %>%
head()
tableStudies %>%
arrange(desc(nct_id)) %>%
head() %>%
arrange(desc(combined_score)) %>%
head()
tableStudies %>%
arrange(desc(nct_id)) %>%
#head() %>%
arrange(desc(combined_score)) %>%
head()
tableStudies %>%
arrange(desc(nct_id)) %>%
#head() %>%
aggregate( by=tableStudies['nct_id'], function(x) {paste(unique(x), collapse = ";\n")}) %>%
arrange(desc(combined_score)) %>%
head()
rlang::last_error()
rlang::last_trace()
tableStudies %>%
arrange(desc(nct_id)) %>%
#head() %>%
aggregate( by=tableStudies['nct_id'], function(x) {paste(unique(x), collapse = ";\n")}) %>%
#arrange(desc(combined_score)) %>%
head()
tableStudies %>%
arrange(desc(nct_id)) %>%
#head() %>%
aggregate( by=tableStudies['nct_id'], function(x) {paste(unique(x), collapse = ";\n")}) %>%
#arrange(desc(combined_score)) %>%
names()
cancerStudies[0, ]
?validate
?DTOutput
?showNotification
?showModal
?validate
strsplit(x="ERBB2 amplification,KRAS mutation", split=",")
class(strsplit(x="ERBB2 amplification,KRAS mutation", split=","))
class(unlist(strsplit(x="ERBB2 amplification,KRAS mutation", split=",")))
unlist(strsplit(x="ERBB2 amplification,KRAS mutation", split=","))
?selectInput
class(unlist(strsplit(x="ERBB2 amplification,KRAS mutation", split=",")))
length(unlist(strsplit(x="ERBB2 amplification,KRAS mutation", split=",")))
url <- "http://en.wikipedia.org/wiki/api.php"
param_set(url, key = "pageid", value = "12")
install.packages("urltools")
library(urltools)
param_set(url, key = "pageid", value = "12")
param_set(url, key = "pageid", value = c("12", "13"))
class(c("ERBB2 amplification", "KRAS mutation"))
x <- data.table(letters[1:4], 1:4)
library(DT)
x <- data.table(letters[1:4], 1:4)
?datatable
x <- datatable(letters[1:4], 1:4)
?datatable
length(names(table)
)
View(table)
sort(unique(cancerStudies$gene_variant_type))
sort(unique(scoredMatches$gene_variant_type))
?scrollY
?DT::scrollY
unique(c(names(cancerStudies), names(scoredMatches)))
shortlistNames <- unique(c(names(cancerStudies), names(scoredMatches)))
shortlist <- data.frame()
shortlist
colnames(shortlist) <- shortlistNames
data.frame(matrix(ncol=length(shortlistNames),nrow=0, dimnames=shortlistNames))
data.frame(matrix(ncol=length(shortlistNames),nrow=0, dimnames=list(shortlistNames)))
list(shortlistNames)
data.frame(matrix(ncol=length(shortlistNames),nrow=0, dimnames=list(NULL, shortlistNames)))
shortlist <- data.frame(matrix(ncol=length(shortlistNames),nrow=0, dimnames=list(NULL, shortlistNames)))
createEmptyShortlist <- function() {
## get column names from a merge of cancerStudies and scoredMatches
shortlistNames <- unique(c(names(cancerStudies), names(scoredMatches)))
## create empty dataframe
shortlist <- data.frame(matrix(ncol=length(shortlistNames),nrow=0, dimnames=list(NULL, shortlistNames)))
## return empty shortlist
return(shortlist)
}
createEmptyShortlist()
shortlist <-createEmptyShortlist()
shortlistNames
mergedStudyTableStatisHead <- merge(x=head(cancerStudies), by.x=c("nct_id")
y=head(scoredMatches), by.y=c("nct_id"))
mergedStudyTableStaticHead <- merge(x=head(cancerStudies), by.x=c("nct_id"),
y=head(scoredMatches), by.y=c("nct_id"))
mergedStudyTableStaticHead
setdiff(names(mergedStudyTableStaticHead), names(shortlistNames))
setdiff(names(mergedStudyTableStaticHead), names(shortlist))
filter(scoredMatches, gene_variant_type %in% NULL)
testScored <- filter(scoredMatches, gene_variant_type %in% NULL)
merge(x=head(cancerStudies), by.x="nct_id", all.x=TRUE, y=testScored, by.y="nct_id")
