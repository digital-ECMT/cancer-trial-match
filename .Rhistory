LEFT JOIN facility_investigators fi ON f.id=fi.facility_id
WHERE f.country LIKE ('",
country,
"')
AND s.study_type LIKE ('Interventional')
AND s.overall_status IN ('Recruiting')
AND f.status IN ('Recruiting', 'Not yet recruiting')")
## get data from clinicaltrials.gov
openStudies <- dbGetQuery(conn2,openStudiesQ)
View(openStudies)
rm(list=ls())
getwd()
rmarkdown::render("trialMatchDataRefresh.Rmd")
library(jsonlite)
jsonlite::fromJSON(file = "trialMatchConfiguration.json")
jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
configuration <- jsonlite::fromJSON(file = "trialMatchConfiguration.json")
aact.username <- configuration$aact.username
aact.password <- configuration$aact.password
configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
aact.username <- configuration$aact.username
aact.password <- configuration$aact.password
aact.password
aact.username
jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
View(locations)
?toJSON
toJSON(locations)
require(flexdashboard)      ## MIT
require(dplyr)              ## MIT
require(tidyr)              ## MIT
require(kableExtra)         ## MIT
require(shinyWidgets)       ## GPL-3
require(leaflet)            ## GPL-3
require(htmltools)          ## GPL-2 | GPL-3
# require(rjson)
require(jsonlite)           ## MIT
require(RSQLite)            ## LGPL-2.1 | LGPL-3
require(DT)                 ## GPL-3
require(DBI)                ## LGPL-2.1 | LGPL-3
## load configuration data from JSON file
configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
#configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 1: setup
require(flexdashboard)      ## MIT
require(dplyr)              ## MIT
require(tidyr)              ## MIT
require(kableExtra)         ## MIT
require(shinyWidgets)       ## GPL-3
require(leaflet)            ## GPL-3
require(htmltools)          ## GPL-2 | GPL-3
# require(rjson)
require(jsonlite)           ## MIT
require(RSQLite)            ## LGPL-2.1 | LGPL-3
require(DT)                 ## GPL-3
require(DBI)                ## LGPL-2.1 | LGPL-3
## load configuration data from JSON file
configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
#configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## get refresh date
refresh.date <- unique(cancerStudies$Refresh.date)
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
#  [1] "interventions"      "locations"          "postcode"           "nct_id"
#  [5] "brief_title"        "overall_status"     "condition"          "site_name"
#  [9] "site_status"        "investigators"      "contacts"           "central_contacts"
# [13] "Refresh.date"       "matching.condition" "TARGET.condition"   "Link"
# [17] "postcode.lat"       "postcode.long"      "lat"                "long"
# [21] "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
conditionSynonyms <- dbGetQuery(con, "SELECT * FROM cancers")
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts,central_contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
central_contacts = toString(sort(unique(na.omit(central_contacts)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
rjson::fromJSON(file = "trialMatchConfiguration.json")
# Chunk 1: setup
require(jsonlite)           ## MIT
require(flexdashboard)      ## MIT
require(dplyr)              ## MIT
require(tidyr)              ## MIT
require(kableExtra)         ## MIT
require(shinyWidgets)       ## GPL-3
require(leaflet)            ## GPL-3
require(htmltools)          ## GPL-2 | GPL-3
require(rjson)              ## GPL-2
require(RSQLite)            ## LGPL-2.1 | LGPL-3
require(DT)                 ## GPL-3
require(DBI)                ## LGPL-2.1 | LGPL-3
## load configuration data from JSON file
#configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
configuration <- rjson::fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## get refresh date
refresh.date <- unique(cancerStudies$Refresh.date)
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
#  [1] "interventions"      "locations"          "postcode"           "nct_id"
#  [5] "brief_title"        "overall_status"     "condition"          "site_name"
#  [9] "site_status"        "investigators"      "contacts"           "central_contacts"
# [13] "Refresh.date"       "matching.condition" "TARGET.condition"   "Link"
# [17] "postcode.lat"       "postcode.long"      "lat"                "long"
# [21] "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
conditionSynonyms <- dbGetQuery(con, "SELECT * FROM cancers")
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts,central_contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
central_contacts = toString(sort(unique(na.omit(central_contacts)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
aact.password
?postcode_lookup
world.cities
install.packages("tidygeocoder")
geo(address = c("Tokyo, Japan", "Lima, Peru", "Nairobi, Kenya"),
method = 'osm')
library(tidygeocoder)
geo(address = c("Tokyo, Japan", "Lima, Peru", "Nairobi, Kenya"),
method = 'osm')
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
##NOTE: the following packages are required to run this script, but should be installed (e.g. using code snippets below) before runnning the script, NOT as part of the script itself
# options(repos = "http://cran.us.r-project.org")
# install.packages("BiocManager")
# BiocManager::install("AnnotationDbi")
# BiocManager::install("org.Hs.eg.db")
# BiocManager::install("KEGGREST")
# BiocManager::install("KEGGlincs")
# BiocManager::install("hgu133a.db")
require(KEGGlincs)        ## GPL-3
require(KEGGgraph)        ## GPL >= 2
require(org.Hs.eg.db)     ## Artistic-2.0
require(KEGGREST)         ## Artistic 2.0
require(DBI)              ## LGPL-2.1 | LGPL-3
# require(RPostgreSQL)    ## GPL-2
require(RODBC)            ## GPL-2 | GPL-3
require(RPostgres)        ## GPL-3
require(RSQLite)          ## LGPL-2.1 | LGPL-3
# require(rjson)          ## GPL-2
require(jsonlite)         ## MIT
require(dplyr)            ## MIT
require(tidyr)            ## MIT
require(formattable)      ## MIT
require(kableExtra)       ## MIT
require(stringr)          ## MIT
#require(stringi)
require(splitstackshape)  ## GPL-3
require(reshape2)         ## MIT
require(tictoc)           ## Apache License (== 2.0
require(maps)             ## GPL-2
require(leaflet)          ## GPL-3
require(PostcodesioR)     ## GPL-3
require(igraph)           ## GPL-2 | GPL-3
require(tidygeocoder)
## clean up first
rm(list=ls())
##get today's date
today <- format(Sys.Date(), format = "%d %B %Y")
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
dbListTables(con)
## conditionSynonyms specifies which cancer types are of interest, and which condition names (as used by clinicaltrials.gov) will be considered as matches for each
## synonyms define on basis of those in clinicaltrials.gov
#conditionSynonyms <- read.csv(file = "conditionSynonyms4.csv", stringsAsFactors = FALSE)
## updated set of more granular cancer types
conditionSynonyms <- read.csv(file = "conditionSynonyms5.csv", stringsAsFactors = FALSE)
## trim leading/trailing whitespace
conditionSynonyms$condition.synonyms <- str_squish(string = conditionSynonyms$condition.synonyms)
## remove redundancy, if any
conditionSynonyms <- unique(conditionSynonyms)
## display conditions and synonyms used
# formattable(as.data.frame(conditionSynonyms %>%
#                   group_by(controlled.cancer.type) %>%
#                   summarise(
#                   synonyms = paste(condition.synonyms, collapse = ", "))))
## preview
formattable(head(conditionSynonyms))
## create as a table in database
dbWriteTable(conn = con,name = "cancers", value = conditionSynonyms, overwrite=TRUE)
## check it has saved
dbListTables(con)
## start timer
tic("download a list of all human genes and their synonyms")
humanGenes <- read.table(file = "humanGenes.tsv", header = TRUE, quote = "", sep = "\t", fill = TRUE, stringsAsFactors = FALSE)
humanGenes <- dplyr::select(humanGenes, Symbol, Aliases)## drop everything except Symbol and Aliases columns
humanGenes$Aliases <- strsplit(x=humanGenes$Aliases, split = ",")## split the aliases on comma
humanGenes <- unnest(data = humanGenes, cols = Aliases, keep_empty = TRUE) ## unnest to multiply rows, keep any rows with no aliases
humanGenes <- as.data.frame(humanGenes) ## convert to data frame
humanGenes$Aliases <- str_squish(string = humanGenes$Aliases) ## trim excess whitespace from Aliases values
## Symbol values are not represented among Aliases
# create a data frame with unique Symbol values
symbols <- data.frame("Symbol"=unique(humanGenes$Symbol), "Aliases"=unique(humanGenes$Symbol))
# bind this onto bottom of humanGenes data frame
humanGenes <- rbind(humanGenes,symbols)
# remove duplicated values, if any
humanGenes <- unique(humanGenes)
# sort on Symbol values
humanGenes <- humanGenes[order(humanGenes$Symbol), ]
# drop any rows where Aliases is NA
humanGenes <- humanGenes[!is.na(humanGenes$Aliases), ]
## drop any rows where Aliases value is only a single character
## NOW humanGenes TABLE CONTAINS ALL HUMAN GENES AND THEIR SYNONYMS
## (61,593 unique symbols, 130,989 rows)
## stop timer
toc()
## preview
formattable(head(humanGenes))
## create as a table in database
dbWriteTable(conn = con,name = "genes", value = humanGenes, overwrite=TRUE)
## check it has saved
dbListTables(con)
## download variant summaries from clinvar
download.file(url="https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz",destfile = "variant_summary.txt.gz")
clinvar <- read.table(gzfile("variant_summary.txt.gz"), sep="\t", quote="", fill = TRUE, stringsAsFactors = FALSE)
# V1 contains values for Allele ID
# V2 gives nature (e.g. fusion, single nucleotide variant etc)
# V7 contains values for clinical significance (inc whether pathogenic or not)
# V25 gives a measure of confidence in assertion
clinvar <- unique(dplyr::select(clinvar, "allele.id" = "V1", "nature"="V2", "significance"="V7", "confidence"="V25"))
## variation_allele contains mappings from clinvar variation ID (clinvar ID) and allele ID
download.file(url="https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variation_allele.txt.gz",destfile = "variation_allele.txt.gz")
variationAllele <- read.table(gzfile("variation_allele.txt.gz"), sep="\t", quote="", fill = TRUE, stringsAsFactors = FALSE)
# V1 contains values for clinvar ID
# V3 contains values for Allele ID
variationAllele <- unique(dplyr::select(variationAllele, "clinvar.id"="V1", "allele.id"="V3"))
## join tables
clinvar <- merge(x=clinvar, by.x="allele.id", y=variationAllele, by.y="allele.id")
# variants contains mappings from variant_id to clinvar_ids
variants <- read.csv(file = "https://civicdb.org/downloads/nightly/nightly-VariantSummaries.tsv", sep = "\t", quote = "", stringsAsFactors = FALSE)
# variants$gene contains gene name (Entrez symbol)
# variants$variant contains amino acid change
# variants$summary contains a useful summary of evidence for each variant
# variants$clinvar_ids contains (comma-separated) clinvar IDs that can be mapped to the clinvar table to get info whether pathogenic or not...
## drop unwanted columns
variants <- unique(dplyr::select(variants, variant_id, gene, variant, summary, variant_groups,civic_variant_evidence_score,clinvar_ids ))
## split and unnest the clinvar_ids column
variants$clinvar_ids <- strsplit(as.character(variants$clinvar_ids), split = ",")
variants <- unnest(data = variants, clinvar_ids)
## join significance from clinvar
variants <- unique(merge(x=variants, by.x="clinvar_ids", all.x=TRUE, y=clinvar, by.y="clinvar.id"))
## drop unwanted columns
variants <- unique(dplyr::select(variants,variant_id, clinvar_ids,gene,variant,summary,variant_groups, significance,confidence))
## split on the word "and"
variants$variant <- strsplit(x=variants$variant, split = " and ")
variants <- unnest(data = variants, cols = variant, keep_empty = TRUE) ## unnest to multiply rows, keep any rows with no aliases
variants <- as.data.frame(variants) ## convert to datack a frame
## trim everything after first space in variants$variant
variants$variant <- gsub(pattern = " .*", replacement = "", x=variants$variant)
## preview
formattable(head(variants))
## create as a table in database
dbWriteTable(conn = con,name = "variants", value = variants, overwrite=TRUE)
## check it has saved
dbListTables(con)
## download evidence from civicDB
# evidence contains mappings from variant_id to gene (gene name) and variant (amino acid change) to drugs etc
evidence <- read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t", quote="", stringsAsFactors = FALSE)
# evidence contains more detailed data re: drugs, sensitivity etc
# evidence$evidence_level contains details of nature of evidence:
# A = validated
# B = clinical
# C = case study
# D = preclinical
## drop unwanted columns
evidence <- unique(dplyr::select(evidence, variant_id, disease, drugs,  evidence_type, evidence_direction,evidence_level,clinical_significance,evidence_statement))
evidence <- as.data.frame(evidence)
## unnest the drugs column
evidence$drugs <- strsplit(x=evidence$drugs, split=",")
evidence <- unnest(data = evidence, cols = drugs, keep_empty = TRUE)
evidence <- as.data.frame(evidence) ## convert to data frame
## preview
formattable(head(evidence))
## create as a table in database
dbWriteTable(conn = con,name = "evidence", value = evidence, overwrite=TRUE)
## check it has saved
dbListTables(con)
## print a list of disease in evidence table, but not represented among condition synonyms
# setdiff(x=unique(evidence$disease), y=unique(conditionSynonyms$condition.synonyms))
## specify user name and password for AACT account
## see https://aact.ctti-clinicaltrials.org/ for how to create an account
## load configuration data from JSON file
## configuration <- rjson::fromJSON(file = "trialMatchConfiguration.json")
## jsonlite is MIT
configuration <- jsonlite::fromJSON(txt = "trialMatchConfiguration.json")
aact.username <- configuration$aact.username
aact.password <- configuration$aact.password
# drv <- dbDriver("PostgreSQL")    ## need RPostgreSQL library to do this
# conn2 <- dbConnect(drv, dbname="aact",host="aact-db.ctti-clinicaltrials.org", port=5432, user=aact.username, password=aact.password )
## connect via odbc
## need PostgreSQL driver installation
# conn2 <- DBI::dbConnect(odbc::odbc(),
#                       Driver   = "PostgreSQL",
#                       Server   = "aact-db.ctti-clinicaltrials.org",
#                       Database = "aact",
#                       UID      = aact.username,
#                       PWD      = aact.password,
#                       Port     = 5432)
## connect via RPostgres (GPL-3 licence)
drv = RPostgres::Postgres()
conn2 <- dbConnect(drv, dbname="aact",host="aact-db.ctti-clinicaltrials.org", port=5432, user=aact.username, password=aact.password )
## get country name specified in configuration file
country <- configuration$country
## get interventional studies for country specified in configuration file
## any indication
## with sites in specified country that have a status of "Recruiting" or "Not yet recruiting"
# form query
openStudiesQ <- paste0("SELECT s.nct_id, s.brief_title, s.overall_status, c.name AS condition, i.name AS interventions, f.name AS site_name,
f.city AS locations, f.zip AS postcode, f.status AS site_status,
fi.name as investigators,
fc.email AS contacts,
cc.email AS central_contacts
FROM studies s
INNER JOIN facilities f ON f.nct_id = s.nct_id
INNER JOIN conditions c ON c.nct_id = s.nct_id
INNER JOIN interventions i ON i.nct_id = s.nct_id
LEFT JOIN central_contacts cc ON cc.nct_id = s.nct_id
LEFT JOIN facility_contacts fc ON f.id = fc.facility_id
LEFT JOIN facility_investigators fi ON f.id=fi.facility_id
WHERE f.country LIKE ('",
country,
"')
AND s.study_type LIKE ('Interventional')
AND s.overall_status IN ('Recruiting')
AND f.status IN ('Recruiting', 'Not yet recruiting')")
## get data from clinicaltrials.gov
openStudies <- dbGetQuery(conn2,openStudiesQ)
## add a column to indicate refresh date
openStudies$Refresh.date <- today
## add a column to hold matching condition
openStudies$matching.condition <- NA
openStudies$TARGET.condition <- NA
## create an empty version to which matching rows will be added after looping through condition synonyms
cancerStudies <- openStudies[0, ]
# loop through condition synonyms
for(i in 1:nrow(conditionSynonyms)) {
synonym <- as.character(conditionSynonyms$condition.synonyms[i])
targetCondition <- as.character(conditionSynonyms$controlled.cancer.type[i])
## look for a match in condition name
matching.rows <- grep(pattern = synonym, x=openStudies$condition, ignore.case = TRUE)
## create a temporary data frame to hold matches
temp <- openStudies[matching.rows, ]
if(nrow(temp)>0) {
temp$matching.condition <- synonym
temp$TARGET.condition <- targetCondition
cancerStudies <- rbind(cancerStudies, temp)
}
}
## overwrite openStudies with openStudies2
#openStudies <- openStudies2
## delete copy of openStudies to save memory
rm(openStudies)
## remove redundant rows, if any
cancerStudies <- unique(cancerStudies)
## add a column to hold link
cancerStudies$Link <- paste0("https://clinicaltrials.gov/ct2/show/", cancerStudies$nct_id)
## get eligibility criteria (before connection times out)
studyIDs <- unique(cancerStudies$nct_id)
## form SQL query
studyIDsForSQL <- paste0("\'",paste(studyIDs, collapse = "\',\'"), "\'")
getEligibilities <- paste0("select e.nct_id, e.criteria
from eligibilities e
where e.nct_id in (",
"", studyIDsForSQL,
")")
## get criteria from clinicaltrials.gov
eligibilities <- dbGetQuery(conn2,getEligibilities)
## get lat and long for UK cities
## use postcodes where available
locations <- unique(dplyr::select(cancerStudies, postcode))
locations$postcode.lat <- NA
locations$postcode.long <- NA
for(i in 1:nrow(locations)) {
postcode <- locations$postcode[i]
tryCatch({
lat = postcode_lookup(postcode)$latitude
locations$postcode.lat[i] <- lat
long = postcode_lookup(postcode)$longitude
locations$postcode.long[i] <- long
}, error=function(cond) {return(NA)})
}
## join to cancerStudies table
cancerStudies <- merge(x=cancerStudies, by.x="postcode", all.x=TRUE, y =locations, by.y ="postcode")
geo(address = unique(cancerStudies$locations), method = 'osm')
geo(address = c("London, United Kingdom"),
method = 'osm')
unique(cancerStudies$locations)
unique(paste0(cancerStudies$locations, ", United Kingdom"))
geo(address = unique(paste0(cancerStudies$locations, ", United Kingdom")), method = 'osm')
geo(address = head(unique(paste0(cancerStudies$locations, ", United Kingdom"))), method = 'osm')
geo(address = head(unique(paste0(cancerStudies$locations, ", United Kingdom")),20), method = 'osm')
geo(address = unique(paste0(cancerStudies$locations, ", United Kingdom")), method = 'osm')
tic()
cities <- as.data.frame(geo(address = unique(paste0(cancerStudies$locations, ", United Kingdom")), method = 'osm'))
toc()
paste0(", ", configuration$country)
head(cities)
cities$address <- gsub(pattern=paste0(", ", configuration$country), replacement = "", x=cities$address)
head(cities)
cancerStudies <- merge(x=cancerStudies, by.x="locations", all.x=TRUE, y=dplyr::select(cities, address, lat, long), by.y="address")
head(cancerStudies)
## use tidygeocoder (MIT licence)
## need append country from config file after city name...
cities <- as.data.frame(tidygeocoder::geo(address = unique(paste0(cancerStudies$locations, ", ", configuration$country)), method = 'osm'))
## trim off the suffix
cities$address <- gsub(pattern=paste0(", ", configuration$country), replacement = "", x=cities$address)
cancerStudies <- merge(x=cancerStudies, by.x="locations", all.x=TRUE, y=dplyr::select(cities, address, lat, long), by.y="address")
## if postcode.lat is not NA, use that value to overwrite lat value
cancerStudies$lat[!is.na(cancerStudies$postcode.lat)] <- cancerStudies$postcode.lat[!is.na(cancerStudies$postcode.lat)]
## likewise for longitude
cancerStudies$long[!is.na(cancerStudies$postcode.long)] <- cancerStudies$postcode.long[!is.na(cancerStudies$postcode.long)]
rm(list=ls())
rmarkdown::render("trialMatchDataRefresh.Rmd")
