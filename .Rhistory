split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
modFit <- train(Species ~ ., method="rpart", data=split1.1)
fancyRpartPlot(modFit$finalModel)
split2.1 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[1]]
head(split2.1)
split2.2 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[2]]
head(split2.2)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]  ## sample rows from training dataset, all variables
split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
head(split1.1)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
split1.2 <- training[sample(nrow(training),size=nrow(split1.2),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.2)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE))
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
> split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
> split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
head(split1.1)
head(split1.2)
?getTree
library(randomForest)
?getTree
modFit <- train(Species ~ ., data = training, method="rf", prox=TRUE)
getTree(modFit$finalModel, k=1)
class(getTree(modFit$finalModel, k=1))
fancyRpartPlot(getTree(modFit$finalModel, k=1))
cforest(Species ~ ., data=training, controls=cforest_control(mtry=2, mincriterion=0))
rm(list=ls())
data("iris")
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
head(training)
> modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
library(rattle)
fancyRpartPlot(modFit$finalModel) ## nicer looking plot
split1.1 <- split(training, Petal.Length<2.5)[[1]]
split1.1 <- split(training, training$Petal.Length<2.5)[[1]]
split1.2 <- split(training, training$Petal.Length<2.5)[[2]]
head(split1.1,10)
head(split1.2,10)
head(training,10)
table(iris$Species)
table(training$Species)
table(split1.1$Species)
table(split1.2$Species)
split2.1 <- split(split1.1, split1.1$Petal.Width<1.6)[[1]]
split2.2 <- split(split1.1, split1.1$Petal.Width<1.6)[[2]]
head(split2.1)
table(split2.1$Species)
head(split2.2)
table(split2.2$Species)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
table(split1.1$Species)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
table(split1.2$Species)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
evidence <- read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
dim(evidence)
names(evidence)
"H773_V774insAH" %in% evidence$variant
filter(evidence, gene=="EGFR")
library(dplyr)
filter(evidence, gene=="EGFR")
unique(filter(evidence, gene=="EGFR"))
unique(filter(evidence, gene=="EGFR"))$variant
sort(unique(filter(evidence, gene=="EGFR"))$variant)
sort(unique(filter(evidence, gene=="MYC"))$variant)
sort(unique(filter(evidence, gene=="MYC")))
unique(filter(evidence, gene=="MYC"))
sort(unique(filter(evidence, gene=="FGFR3"))$variant)
unique(filter(evidence, gene=="FGFR3"))
unique(filter(evidence, gene=="KRAS"))
unique(filter(evidence, gene=="KRAS"))$variant
sort(unique(filter(evidence, gene=="FGFR3")$variant))
sort(unique(filter(evidence, gene=="KRAS")$variant))
unique(filter(evidence, gene=="KRAS" & variant =="Q61R"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61.*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61"))
rm(list=ls())
getwd()
?checkboxInput
?buttonInput
?actionButton
paste0("<input id='type1_",1:nrow(table), "' type='checkbox' >")
paste0("<input id='type1_",1:15, "' type='checkbox' >")
?observeEvent
shiny::runApp('GitHub/UHS_COVID/checkboxes')
runApp('GitHub/UHS_COVID/checkboxes')
runApp('GitHub/UHS_COVID/checkboxes')
runApp('GitHub/UHS_COVID/checkboxes')
runApp('GitHub/UHS_COVID/checkboxes')
data.frame(bins = c(30, 50), cb = c(T, F))
?datatable
head(humanGenes)
humanGenes[0,]
getwd()
setwd("GitHub/decisionScience")
rmarkdown::render("decisionScience_ranking.Rmd")
paste(filepath, "trialMatchConfiguration.json", sep = "/")
filepath <-"C:/Users/O’ReganPaul/Documents"
paste(filepath, "trialMatchConfiguration.json", sep = "/")
configuration <- fromJSON(file = paste(filepath, "trialMatchConfiguration.json", sep = "/"))
configuration$aact.username
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
##NOTE: the following packages are required to run this script, but should be installed (e.g. using code snippets below) before runnning the script, NOT as part of the script itself
# options(repos = "http://cran.us.r-project.org")
# install.packages("BiocManager")
# BiocManager::install("AnnotationDbi")
# BiocManager::install("org.Hs.eg.db")
# BiocManager::install("KEGGREST")
# BiocManager::install("KEGGlincs")
# BiocManager::install("hgu133a.db")
require(KEGGlincs)
require(KEGGgraph)
require(RPostgreSQL)
require(RODBC)
require(formattable)
require(org.Hs.eg.db)
require(DBI)
require(dplyr)
require(tidyr)
require(kableExtra)
require(KEGGREST)
require(stringr)
require(splitstackshape)
require(reshape2)
require(tictoc)
require(rjson)
require(RSQLite)
require(igraph)
## clean up first
rm(list=ls())
##get today's date
today <- format(Sys.Date(), format = "%d %B %Y")
## specify user name and password for AACT account
## see https://aact.ctti-clinicaltrials.org/ for how to create an account
## specify path to configuration file
filepath <-"C:/Users/O’ReganPaul/Documents"
## load configuration data from JSON file
configuration <- fromJSON(file = paste(filepath, "trialMatchConfiguration.json", sep = "/"))
aact.username <- configuration$aact.username
aact.password <- configuration$aact.password
drv <- dbDriver("PostgreSQL")
conn2 <- dbConnect(drv, dbname="aact",host="aact-db.ctti-clinicaltrials.org", port=5432, user=aact.username, password=aact.password )
con <- dbConnect(RSQLite::SQLite(), "trialResults.sqlite")
dbListTables(con)
rmarkdown::render("decisionScience_ranking.Rmd")
rmarkdown::render("decisionScience_ranking.Rmd")
rmarkdown::render("decisionScience_ranking.Rmd")
## add a column to indicate criterion type
eligibilities$criterion.type <- NA
## split into individual criteria
for(i in 1:length(eligibilities$criteria)) {
criteria <- as.character(eligibilities$criteria[i])
#criteria <- unlist(strsplit(criteria, split = "\n\n"))## split on double line breaks (DEPRECATED)
criteria <- unlist(strsplit(criteria, split = "\r\n\r\n"))## split on double newline/carriage return
criteria <- trimws(x=criteria, which = "both")## trim whitespace from start and end
criteria <- gsub(pattern = "\n", replacement = "", x= criteria)## remove single line breaks from each criterion
criteria <- str_squish(string = criteria) ## squish repeated spaces within each criterion
#criteria <- as.list(criteria)
eligibilities$criteria[i] <- list(criteria)
}
## unnest
eligibilities <- as.data.frame(unnest(data = eligibilities, cols = criteria))
eligibilities$criterion.type[1] <- "INCLUSION"
View(eligibilities)
## classify as either inclusion or exclusion
## tag start of inclusion criteria
eligibilities$criterion.type[grep(pattern = "inclusion criteria:?$", x=eligibilities$criteria, ignore.case = TRUE)] <- "INCLUSION"
## tag start of exclusion criteria
eligibilities$criterion.type[grep(pattern = "exclusion criteria:?$", x=eligibilities$criteria, ignore.case = TRUE)] <- "EXCLUSION"
## fill "down" using the tdiyr::fill() function
eligibilities <- tidyr::fill(data=eligibilities, criterion.type, .direction="down")
## add a column to indicate feature referenced by text
eligibilities$feature <- NA
## add a column that will hold matching term (e.g. gene names)
eligibilities$match <- NA
indexOnPattern <- function(eligibilities, pattern, wordRange, featureLabel) {
table <- eligibilities
pattern <- pattern
wordRange <- wordRange
featureLabel <- featureLabel
## get indices containing specified pattern
indices <- grep(pattern = pattern, x=table$criteria, ignore.case = T)
# subset table
table <- table[indices, ]
# label nature of change
table$feature <- featureLabel
## loop through each criterion that contains pattern
for(i in 1:nrow(table)) {
criterion <- table$criteria[i]
# also create an alternative criterion for patterns such as "BRCA1/2"
alternative.criterion <- gsub(pattern = "./", replacement = "", x=criterion)
# concatenate
criterion <- paste(criterion,alternative.criterion, sep = " " )
# split into tokens
criterion <- unlist(strsplit(x=criterion, split = " |\\(|\\)|,|-|/"))
## criterion is now a vector of tokens (words, but also some empty elements)
## remove any empty elements in criterion
criterion <- criterion[criterion!=""]
## get indices of match(es) against pattern (need to squish preceding space)
indices <- grep(pattern = str_squish(pattern), x = criterion, ignore.case = TRUE)
## specify start and end point(s) based on specified word range
starts <- indices - wordRange
ends <- indices + wordRange
range <- numeric(0)
for(j in 1:length(starts)) { ## because there may be more than one match
if(starts[j] <1) {starts[j] <- 1}
range <- append(range,starts[j]:ends[j])
} ## now range contains the indices of the words either side of the pattern, within specified word range
range <- unique(range) ## if the ranges overlap, just get the unique elements
## range is the indices of words within the criterion that are within the specified wordRange from pattern (i.e. the ones we want to keep)
## subset the criterion retain only words within specified range
criterion <- criterion[range]
## omit any NA values (i.e. where match is less than wordRange from end of sentence)
criterion <- criterion[!is.na(criterion)]
## now subset and retain only words that are a valid gene alias
criterion <- unique(criterion[criterion %in% humanGenes$Aliases])
## drop any aliases that are a single or 2 characters
criterion <- criterion[nchar(criterion)>2]
## drop any matches against the word "not"
criterion <- criterion[criterion != "not"]
if(length(criterion)>0) table$match[i] <- list(criterion)
}
## drop rows not indexed against a gene
table <- table[!is.na(table$match), ]
## unnest
table <- as.data.frame(unnest(table, cols = "match"))
## join to Entrez symbols from humanGenes
table <- merge(x=table, by.x="match", y=humanGenes, by.y = "Aliases")
## rename Symbol to "controlled.match"
# using rename gives unreliable results (?!)
# see https://stackoverflow.com/questions/26371279/dplyr-0-3-0-2-rename-idiom-unstable-when-reshape-package-is-loaded
#table <- rename(table, "controlled.match"="Symbol")
table$controlled.match <- table$Symbol
table <- dplyr::select(table, -Symbol)
## drop redundant rows
table <- unique(table)
## return table
return(table)
}
## call indexing function
## exclude matches containing "positive" as these tend to be IHC, not mutation
## also exclude "loss" as this is included in rearrangementPattern
mutation.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = "mutat|mutant|defect|deficien|alter|loss of function|loss-of-function", wordRange = 6, featureLabel = "mutation")
## start timer
tic("download a list of all human genes and their synonyms")
humanGenes <- read.table(file = "humanGenes.tsv", header = TRUE, quote = "", sep = "\t", fill = TRUE, stringsAsFactors = FALSE)
humanGenes <- dplyr::select(humanGenes, Symbol, Aliases)## drop everything except Symbol and Aliases columns
humanGenes$Aliases <- strsplit(x=humanGenes$Aliases, split = ",")## split the aliases on comma
humanGenes <- unnest(data = humanGenes, cols = Aliases, keep_empty = TRUE) ## unnest to multiply rows, keep any rows with no aliases
humanGenes <- as.data.frame(humanGenes) ## convert to data frame
humanGenes$Aliases <- str_squish(string = humanGenes$Aliases) ## trim excess whitespace from Aliases values
## Symbol values are not represented among Aliases
# create a data frame with unique Symbol values
symbols <- data.frame("Symbol"=unique(humanGenes$Symbol), "Aliases"=unique(humanGenes$Symbol))
# bind this onto bottom of humanGenes data frame
humanGenes <- rbind(humanGenes,symbols)
# remove duplicated values, if any
humanGenes <- unique(humanGenes)
# sort on Symbol values
humanGenes <- humanGenes[order(humanGenes$Symbol), ]
# drop any rows where Aliases is NA
humanGenes <- humanGenes[!is.na(humanGenes$Aliases), ]
## drop any rows where Aliases value is only a single character
## NOW humanGenes TABLE CONTAINS ALL HUMAN GENES AND THEIR SYNONYMS
## (61,593 unique symbols, 130,989 rows)
## stop timer
toc()
## call indexing function
## exclude matches containing "positive" as these tend to be IHC, not mutation
## also exclude "loss" as this is included in rearrangementPattern
mutation.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = "mutat|mutant|defect|deficien|alter|loss of function|loss-of-function", wordRange = 6, featureLabel = "mutation")
## preview
formattable(head(mutation.eligibilities))
head(mutation.eligibilities)
## NOT USED BECAUSE SUPERCEDED BY INDEX ON REARRANGEMENTS
fusion.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = " fusion|rearrangement", wordRange = 7, featureLabel = "fusion")
## preview
formattable(head(fusion.eligibilities))
rearrangement.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = " fusion|rearrangement|truncation|truncated|deletion|deleted|lost|duplication|duplicated", wordRange = 6, featureLabel = "rearrangement")
## preview
formattable(head(rearrangement.eligibilities))
## NOTE USE WORD RANGE OF 2 FOR LOSS, OTHERWISE GET TOO MANY FALSE HITS (including "loss of function" etc, which is indexed as a mutation)
loss.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = "loss", wordRange = 2, featureLabel = "loss")
## preview
formattable(head(loss.eligibilities))
amplification.eligibilities <- indexOnPattern(eligibilities = eligibilities, pattern = " amplification|overexpression", wordRange = 5, featureLabel = "amplification")
## preview
formattable(head(amplification.eligibilities))
unique(rbind(mutation.eligibilities, rearrangement.eligibilities, loss.eligibilities, amplification.eligibilities))
rmarkdown::render("decisionScience_ranking.Rmd")
?dbConnect
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 1: setup
require(flexdashboard)
require(dplyr)
require(tidyr)
require(kableExtra)
require(shinyWidgets)
require(leaflet)
require(htmltools)
require(rjson)
require(RSQLite)
require(DT)
require(DBI)
#require(DT)
## load configuration data from JSON file
configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## get refresh date
refresh.date <- unique(cancerStudies$Refresh.date)
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
#  [1] "interventions"      "locations"          "postcode"           "nct_id"
#  [5] "brief_title"        "overall_status"     "condition"          "site_name"
#  [9] "site_status"        "investigators"      "contacts"           "central_contacts"
# [13] "Refresh.date"       "matching.condition" "TARGET.condition"   "Link"
# [17] "postcode.lat"       "postcode.long"      "lat"                "long"
# [21] "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
conditionSynonyms <- dbGetQuery(con, "SELECT * FROM cancers")
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts,central_contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
central_contacts = toString(sort(unique(na.omit(central_contacts)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
dbListTables(con)
getwd()
setwd("C:/Users/O’ReganPaul/Documents/GitHub/cancer-trial-match")
dbListTables(con)
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
dbListTables(con)
# Chunk 1: setup
require(flexdashboard)
require(dplyr)
require(tidyr)
require(kableExtra)
require(shinyWidgets)
require(leaflet)
require(htmltools)
require(rjson)
require(RSQLite)
require(DT)
require(DBI)
#require(DT)
## load configuration data from JSON file
configuration <- fromJSON(file = "trialMatchConfiguration.json")
# Chunk 2: connect to SQLite DB
# Create an RSQLite database
con <- dbConnect(RSQLite::SQLite(), "trialMatchData.sqlite")
# Chunk 3: read cancer study data into memory
## read cancerStudies table into memory
cancerStudies <- dbGetQuery(con, "SELECT * FROM cancerStudies")
## get refresh date
refresh.date <- unique(cancerStudies$Refresh.date)
## contains study details, mapped to a controlled set of cancer types in the "TARGET.condition"  column
## names are
#  [1] "interventions"      "locations"          "postcode"           "nct_id"
#  [5] "brief_title"        "overall_status"     "condition"          "site_name"
#  [9] "site_status"        "investigators"      "contacts"           "central_contacts"
# [13] "Refresh.date"       "matching.condition" "TARGET.condition"   "Link"
# [17] "postcode.lat"       "postcode.long"      "lat"                "long"
# [21] "ParentTerm"
# no columns are aggregated
## filter and retain only studies with overall status of "Recruiting"
cancerStudies <- dplyr::filter(cancerStudies, overall_status == "Recruiting")
## drop postcode.lat and postcode.long columns
cancerStudies <- unique(dplyr::select(cancerStudies, -c("postcode.lat", "postcode.long")))
## rename parentTerm column as "Mechanism"
cancerStudies <- rename(cancerStudies, "Mechanism"="ParentTerm")
## read conditions and synonyms into memory
conditionSynonyms <- dbGetQuery(con, "SELECT * FROM cancers")
# Chunk 4: get a full set of all study locations
cancer.study.locations <- unique(dplyr::select(cancerStudies, nct_id, lat, long))
## drop any rows with missing lat/long values
## NOTE THAT THIS MEANS THESE STUDIES WILL NOT BE DISPLAYED ON MAP
## (BUT WILL BE IN THE TABLE UNDERNEATH)
cancer.study.locations <- cancer.study.locations[complete.cases(cancer.study.locations), ]
# Chunk 5: aggregate cancerStudies into compact form
## aggregating interventions was causing some study:intervention combinations to be missed out
cancerStudies <- cancerStudies %>%
group_by_at(vars(-c( locations, postcode, condition, site_name, site_status, investigators, contacts,central_contacts, lat, long, Refresh.date))) %>%
summarize(locations = toString(sort(unique(na.omit(locations)))),
sites = toString(sort(unique(na.omit(site_name)))),
conditions = toString(sort(unique(na.omit(condition)))),
investigators = toString(sort(unique(na.omit(investigators)))),
central_contacts = toString(sort(unique(na.omit(central_contacts)))),
contacts = toString(sort(unique(na.omit(contacts))))) %>%
as.data.frame()
# Chunk 6: get prior tx exclusions
## read indexed eligibilities table into memory
indexedEligibility <- dbGetQuery(con, "SELECT * FROM indexedEligibility")
## filter for exclusions
excludedTX <- filter(indexedEligibility, criterion.type=="EXCLUSION")
## filter for prior therapy
excludedTX <- filter(excludedTX, feature=="PRIOR_THERAPY")
## drop unnecessary columns
excludedTX <- unique(dplyr::select(excludedTX, nct_id, "Exclusions"="criteria"))
## aggregate into single row per study
excludedTX <- excludedTX %>%
group_by(nct_id) %>%
summarize(Exclusions = paste(sort(unique(na.omit(Exclusions))), collapse="\n")) %>%
as.data.frame()
## join to cancerStudies
cancerStudies <- merge(x=cancerStudies, by.x = "nct_id", all.x = TRUE, y=excludedTX, by.y="nct_id")
# Chunk 7: read studies scored on match against genes of interest
## read cancerStudies table into memory
scoredMatches <- dbGetQuery(con, "SELECT * FROM scoredMatches")
## scoredMatches contains all possible matches of studies, their interventions and inclusion criteria against all possible genes of interest
## column names are
# [1] "symbol"                 "variant_type"           "nct_id"
# [4] "intervention_rationale" "eligibility_rationale"  "matching_criteria"
# [7] "combined_score"
dplyr::filter(scoredMatches, gene_variant_type %in% NULL)
table <- scoredMatches[NULL, ]
table
names(scoredMatches)
names(scoredMatches)
scoredMatches[NULL, ]
merge(x=head(cancerStudies), by.x="nct_id", all.x = TRUE, y=scoredMatches[NULL, ], by.y="nct_id")
dplyr::filter(scoredMatches, gene_variant_type %in% NULL)
dbListTables(con)
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
dbGetQuery(con, "SELECT * FROM shortlisted")
dbGetQuery(con, "SELECT * FROM shortlisted")
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
nrow(dbGetQuery(con, "SELECT * FROM shortlisted"))
dbListTables(con)
head(dbGetQuery(con, "SELECT * FROM shortlisted"))
dbListTables(con)
