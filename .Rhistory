names(salivary.studies)
## select columns of interest
salivary.studies <- dplyr::select(salivary.studies, nct_id, official_title, sites, start_date, completion_date, cancer_types, matching.symbol, matching.alias, eligibility_criteria)
## remove duplicated rows
salivary.studies <- unique(salivary.studies)
rmarkdown::render("salivary_cancers.Rmd")
filter(matchesTable, nchar(matching.alias) <2)
class(matchesTable$matching.alias)
matchesTable$matching.alias <- as.character(matchesTable$matching.alias)
filter(matchesTable, nchar(matching.alias) <2)
filter(matchesTable, nchar(matching.alias) >1 )
rmarkdown::render("salivary_cancers.Rmd")
rmarkdown::render("salivary_cancers.Rmd")
strsplit(x="a bunch of words, separated by (parentheses)", split = " |/|,|(|)")
strsplit(x="a bunch of words, separated by (parentheses)", split = " |/|,|\(|\)")
strsplit(x="a bunch of words, separated by (parentheses)", split = " |/|,|\\(|\\)")
rmarkdown::render("salivary_cancers.Rmd")
rmarkdown::render("salivary_cancers.Rmd")
"FGFR" %in% humanGenes$Aliases
rmarkdown::render("salivary_cancers.Rmd")
install.packages("xlsx")
?write.xlsx
library(xlsx)
?write.xlsx
rmarkdown::render("salivary_cancers.Rmd")
library(xlsx)
?write.table
install.packages("xlsx")
library(xlsx)
install.packages("xlsx")
library(xlsx)
install.packages("openxlsx")
library(openxlsx)
write.xlsx(x=salivary.studies, file = "salivary_studies_all.xlsx", sheetName = "Sheet1", col.names = TRUE, row.names = FALSE, append = FALSE)
write.xlsx(x=salivary.studies, file = "test.xlsx", col.names = TRUE, row.names = FALSE, append = FALSE)
?write.xlsx
write.xlsx(x=salivary.studies, file = "test.xlsx")
install.packages("zip")
install.packages("zip")
install.packages("ggplot2")
library(zip)
write.xlsx(x=salivary.studies, file = "test.xlsx")
library(openxlsx)
write.xlsx(x=salivary.studies, file = "test.xlsx")
rmarkdown::render("salivary_cancers.Rmd")
write.xlsx(x=salivary.studies, file = "test.xlsx")
library(zip)
write.xlsx(x=salivary.studies, file = "test.xlsx")
rmarkdown::render("salivary_cancers.Rmd")
rmarkdown::render("salivary_cancers.Rmd")
write.table(salivary.studies.all, file = "salivary_studies_all.tsv", sep = "\t",
row.names = FALSE, col.names = names(salivary.studies))
salivary.studies.all$eligibility_criteria[1]
write.csv(salivary.studies.all, file = "salivary_studies_all.csv"row.names = FALSE)
write.csv(salivary.studies.all, file = "salivary_studies_all.csv", row.names = FALSE)
rmarkdown::render("salivary_cancers.Rmd")
salivary.studies$eligibility_criteria[8]
gsub(pattern = "[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
gsub(pattern = "[a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
gsub(pattern = "[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
gsub(pattern = "^(.*?)[a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
gsub(pattern = "^(.*?)[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
salivary.studies$eligibility_criteria.trimmed <- gsub(pattern = "^(.*?)[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria)
salivary.studies$eligibility_criteria.trimmed <- gsub(pattern = "[^a-zA-Z0-9?]", replacement = "", x= salivary.studies$eligibility_criteria)
gsub(pattern = "^(.*?)[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
gsub(pattern = "[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
?gsub
sub(pattern = "[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
salivary.studies$eligibility_criteria.trimmed <- sub(pattern = "[^a-zA-Z0-9?]", replacement = "", x= salivary.studies$eligibility_criteria)
sub(pattern = "[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
sub(pattern = "^[^a-zA-Z0-9]", replacement = "", x= salivary.studies$eligibility_criteria[8])
salivary.studies$eligibility_criteria.trimmed <- sub(pattern = "^[^a-zA-Z0-9?]", replacement = "", x= salivary.studies$eligibility_criteria)
sub(pattern = "^[^a-zA-Z0-9?]", replacement = "", x= salivary.studies.all$eligibility_criteria)
salivary.studies.all$eligibility_criteria.trimmed <- sub(pattern = "^[^a-zA-Z0-9?]", replacement = "", x= salivary.studies.all$eligibility_criteria)
View(salivary.studies.all)
rmarkdown::render("salivary_cancers.Rmd")
rmarkdown::render("salivary_cancers.Rmd")
rmarkdown::render("salivary_cancers.Rmd")
38+51+1
107+258+6+2
197/460
exp(0.73)
exp(0.064)
exp(1.416)
rm(list=ls())
?rename
library(dplyr)
?rename
1367+2377+2063
79/5807
299*35+1794
278*35+2508
260*35+3131
322*35+968
347*36
283*35+2554
328*35+985
304*35+1827
328*35+985
localFilepath <-"C:/Users/Oâ€™ReganPaul/Downloads"
read.csv(file = paste(localFilepath,"REACT_pharmacy_15Jan21.csv", sep = "/"), stringsAsFactors = FALSE, header = TRUE)
pharmacy <- read.csv(file = paste(localFilepath,"REACT_PharmacData_15Jan21.csv", sep = "/"), stringsAsFactors = FALSE, header = TRUE)
pharmacy <- read.csv(file = paste(localFilepath,"REACT_PharmacyData_15Jan21.csv", sep = "/"), stringsAsFactors = FALSE, header = TRUE)
unique(pharmacy$DRUGDESCRIPTION)
grep(pattern = "DEXAM", x=pharmacy$DRUGDESCRIPTION)
unique(pharmacy$STUDY_ID[grep(pattern = "DEXAM", x=pharmacy$DRUGDESCRIPTION)])
length(unique(pharmacy$STUDY_ID[grep(pattern = "DEXAM", x=pharmacy$DRUGDESCRIPTION)]))
rm(list=ls())
library(ISLR)
library(caret)
data(Wage)
head(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE) # partition into 70% trainind set
training <- Wage[inTrain, ]  ## create training set
testing <- Wage[-inTrain, ]  ## create test set
unique(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data = training) ## create dummy variables, 0 and 1 for each level
head(dummies)
head(predict(dummies, newdata = training))
head(predict(dummies, newdata = training)) ## assign dummy variable values to each sample in the training set
nsv <- nearZeroVar(training, saveMetrics = TRUE) ## identify which variables in the training set have very little variability
nsv
library(splines)
bsBasis <- bs(training$age, df=3)
bsBasis
lml <- lm)wage ~ bsBasis, data=training
lml <- lm(wage ~ bsBasis, data=training)
plot(training$age, training$wage,pch=19,cex=0.5)
points(training$age,predict(lml,newdata = training), col="red",pch=19,cex=0.5)
predict(bsBasis, age=testing$age)
plot(training$age, training$wage,pch=19,cex=0.5)
predict(bsBasis, age=testing$age)
rm(list=ls())
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[, -58])) ## column 58 is the outcome of interest
M
diag(M)
diag(M) <- 0
M
which(M > 0.8, arr.ind = TRUE)
names(spam)[c(34,32)]
plot(spam[,34], spam[,32])
names(spam)[c(34,32,40)]
X <- training$num415 + training$num857
Y <- training$num415 - training$num857
plot(X,Y)
smallSpam <- spam[ ,c(34,32)]   ## just get the num415 and num857 columns for simplicity
prComp <- prcomp(smallSpam)  ## get principal components
prComp
plot(prComp$x[,1], prComp$x[,2])
prComp$x
tail(prComp$x)
unique(prComp$x$PC1)
unique(prComp$x[,1])
summary(prComp)
str(prComp)
class(prComp$x)
prComp$rotation
preProc <- preProcess(log10(spam[,-58]+1), method = "pca", pcaComp = 2)
summary(preProc)
head(preProc)
spamPC <- predict(preProc, log10(spam[ ,-58]+1)) ##
plot(spamPC[,1], spamPC[,2], col=typeColor)
typeColor <- ((spam$type=="spam")*1 +1)
typeColor
unique(typeColor)
prComp <- prcomp(log10(spam[,-58]+1)) ## take log10 of variables, add 1 and calculate principal components
plot(prComp$x[,1], prComp$x[, 2], col=typeColor, xlab="PC1", ylab="PC2")
> spamPC <- predict(preProc, log10(spam[ ,-58]+1)) ##
> plot(spamPC[,1], spamPC[,2], col=typeColor)
spamPC <- predict(preProc, log10(spam[ ,-58]+1)) ##
plot(spamPC[,1], spamPC[,2], col=typeColor)
prComp$rotation
prComp$rotation[ ,1]
preProc <- preProcess(log10(spam[,-58]+1), method = "pca", pcaComp = 2)
class(preProc)
preProc <- preProcess(log10(training[,-58]+1), method = "pca", pcaComp = 2)
trainPC <- predict(preProc, log10(training[, -58]+1))
modelFit <- train(training$type ~ ., method="glm", data=trainPC) ##
inTrain
training <- spam[inTrain,]
testing <- spam[-inTrain, ]
preProc <- preProcess(log10(training[,-58]+1), method = "pca", pcaComp = 2)
trainPC <- predict(log10(training[,-58]+1))
trainPC <- predict(preProc, log10(training[,-58]+1))
modelFit <- train(training$type ~ ., method="glm", data = trainPC)
rm(list=ls())
library(caret)
data("faithful")
set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue",xlab = "Waiting time", ylab = "Eruption duration")
lm1 <- lm(eruptions ~ waiting, data=trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue",xlab = "Waiting time", ylab = "Eruption duration")
lines(trainFaith$waiting, lm1$fitted.values, lwd=3)
newdata <- data.frame(waiting=80)
predict(lm1, newdata)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue",xlab = "Waiting time", ylab = "Eruption duration")
lines(trainFaith$waiting, lm1$fitted.values, lwd=3)
sqrt(sum((predict(lm1,newdata = testFaith)-testFaith$eruptions)^2))
predict(lm1,newdata = testFaith)-testFaith$eruptions
(predict(lm1,newdata = testFaith)-testFaith$eruptions)^2
mean((predict(lm1,newdata = testFaith)-testFaith$eruptions)^2)
sqrt(mean((predict(lm1,newdata = testFaith)-testFaith$eruptions)^2)
)
sqrt(mean((predict(lm1,newdata = testFaith)-testFaith$eruptions)^2))
sqrt(mean((predict(lm1,newdata = trainFaith)-trainFaith$eruptions)^2))
pred1 <- predict(lm1, newdata = testFaith, interval = "prediction")
class(pred1)
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue") ## plot actual values in test set
matlines(testFaith$waiting[ord], pred1[ord], type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3) ## add lines with predicted values and prediction intervals
matlines(testFaith$waiting[ord], pred1[ord, ], type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3) ## add lines with predicted values and prediction intervals
ord
pred1
pred1[ord, ] ## reorder on waiting time
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue") ## plot actual values in test set
matlines(testFaith$waiting, pred1 , type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3) ## add lines with predicted values and prediction intervals
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue") ## plot actual values in test set
matlines(testFaith$waiting[ord], pred1[ord, ], type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3) ## add lines with predicted values and prediction intervals
modFit <- train(eruptions ~ waiting, data=trainFaith, method="lm")
summary(modFit$finalModel)
predict(modFit, newdata)
pred2 <- predict(modFit, newdata = testFaith, interval="prediction")
head(pred2)
predict(modFit, newdata = testFaith, interval="prediction")
predict(modFit$finalModel, newdata = testFaith, interval="prediction")
pred2 <- predict(modFit$finalModel, newdata = testFaith, interval="prediction")
head(pred2)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue") ## plot actual values in test set
matlines(testFaith$waiting, pred2, type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3)
?train
library(ISLR)
data("Wage")
Wage <- subset(Wage, select = -c(logwage))
inTrain <- createDataPartition(y-Wage$wage, p=0.7, list = FALSE)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
qplot(age, wage, colour=jobclass, data=training)  ## exploratory plot
qplot(age, wage, colour=education, data=training)  ## exploratory plot
modeFit <- train(wage ~ age + jobclass + education,
method = "lm",
data=training)
finMod <- modFit$finalModel
print(modFit)
modFit <- train(wage ~ age + jobclass + education,
method = "lm",
data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod, pch=19, cex=0.5,col="#00000010")
qplot(finMod$fitted.values, finMod$residuals, colour=race, data=training)
plot(finMod$residuals, pch=19)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisaease)
data(AlzheimerDisease)
data("concrete")
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training <- mixtures[inTrain, ]
testing <- mixtures[-inTrain, ]
qplot(training$CompressiveStrength)
plot(training$CompressiveStrength)
names(training)
plot(training$CompressiveStrength, colour="Cement")
qplot(training$CompressiveStrength, colour="Cement")
qplot(training$CompressiveStrength,seq_along(training$CompressiveStrength) colour="Cement")
qplot(training$CompressiveStrength,seq_along(training$CompressiveStrength), colour="Cement")
plot(training$CompressiveStrength, colour="Cement")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="Cement")
names(training)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="BlastFurnaceSlag")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="FlyAsh")
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=Cement)
unique(training$Cement)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour="Cement")
?cut2
libary(Hmisc)
library(Hmisc)
?cut2
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Cement))
head(training)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$BlastFurnaceSlag))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$FlyAsh))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Water))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$Age))
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength)
qplot(seq_along(training$CompressiveStrength),training$CompressiveStrength, colour=cut2(training$FlyAsh))
qplot(training$Superplasticizer)
log(training$Superplasticizer)
set.seed(3433)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
names(training)
grep(pattern = "IL", x=names(training))
head(training[ ,grep(pattern = "IL", x=names(training))])
head(training[ ,grep(pattern = "^IL", x=names(training))])
subTraining <- training[ ,grep(pattern = "^IL", x=names(training))]
prComp <- prcomp(subTraining)
head(prComp)
summary(prComp)
preObj <- preProcess(training[ ,grep(pattern = "^IL", x=names(training))])
summary(preObj)
class(preObj)
preObj$rotation
set.seed(3433)
data(AlzheimerDisease)
names(training)
rm(list=ls())
rm(list=ls())
data("iris")
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
modFit <- train(Species ~ ., data=training, method="rf", prox=TRUE)
modFit <- train(Species ~ ., data=training, method="rf", prox=TRUE)
modFit
getTree(modFit$finalModel, k=2)
library(randomForest)
getTree(modFit$finalModel, k=2)
irisP <- classCenter(training[ ,c(3,4)], training$Species, modFit$finalModel$proximity)
class(irisP)
irisP <- as.data.frame(irisP)
head(irisP)
irisP
irisP$Species <- rownames(irisP)
irisP
p <- qplot(Petal.Width, Petal.Length, col=Species, data=training)
p+ geom_point(aes(x=Petal.Width, y=Petal.Length, col=Species), size=5, shape=4, data=irisP)
pred <- predict(modFit, testing)
testing$predRight <- pred==testing$Species
table(pred, testing$Species)
qplot(Petal.Width, Petal.Length, colour=predRight,data=testing, main="newdata Predictions")
rm(list=ls())
library(caret)
data("iris")
head(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[ -inTrain, ]
head(training)
sample(x=training, size=5, replace = TRUE)
?sample
X[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]
training[sample(nrow(training),size=5,replace=TRUE),]  ## sample 5 rows from training dataset, all variables
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
split0 <- training[sample(nrow(training),size=5,replace=TRUE),]  ## sample 5 rows from training dataset, all variables
split1 <- training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
split2 <- training[sample(nrow(training),size=5,replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## sample 5 rows and 2 variables from training dataset
install.packages("ineq")
library(ineq)
modFit <- train(Species ~ ., method="rpart", data=split0)
head(split0)
split0 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]  ## sample 5 rows from training dataset, all variables
modFit <- train(Species ~ ., method="rpart", data=split0)
library(rattle)
fancyRpartPlot(modFit$finalModel)
split(split0, Petal.Length < 2.6)
split(split0, split0$Petal.Length < 2.6)
split(split0, split0$Petal.Length < 2.6)[[1]]
split1.1 <- split(split0, split0$Petal.Length < 2.6)[[1]]
head(split1.1)
split1.2 <- split(split0, split0$Petal.Length < 2.6)[[2]]
head(split1.2)
split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
modFit <- train(Species ~ ., method="rpart", data=split1.1)
fancyRpartPlot(modFit$finalModel)
split2.1 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[1]]
head(split2.1)
split2.2 <- split(split1.1, split1.1$Sepal.Length < 5.5)[[2]]
head(split2.2)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]  ## sample rows from training dataset, all variables
split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
head(split1.1)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- training[sample(nrow(training),size=nrow(split1.1),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.1)
split1.2 <- training[sample(nrow(training),size=nrow(split1.2),replace=TRUE),c(sample(1:4,size=2,replace=TRUE),5)]  ## resample all rows and 2 variables from the result of the first split
head(split1.2)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE))
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
> split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
> split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
head(split1.1)
head(split1.2)
?getTree
library(randomForest)
?getTree
modFit <- train(Species ~ ., data = training, method="rf", prox=TRUE)
getTree(modFit$finalModel, k=1)
class(getTree(modFit$finalModel, k=1))
fancyRpartPlot(getTree(modFit$finalModel, k=1))
cforest(Species ~ ., data=training, controls=cforest_control(mtry=2, mincriterion=0))
rm(list=ls())
data("iris")
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
head(training)
> modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
modFit <- train(Species ~ ., method="rpart", data=training) ## rpart is R's method for creating decision trees
library(rattle)
fancyRpartPlot(modFit$finalModel) ## nicer looking plot
split1.1 <- split(training, Petal.Length<2.5)[[1]]
split1.1 <- split(training, training$Petal.Length<2.5)[[1]]
split1.2 <- split(training, training$Petal.Length<2.5)[[2]]
head(split1.1,10)
head(split1.2,10)
head(training,10)
table(iris$Species)
table(training$Species)
table(split1.1$Species)
table(split1.2$Species)
split2.1 <- split(split1.1, split1.1$Petal.Width<1.6)[[1]]
split2.2 <- split(split1.1, split1.1$Petal.Width<1.6)[[2]]
head(split2.1)
table(split2.1$Species)
head(split2.2)
table(split2.2$Species)
bootstrap1 <- training[sample(nrow(training),size=nrow(training),replace=TRUE),]
split1.1 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[1]]
table(split1.1$Species)
split1.2 <- split(bootstrap1, bootstrap1$Petal.Length < 2.6)[[2]]
table(split1.2$Species)
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
available.for.split <- sample(names(split1.1)[1:4], size = 4, replace = TRUE)
available.for.split
read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
evidence <- read.csv(file = "https://civicdb.org/downloads/nightly/nightly-ClinicalEvidenceSummaries.tsv", sep = "\t")
dim(evidence)
names(evidence)
"H773_V774insAH" %in% evidence$variant
filter(evidence, gene=="EGFR")
library(dplyr)
filter(evidence, gene=="EGFR")
unique(filter(evidence, gene=="EGFR"))
unique(filter(evidence, gene=="EGFR"))$variant
sort(unique(filter(evidence, gene=="EGFR"))$variant)
sort(unique(filter(evidence, gene=="MYC"))$variant)
sort(unique(filter(evidence, gene=="MYC")))
unique(filter(evidence, gene=="MYC"))
sort(unique(filter(evidence, gene=="FGFR3"))$variant)
unique(filter(evidence, gene=="FGFR3"))
unique(filter(evidence, gene=="KRAS"))
unique(filter(evidence, gene=="KRAS"))$variant
sort(unique(filter(evidence, gene=="FGFR3")$variant))
sort(unique(filter(evidence, gene=="KRAS")$variant))
unique(filter(evidence, gene=="KRAS" & variant =="Q61R"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61.*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61*"))
unique(filter(evidence, gene=="KRAS" & variant =="Q61"))
rm(list=ls())
getwd()
Sys.info()
packageVersion("tidyr")
packageVersion("dplyr")
installed. packages()
installed.packages()
class(installed.packages())
dim(installed.packages())
names(installed.packages())
as.data.frame(installed.packages())
write.csv(as.data.frame(installed.packages()), file = "systemInfo.csv")
getwd()
setwd("GitHub/cancer-trial-match")
rm(list=ls())
rmarkdown::render("trialMatchDataRefresh.Rmd")
tic("run trial match data refresh")
rmarkdown::render("trialMatchDataRefresh.Rmd")
toc()
dbDisconnect(conn2)
rm(list=ls())
getwd()
rmarkdown::render("trialMatchDataRefresh.Rmd")
